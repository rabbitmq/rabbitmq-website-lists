<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] Durability and consumer acknowledgement extremely slow
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Durability%20and%20consumer%20acknowledgement%0A%20extremely%20slow&In-Reply-To=%3CCAFBkYiFkRo_bUReP4g1BV%3D2WJteW6JtrJ%2BGg1OwT-9svAsF1VQ%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="026702.html">
   <LINK REL="Next"  HREF="026690.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] Durability and consumer acknowledgement extremely slow</H1>
    <B>Karl Rieb</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Durability%20and%20consumer%20acknowledgement%0A%20extremely%20slow&In-Reply-To=%3CCAFBkYiFkRo_bUReP4g1BV%3D2WJteW6JtrJ%2BGg1OwT-9svAsF1VQ%40mail.gmail.com%3E"
       TITLE="[rabbitmq-discuss] Durability and consumer acknowledgement extremely slow">karl.rieb at gmail.com
       </A><BR>
    <I>Fri Apr 26 14:21:39 BST 2013</I>
    <P><UL>
        <LI>Previous message: <A HREF="026702.html">[rabbitmq-discuss] Durability and consumer acknowledgement extremely slow
</A></li>
        <LI>Next message: <A HREF="026690.html">[rabbitmq-discuss] Need Advice to solve the problem
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#26732">[ date ]</a>
              <a href="thread.html#26732">[ thread ]</a>
              <a href="subject.html#26732">[ subject ]</a>
              <a href="author.html#26732">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>(Replying again but using Reply-All to ensure rabbitmq-discuss forum sees
my response)

Hi Simon,

Thanks a lot for your response.  Okay, I just wanted to make sure I didn't
have something misconfigured.  If the throughput I'm seeing is considered
&quot;normal&quot; given the type of machines I'm running on, then that is a huge
help to me.  I had been wondering if those numbers were considered good,
bad, etc.  Thanks!




On Thu, Apr 25, 2013 at 6:59 AM, Simon MacMullen &lt;<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">simon at rabbitmq.com</A>&gt; wrote:

&gt;<i> Hi Karl. I suspect you are not really seeing a bottleneck with
</I>&gt;<i> acknowledgements, but rather an optimisation in autoack mode. When you
</I>&gt;<i> publish a persistent message to an empty queue with a non-blocked autoack
</I>&gt;<i> consumer RabbitMQ will not persist the message to disc - there's no point.
</I>&gt;<i> The message can go straight to the consumer, and then it's gone; it can
</I>&gt;<i> never be requeued.
</I>&gt;<i>
</I>&gt;<i> So I suspect that's the difference you're seeing. And I'm afraid 5-8k
</I>&gt;<i> msg/s is roughly what I would expect for persistent messages on a
</I>&gt;<i> reasonable machine.
</I>&gt;<i>
</I>&gt;<i> Cheers, Simon
</I>&gt;<i>
</I>&gt;<i> On 24/04/13 17:26, Karl Rieb wrote:
</I>&gt;<i>
</I>&gt;&gt;<i> Hi,
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I am trying to improve the message throughput for a RabbitMQ queue in an
</I>&gt;&gt;<i> Amazon cloud instance and am noticing a *significant* drop in
</I>&gt;&gt;<i> performance when enabling acknowledgements for consumer of a durable
</I>&gt;&gt;<i> queue (with persisted messages).  The real problem is that the
</I>&gt;&gt;<i> bottleneck appears to be on the rabbit node and not with the consumers,
</I>&gt;&gt;<i> so adding more consumers does not improve the throughput (or help drain
</I>&gt;&gt;<i> the queue any quicker).  As a matter of fact, adding new consumers will
</I>&gt;&gt;<i> just slow down existing consumers so everyone ends up consuming at a
</I>&gt;&gt;<i> slower rate, preventing overall throughput from changing.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Trying to do batch acknowledgements using the Multiple flag helps a bit
</I>&gt;&gt;<i> (8k msgs/s vs 5.5k msgs/s) but not much compared to the initial drop.
</I>&gt;&gt;<i>   It is only when I turn on *auto_ack* for the consumers that I see the
</I>&gt;&gt;<i> performance shoot *way *back up and when I start seeing a linear
</I>&gt;&gt;<i> increase in throughput as I add more consumers.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Is this expected behavior?  Is there a way to configure the rabbit node
</I>&gt;&gt;<i> so it doesn't hit this bottleneck with acknowledgements?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Here is the sample code I'm using to test the throughput:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Publisher:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     #!/usr/bin/python
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     import pika
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     creds = pika.PlainCredentials('guest',**'guest')
</I>&gt;&gt;<i>     conn  =
</I>&gt;&gt;<i>     pika.BlockingConnection(pika.**ConnectionParameters(host='10.**10.1.123',
</I>&gt;&gt;<i> credentials=creds))
</I>&gt;&gt;<i>     chan  = conn.channel()
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     while True:
</I>&gt;&gt;<i>     chan.basic_publish(exchange='**simple_exchange',
</I>&gt;&gt;<i>     routing_key='simple_queue', body='',
</I>&gt;&gt;<i>     properties=pika.**BasicProperties(delivery_mode=**2))
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Consumer:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>       #!/usr/bin/python
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     import pika
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     def callback(chan, method, properties, body):
</I>&gt;&gt;<i>          chan.basic_ack(delivery_tag=**method.delivery_tag,
</I>&gt;&gt;<i> multiple=False)
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     creds = pika.PlainCredentials('guest',**'guest')
</I>&gt;&gt;<i>     conn  =
</I>&gt;&gt;<i>     pika.BlockingConnection(pika.**ConnectionParameters(host='10.**10.1.123',
</I>&gt;&gt;<i> credentials=creds))
</I>&gt;&gt;<i>     chan  = conn.channel()
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>     chan.basic_consume(callback, queue='simple_queue', no_ack=False)
</I>&gt;&gt;<i>     chan.basic_qos(prefetch_count=**1000)
</I>&gt;&gt;<i>     chan.start_consuming()
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I spawn multiple processes for the producers and multiple for the
</I>&gt;&gt;<i> consumer (so there is no python interpreter locking issues since each
</I>&gt;&gt;<i> runs in its own interpreter instance).  I'm using an an Amazon
</I>&gt;&gt;<i> *c1.xlarge *(8 virtual cores and &quot;high&quot; IO) Ubuntu 12.04 LTS instance
</I>&gt;&gt;<i> with RabbitMQ version 3.0.4-1 and an Amazon ephemeral disk (in
</I>&gt;&gt;<i> production we would use an EBS volume instead).  The queue is marked
</I>&gt;&gt;<i> *Durable* and my messages all use *delivery_mode* 2 (persist).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Below are the performance numbers.  For each test I use 2 publishers
</I>&gt;&gt;<i> processes and 6 consumer processes (where 3 different machines host 2
</I>&gt;&gt;<i> consumers each).  The producers and consumers are all on *separate*
</I>&gt;&gt;<i> machines from the rabbit node.  Throughput measurements were done using
</I>&gt;&gt;<i> the RabbitMQ management UI and linux utility top.  Python was compiled
</I>&gt;&gt;<i> to pyc files before running.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> *no_ack = True:*
</I>&gt;&gt;<i>      rate = 24,000/s
</I>&gt;&gt;<i>      single consumer CPU   =  65%
</I>&gt;&gt;<i>      single publisher CPU  =  80% (flow control enabled and being
</I>&gt;&gt;<i> enforced)
</I>&gt;&gt;<i>      (beam.smp) rabbit CPU = 400% (of 800%, 8 cores) -&gt; 0.0%wa 11.5%sy
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> *no_ack = False (manual acks per message):*
</I>&gt;&gt;<i>      rate =  5,500/s
</I>&gt;&gt;<i>      single consumer CPU   =  20%
</I>&gt;&gt;<i>      single publisher CPU  =  20% (flow control enabled and being
</I>&gt;&gt;<i> enforced)
</I>&gt;&gt;<i>      (beam.smp) rabbit CPU = 300% (of 800%, 8 cores) -&gt; 4.5%wa 10.0%sy
</I>&gt;&gt;<i> The most notable difference besides the throughput are the I/O waits
</I>&gt;&gt;<i> when ACKs are enabled (4.5% vs 0.0%).  This leads me to believe that the
</I>&gt;&gt;<i> rabbit node is being bottlenecked by performing I/O operations for ACK
</I>&gt;&gt;<i> bookkeeping.  The I/O doesn't appear to be a problem for persisting the
</I>&gt;&gt;<i> published messages since I'm *guessing* that rabbit is buffering those
</I>&gt;&gt;<i> and syncing them to disk in batches.  Does this mean the
</I>&gt;&gt;<i> acknowledgements are not also being buffered before synced with disk?
</I>&gt;&gt;<i>   Can I configure the rabbit node to change this behavior to help speed
</I>&gt;&gt;<i> up the acknowledgements?   I'm not using transactions in the example
</I>&gt;&gt;<i> code above, so I don't need any strict guarantees that ACKs were written
</I>&gt;&gt;<i> to disk before returning.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Thanks,
</I>&gt;&gt;<i> Karl
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> P.S. I wrote the same sample consumer code in Ruby to see if there was a
</I>&gt;&gt;<i> difference (in case there was a Python issue), but the numbers were
</I>&gt;&gt;<i> about the same.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> ______________________________**_________________
</I>&gt;&gt;<i> rabbitmq-discuss mailing list
</I>&gt;&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.</A>**rabbitmq.com&lt;<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>&gt;
</I>&gt;&gt;<i> <A HREF="https://lists.rabbitmq.com/**cgi-bin/mailman/listinfo/**rabbitmq-discuss&lt;https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">https://lists.rabbitmq.com/**cgi-bin/mailman/listinfo/**rabbitmq-discuss&lt;https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>&gt;
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i> --
</I>&gt;<i> Simon MacMullen
</I>&gt;<i> RabbitMQ, VMware
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20130426/c926a931/attachment.htm">http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20130426/c926a931/attachment.htm</A>&gt;
</PRE>



<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="026702.html">[rabbitmq-discuss] Durability and consumer acknowledgement extremely slow
</A></li>
	<LI>Next message: <A HREF="026690.html">[rabbitmq-discuss] Need Advice to solve the problem
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#26732">[ date ]</a>
              <a href="thread.html#26732">[ thread ]</a>
              <a href="subject.html#26732">[ subject ]</a>
              <a href="author.html#26732">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
