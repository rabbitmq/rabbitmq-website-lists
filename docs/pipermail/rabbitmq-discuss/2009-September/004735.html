<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] of queues, memory and heartbeats...
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=%5Brabbitmq-discuss%5D%20of%20queues%2C%20memory%20and%20heartbeats...&In-Reply-To=1bf8be120909010036lf5ad8e5r97801898214397%40mail.gmail.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="004734.html">
   <LINK REL="Next"  HREF="004737.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] of queues, memory and heartbeats...</H1>
    <B>Ben Hood</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=%5Brabbitmq-discuss%5D%20of%20queues%2C%20memory%20and%20heartbeats...&In-Reply-To=1bf8be120909010036lf5ad8e5r97801898214397%40mail.gmail.com"
       TITLE="[rabbitmq-discuss] of queues, memory and heartbeats...">0x6e6562 at gmail.com
       </A><BR>
    <I>Tue Sep  1 09:19:00 BST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="004734.html">[rabbitmq-discuss] of queues, memory and heartbeats...
</A></li>
        <LI>Next message: <A HREF="004737.html">[rabbitmq-discuss] of queues, memory and heartbeats...
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4735">[ date ]</a>
              <a href="thread.html#4735">[ thread ]</a>
              <a href="subject.html#4735">[ subject ]</a>
              <a href="author.html#4735">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Anthony,

On Tue, Sep 1, 2009 at 8:36 AM, Anthony&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">anthony-rabbitmq at hogan.id.au</A>&gt; wrote:
&gt;<i> We're in a particular situation where occasionally a client will be
</I>&gt;<i> disconnected from the server (often through some unclean network break, such
</I>&gt;<i> as the random stuff that can happen with 3G data links and virtual
</I>&gt;<i> machines), but the queues associated with that client don't die and continue
</I>&gt;<i> to grow.
</I>&gt;<i>
</I>&gt;<i> Eventually some of the queues grow so large, that we start seeing txamqp
</I>&gt;<i> (the client side library we use) start whining that it doesn't know what to
</I>&gt;<i> do with &quot;channel_flow&quot; - presumably this is the memory based throttling
</I>&gt;<i> kicking in (though I don't recall explicitly enabling it - unless it's
</I>&gt;<i> something auto-enabled by default in the .deb packages?)...
</I>
Although it is was written a while ago, the behavior it describes
w.r.t channel.flow is still current:

<A HREF="http://hopper.squarespace.com/blog/2008/11/9/flow-control-in-rabbitmq.html">http://hopper.squarespace.com/blog/2008/11/9/flow-control-in-rabbitmq.html</A>

However, the actual client library needs to be aware of the
channel.flow command (which is a reverse RPC from the client's
perspective). IIRC txamqp is based on the qpid python client - it
might be worth looking it that client's support for channel.flow (or
just ask the txamqp guys because I might be wrong).

&gt;<i> Even though we haven't explicitly enabled it, if we do start to see
</I>&gt;<i> channel_flow messages, this would be the memory based throttling, correct?
</I>
Yes. Exceeding a high water mark will trigger an alarm which then
sends out the channel flow command.

&gt;<i> Besides rabbit noticing when a TCP connection dies - is there any
</I>&gt;<i> &quot;heartbeat&quot; functionality built into rabbit and/or the AMQP spec that would
</I>&gt;<i> actually test whether or not a connection is active, and if it isn't, kill
</I>&gt;<i> the relevant queues?
</I>
There are heartbeats as part of the protocol, but would only propagate
a connection getting killed. This *may* kill queues, for example if
they are not marked as durable.

&gt;<i> Do I as the person who monitors the server configure
</I>&gt;<i> this, or do the programmers who write our clients need to incorporate
</I>&gt;<i> something into their code?
</I>
ATM the best why to monitor queues and connections is via rabbitmqctl,
which is an admin centric tool. There is very little exposed in the
client libraries on this matter.

&gt;<i> In calculating the &quot;5%&quot; of memory available threshold, what would rabbit be
</I>&gt;<i> considering memory.. Real? Swap? Virtual? All of the above?
</I>&gt;<i> Ie.
</I>&gt;<i> # cat /proc/meminfo | grep -i &quot;total\|free&quot;
</I>&gt;<i> MemTotal:&#160;&#160;&#160;&#160;&#160;&#160; 514056 kB
</I>&gt;<i> MemFree:&#160;&#160;&#160;&#160;&#160;&#160;&#160; 144860 kB
</I>&gt;<i> HighTotal:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 0 kB
</I>&gt;<i> HighFree:&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; 0 kB
</I>&gt;<i> LowTotal:&#160;&#160;&#160;&#160;&#160;&#160; 514056 kB
</I>&gt;<i> LowFree:&#160;&#160;&#160;&#160;&#160;&#160;&#160; 144860 kB
</I>&gt;<i> SwapTotal:&#160;&#160;&#160;&#160; 1044184 kB
</I>&gt;<i> SwapFree:&#160;&#160;&#160;&#160;&#160;&#160; 838244 kB
</I>&gt;<i> VmallocTotal:&#160;&#160; 442360 kB
</I>&gt;<i> HugePages_Total:&#160;&#160;&#160;&#160; 0
</I>&gt;<i> HugePages_Free:&#160;&#160;&#160;&#160;&#160; 0
</I>
The rabbit_memsup_linux module parses these values out of /proc/meminfo:

'MemTotal', 'MemFree', 'Buffers', 'Cached'

such that

MemUsed = MemTotal - MemFree - Buffers - Cached

&gt;<i> As a failsafe against runaway queues, I'm thinking of implementing something
</I>&gt;<i> that culls queues over a given order of magnitude on a timed basis, or
</I>&gt;<i> triggered by a lower memory threshold than rabbit's..
</I>
You might be interested in the new persister that is coming out in the
next release (there are many posts on this - google the archive for
queue paging). With this, you won't be bounded by memory any more.

On a similar note, recently we implemented a queue drain command as
part of the BQL plugin (which is dependent on the plugin mechanism
that is part of the next release) - for one system I just wrote a cron
job that drained the queue to a disk log every hour.

HTH,

Ben


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="004734.html">[rabbitmq-discuss] of queues, memory and heartbeats...
</A></li>
	<LI>Next message: <A HREF="004737.html">[rabbitmq-discuss] of queues, memory and heartbeats...
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4735">[ date ]</a>
              <a href="thread.html#4735">[ thread ]</a>
              <a href="subject.html#4735">[ subject ]</a>
              <a href="author.html#4735">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
