<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] RabbitMQ Stability Issues with large queue -	2011-12-28
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%20Stability%20Issues%20with%20large%20queue%20-%0A%092011-12-28&In-Reply-To=%3CE89E025C-D8EA-497C-9207-3E547338B0D4%40aol.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017041.html">
   <LINK REL="Next"  HREF="017050.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] RabbitMQ Stability Issues with large queue -	2011-12-28</H1>
    <B>DawgTool</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%20Stability%20Issues%20with%20large%20queue%20-%0A%092011-12-28&In-Reply-To=%3CE89E025C-D8EA-497C-9207-3E547338B0D4%40aol.com%3E"
       TITLE="[rabbitmq-discuss] RabbitMQ Stability Issues with large queue -	2011-12-28">dawgtool at aol.com
       </A><BR>
    <I>Wed Dec 28 22:20:20 GMT 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="017041.html">[rabbitmq-discuss] RabbitMQ Stability Issues with large queue -	2011-12-28
</A></li>
        <LI>Next message: <A HREF="017050.html">[rabbitmq-discuss] Possible bug when disposing connections in .NET	client 2.7.0/1
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17049">[ date ]</a>
              <a href="thread.html#17049">[ thread ]</a>
              <a href="subject.html#17049">[ subject ]</a>
              <a href="author.html#17049">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi All,

Ran the publisher against a single node (removed the clustering) and was able to grab the report just before crashing.
Here are the details:

==&gt; dc001.log &lt;==
=INFO REPORT==== 28-Dec-2011::17:00:00 ===
vm_memory_high_watermark set. Memory used:8662988728 allowed:5153960755

=INFO REPORT==== 28-Dec-2011::17:00:00 ===
    alarm_handler: {set,{{vm_memory_high_watermark,'<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>'},[]}}

=WARNING REPORT==== 28-Dec-2011::17:00:00 ===
Mnesia('<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>'): ** WARNING ** Mnesia is overloaded: {dump_log, time_threshold}




Reporting server status on {{2011,12,28},{22,6,3}}

Status of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>' ...
[{pid,13173},
 {running_applications,
     [{rabbitmq_management_visualiser,&quot;RabbitMQ Visualiser&quot;,&quot;2.7.0&quot;},
      {rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;2.7.0&quot;},
      {rabbitmq_mochiweb,&quot;RabbitMQ Mochiweb Embedding&quot;,&quot;2.7.0&quot;},
      {webmachine,&quot;webmachine&quot;,&quot;1.7.0-rmq2.7.0-hg&quot;},
      {amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;2.7.0&quot;},
      {rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,&quot;2.7.0&quot;},
      {rabbit,&quot;RabbitMQ&quot;,&quot;2.7.0&quot;},
      {mnesia,&quot;MNESIA  CXC 138 12&quot;,&quot;4.4.17&quot;},
      {os_mon,&quot;CPO  CXC 138 46&quot;,&quot;2.2.5&quot;},
      {sasl,&quot;SASL  CXC 138 11&quot;,&quot;2.1.9.3&quot;},
      {mochiweb,&quot;MochiMedia Web Server&quot;,&quot;1.3-rmq2.7.0-git&quot;},
      {inets,&quot;INETS  CXC 138 49&quot;,&quot;5.5.2&quot;},
      {stdlib,&quot;ERTS  CXC 138 10&quot;,&quot;1.17.3&quot;},
      {kernel,&quot;ERTS  CXC 138 10&quot;,&quot;2.14.3&quot;}]},
 {os,{unix,linux}},
 {erlang_version,
     &quot;Erlang R14B02 (erts-5.8.3) [source] [64-bit] [smp:2:2] [rq:2] [async-threads:30] [hipe] [kernel-poll:true]\n&quot;},
 {memory,
     [{total,8825539568},
      {processes,4061532008},
      {processes_used,4061085200},
      {system,4764007560},
      {atom,1677993},
      {atom_used,1659957},
      {binary,4448013416},
      {code,16452002},
      {ets,295062344}]},
 {vm_memory_high_watermark,0.5999999999767169},
 {vm_memory_limit,5153960755}]

Cluster status of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>' ...
[{nodes,[{disc,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>']}]},{running_nodes,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>']}]

Application environment of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>' ...
[{auth_backends,[rabbit_auth_backend_internal]},
 {auth_mechanisms,['PLAIN','AMQPLAIN']},
 {backing_queue_module,rabbit_variable_queue},
 {cluster_nodes,[]},
 {collect_statistics,fine},
 {collect_statistics_interval,5000},
 {default_permissions,[&lt;&lt;&quot;.*&quot;&gt;&gt;,&lt;&lt;&quot;.*&quot;&gt;&gt;,&lt;&lt;&quot;.*&quot;&gt;&gt;]},
 {default_user,&lt;&lt;&quot;guest&quot;&gt;&gt;},
 {default_user_tags,[administrator]},
 {default_vhost,&lt;&lt;&quot;/&quot;&gt;&gt;},
 {delegate_count,16},
 {error_logger,{file,&quot;/data/rabbitmq/dc001/log/dc001.log&quot;}},
 {frame_max,131072},
 {hipe_compile,true},
 {included_applications,[]},
 {msg_store_file_size_limit,16777216},
 {msg_store_index_module,rabbit_msg_store_ets_index},
 {queue_index_max_journal_entries,262144},
 {sasl_error_logger,{file,&quot;/data/rabbitmq/dc001/log/dc001-sasl.log&quot;}},
 {server_properties,[]},
 {ssl_listeners,[]},
 {ssl_options,[]},
 {tcp_listen_options,[binary,
                      {packet,raw},
                      {reuseaddr,true},
                      {backlog,128},
                      {nodelay,true},
                      {exit_on_close,false}]},
 {tcp_listeners,[5672]},
 {trace_vhosts,[]},
 {vm_memory_high_watermark,0.6}]

Connections:
pid	address	port	peer_address	peer_port	ssl	peer_cert_subject	peer_cert_issuer	peer_cert_validity	auth_mechanism	ssl_protocol	ssl_key_exchange	ssl_cipher	ssl_hash	protocol	user	vhost	timeout	frame_max	client_properties	recv_oct	recv_cnt	send_oct	send_cnt	send_pend	state	channels
&lt;'<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>'.1.4461.3&gt;	192.168.0.100	5672	192.168.0.97	33792	false				PLAIN					{0,8,0}	guest	/	0	131072	[]	79447230	86718	292	4	0	blocked	1

Channels:
pid	connection	number	user	vhost	transactional	confirm	consumer_count	messages_unacknowledged	messages_unconfirmed	messages_uncommitted	acks_uncommitted	prefetch_count	client_flow_blocked
&lt;'<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>'.1.4465.3&gt;	&lt;'<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>'.1.4461.3&gt;	1	guest	/	false	false	0	0	0	0	0	0	false

Queues on /:
pid	name	durable	auto_delete	arguments	owner_pid	slave_pids	synchronised_slave_pids	exclusive_consumer_pid	exclusive_consumer_tag	messages_ready	messages_unacknowledged	messages	consumers	memory	backing_queue_status
&lt;'<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>'.1.9112.0&gt;	dc.data:durable:all	true	false	[]						4589172	0	4589172	0	4041816264	[{q1,0}, {q2,0}, {delta,{delta,2667892,1921280,4589172}}, {q3,132544}, {q4,2535348}, {len,4589172}, {pending_acks,0}, {target_ram_count,0}, {ram_msg_count,2535348}, {ram_ack_count,0}, {next_seq_id,4589172}, {persistent_count,0}, {avg_ingress_rate,0.0}, {avg_egress_rate,0.0}, {avg_ack_ingress_rate,0.0}, {avg_ack_egress_rate,0.0}]

Exchanges on /:
name	type	durable	auto_delete	internal	arguments
amq.direct	direct	true	false	false	[]
dc.data:fanout	fanout	true	false	false	[]
amq.topic	topic	true	false	false	[]
amq.rabbitmq.trace	topic	true	false	false	[]
amq.rabbitmq.log	topic	true	false	false	[]
amq.fanout	fanout	true	false	false	[]
amq.headers	headers	true	false	false	[]
	direct	true	false	false	[]
amq.match	headers	true	false	false	[]

Bindings on /:
source_name	source_kind	destination_name	destination_kind	routing_key	arguments
	exchange	dc.data:durable:all	queue	dc.data:durable:all	[]
dc.data:fanout	exchange	dc.data:durable:all	queue		[]

Consumers on /:

Permissions on /:
user	configure	write	read
guest	.*	.*	.*

End of server status report
...done.




On Dec 28, 2011, at 9:22 AM, DawgTool wrote:

&gt;<i> RabbitMQ Stability Issues with large queue - 2011-12-28
</I>&gt;<i> 
</I>&gt;<i> Hi All,
</I>&gt;<i> 
</I>&gt;<i> I posted in the IRC channel a few nights ago, and they suggested that I bring this to the listserv.
</I>&gt;<i> Hopefully can get some suggestions on how to keep my servers from crashing.
</I>&gt;<i> Thanks,
</I>&gt;<i> -- DawgTool
</I>&gt;<i> 
</I>&gt;<i> Cluster Info:
</I>&gt;<i> Cluster status of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>' ...
</I>&gt;<i> [{nodes,[{disc,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m04</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m03</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m02</A>',
</I>&gt;<i>                '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>']}]},
</I>&gt;<i> {running_nodes,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m04</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m03</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m02</A>',
</I>&gt;<i>                 '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">dc001 at rmquat-m01</A>']}]
</I>&gt;<i> 
</I>&gt;<i> Config Info:
</I>&gt;<i> ==&gt; enabled_plugins &lt;==
</I>&gt;<i> [rabbitmq_management,rabbitmq_management_agent,rabbitmq_management_visualiser].
</I>&gt;<i> 
</I>&gt;<i> ==&gt; rabbitmq.config &lt;==
</I>&gt;<i> [
</I>&gt;<i>  {rabbit,                    [{vm_memory_high_watermark, 0.6},
</I>&gt;<i>                               {collect_statistics_interval, 5000},
</I>&gt;<i>                               {hipe_compile, true}
</I>&gt;<i>                              ]
</I>&gt;<i>  },
</I>&gt;<i>  {rabbitmq_management,       [ {http_log_dir, &quot;/data/rabbitmq/dc001/rabbit-mgmt&quot;} ] },
</I>&gt;<i>  {rabbitmq_management_agent, [ {force_fine_statistics, true} ] }
</I>&gt;<i> ].
</I>&gt;<i> 
</I>&gt;<i> ==&gt; rabbitmq-env.conf &lt;==
</I>&gt;<i> NODENAME=dc001
</I>&gt;<i> BASE=/data/rabbitmq/dc001
</I>&gt;<i> MNESIA_BASE=/data/rabbitmq/dc001/mnesia
</I>&gt;<i> LOG_BASE=/data/rabbitmq/dc001/log
</I>&gt;<i> SERVER_START_ARGS=&quot;-smp enable&quot;
</I>&gt;<i> 
</I>&gt;<i> 
</I>&gt;<i> IRC:
</I>&gt;<i> [17:32] &lt;dawgtool&gt; background. doing some testing on 2.7.0 : 4 servers 2vcpu, 8gb ram, 80gb disc.
</I>&gt;<i> [17:32] &lt;dawgtool&gt; cluser is setup all disc, currently one exchange durable fanout
</I>&gt;<i> [17:33] &lt;dawgtool&gt; one queue also durable bind to the exchange.
</I>&gt;<i> [17:33] &lt;dawgtool&gt; i'm pushing about 5M records, payload is ~500bytes each record
</I>&gt;<i> [17:34] &lt;dawgtool&gt; rate is about 14k/s (which seems pretty slow)
</I>&gt;<i> [17:35] &lt;dawgtool&gt; but my problem is, I'm testing a case where they consumers are busy or unavailable, so the queues would be filling up.
</I>&gt;<i> [17:35] &lt;dawgtool&gt; even after slowing the publish rate to about 4k/s the mirrored queue does not complete on any of the clusters nodes other then master.
</I>&gt;<i> [17:37] &lt;dawgtool&gt; memory seems to be the biggest issue here, as the servers will grow passed the high water mark, and eventually crash one at a time.
</I>&gt;<i> [17:37] &lt;dawgtool&gt; once they are restarted, most servers in the cluster will have about 200k to 300k of messages in their queue
</I>&gt;<i> [17:40] &lt;dawgtool&gt; so question is, why is so much memory being consumed (on disk these records are about 5.5GB) RabbitMQ pushes to 7.9 real, 11.9 virtual (swapping).
</I>&gt;<i> [17:40] &lt;dawgtool&gt; why is the queue not stopping the publishers (RAM based clusters seem to stop the publisher until it can be spilled to disk)
</I>&gt;<i> [17:41] &lt;dawgtool&gt; Why is mirroring unreliable in this test.
</I>&gt;<i> [17:41] &lt;dawgtool&gt; ok, i'm done with the backgroud. =)
</I>&gt;<i> [17:41] &lt;dawgtool&gt; lol
</I>&gt;<i> [17:42] &lt;antares_&gt; having 300K messages in one queue will result in RAM consumption like this
</I>&gt;<i> [17:42] &lt;antares_&gt; 30 queues with 10K is a better option
</I>&gt;<i> [17:43] &lt;antares_&gt; I can't say for mirroring but my understanding is that mirroring cannot decrease RAM usage
</I>&gt;<i> [17:43] &lt;dawgtool&gt; true, i need to make sure I don't loose any records, so disc with mirror
</I>&gt;<i> [17:44] &lt;dawgtool&gt; does performance get that bad after 300k message in a queue?
</I>&gt;<i> [17:44] &lt;antares_&gt; this kind of questions is better asked on the rabbitmq-discuss (mailing list)
</I>&gt;<i> [17:45] &lt;antares_&gt; the exact number will vary but yes, having queues with excessive # of messages that are not consumed will result in more or less this behavior
</I>&gt;<i> [17:45] &lt;dawgtool&gt; yea, just joined the mailing list, I can post it there. was hoping someone had a quick answer. =)
</I>&gt;<i> [17:45] &lt;antares_&gt; each queue is backed by one Erlang process and Erlang VM GC releases process memory all at once
</I>&gt;<i> [17:46] &lt;dawgtool&gt; even with the -smp set to true?
</I>&gt;<i> [17:46] &lt;antares_&gt; so having large amount of messages in your queues impedes that
</I>&gt;<i> [17:46] &lt;antares_&gt; dawgtool: I doubt that -smp affects GC behavior
</I>&gt;<i> [17:46] &lt;dawgtool&gt; hmmm
</I>&gt;<i> [17:47] &lt;antares_&gt; in this regard anyway, because there is still no shared heap
</I>&gt;<i> [17:47] &lt;antares_&gt; but rabbitmq team members definitely know more than I do
</I>&gt;<i> [17:47] &lt;antares_&gt; and they are all on rabbitmq-discuss
</I>&gt;<i> [17:48] &lt;dawgtool&gt; ok, I'll give the mailing list a shot.  300k is going to be hard to live under, one of my current systems is  doing server times that a second. =(
</I>&gt;<i> [17:49] &lt;dawgtool&gt; which i was hoping to migrate to a more open system, at least parts of it. =(
</I>&gt;<i> [17:49] &lt;antares_&gt; dawgtool: total # of messages is not the point
</I>&gt;<i> [17:50] &lt;antares_&gt; the point is max # of messages in one queue
</I>&gt;<i> [17:50] &lt;antares_&gt; you can have 10K queues and one app consuming messages from them all
</I>&gt;<i> [17:50] &lt;antares_&gt; unless ordering is a serious concern for your case, it will work just as well as 1 queue
</I>&gt;<i> [17:50] &lt;dawgtool&gt; yea, understand, but some consumers might crash, and I will get a backlog
</I>&gt;<i> [17:51] &lt;dawgtool&gt; I need to make sure the MQ system can handle at least a 30 minute outage
</I>&gt;<i> [17:51] &lt;antares_&gt; again, you will have the same problem with just 1 queue
</I>&gt;<i> [17:51] &lt;antares_&gt; dawgtool: I see. And not lose anything?
</I>&gt;<i> [17:51] &lt;dawgtool&gt; right, =(
</I>&gt;<i> [17:51] &lt;antares_&gt; rabbitmq queues can have message TTL
</I>&gt;<i> [17:52] &lt;dawgtool&gt; yea, I have TTL on metric collection consumers.. usually 6 seconds.
</I>&gt;<i> [17:55] &lt;dawgtool&gt; in production, the idea would be to have two exchanges: input.exchange.fanout, metric.exchange.topic bind to input.exchange.fanout. queue.durable.mirror.prod bind to input.exchange.fanout no ttl, several queue.trans.nomirror.metric[1-x] ttl 6sec.
</I>&gt;<i> [17:56] &lt;dawgtool&gt; the input.exchange.fanout will have a second and third queue eventually, which is why there are two exchanges.
</I>&gt;<i> [17:57] &lt;dawgtool&gt; but the second and third will have a 30min ttl
</I>&gt;<i> [18:01] &lt;dawgtool&gt; anyway, thanks for the info.. I'll shot an email out to the listserv and see if I get any bites. =)
</I>&gt;<i> [18:01] &lt;dawgtool&gt; thanks again. =)
</I>&gt;<i> [18:01] &lt;antares_&gt; dawgtool: no problem
</I>&gt;<i> 
</I>&gt;<i> 
</I>
</PRE>
















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="017041.html">[rabbitmq-discuss] RabbitMQ Stability Issues with large queue -	2011-12-28
</A></li>
	<LI>Next message: <A HREF="017050.html">[rabbitmq-discuss] Possible bug when disposing connections in .NET	client 2.7.0/1
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17049">[ date ]</a>
              <a href="thread.html#17049">[ thread ]</a>
              <a href="subject.html#17049">[ subject ]</a>
              <a href="author.html#17049">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
