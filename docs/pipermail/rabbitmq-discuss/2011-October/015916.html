<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] Queue depth and no. of consumers.
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Queue%20depth%20and%20no.%20of%20consumers.&In-Reply-To=%3C4EAECC82.4060004%40rabbitmq.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="015910.html">
   <LINK REL="Next"  HREF="015858.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] Queue depth and no. of consumers.</H1>
    <B>Simon MacMullen</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Queue%20depth%20and%20no.%20of%20consumers.&In-Reply-To=%3C4EAECC82.4060004%40rabbitmq.com%3E"
       TITLE="[rabbitmq-discuss] Queue depth and no. of consumers.">simon at rabbitmq.com
       </A><BR>
    <I>Mon Oct 31 16:27:46 GMT 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="015910.html">[rabbitmq-discuss] Queue depth and no. of consumers.
</A></li>
        <LI>Next message: <A HREF="015858.html">[rabbitmq-discuss] AMQP.BasicProperties
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#15916">[ date ]</a>
              <a href="thread.html#15916">[ thread ]</a>
              <a href="subject.html#15916">[ subject ]</a>
              <a href="author.html#15916">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 31/10/11 14:31, michael neidhardt wrote:
&gt;<i> With no QoS set, I assume each consumer fetches as many messages as
</I>&gt;<i> possible (whatever that means),
</I>&gt;<i> and 'queues' them itself.
</I>
Yes, although the &quot;queueing&quot; doesn't mean there's an explicit queue in 
the client. But messages can back up in networking buffers etc.

&gt;<i> I will try to set QoS/prefetch_count to 1,
</I>&gt;<i> though I seem to remember
</I>&gt;<i> having read that this can cause trouble. I would assume that it would
</I>&gt;<i> be no problem, have you got any thoughts on whether it's a good idea?
</I>
I don't see why it should cause trouble. Setting prefetch to 1 does mean 
that throughput will drop since the broker cannot deliver another 
message until the previous one has been acknowledged, so if throughput 
is a concern then you might set the prefetch to some larger number for 
less fairness but more performance.

In general setting the prefetch count is a good idea if you're concerned 
with fair distribution of messages.

&gt;<i> As I wrote earlier, we have a number (several thousand) of files to
</I>&gt;<i> process, each of which may contain up to several hundred thousand
</I>&gt;<i> records (around 2KB each).
</I>&gt;<i>
</I>&gt;<i> In an earlier test, I let the processes handling files push the ID of
</I>&gt;<i> each record to a queue.
</I>&gt;<i> (Simply add a publish to the above code after the ack). The consumer
</I>&gt;<i> for this queue (which uses autoack)
</I>
(Of course, setting prefetch doesn't do anything in noack mode since the 
server has no way to know how many messages have made it all the way to 
the client.)

&gt;<i> would do a lookup in a Postgresql
</I>&gt;<i> DB, and nothing else.
</I>&gt;<i> After about 50 million records, the vm_memory_high_watermark would be
</I>&gt;<i> set, and shortly after
</I>&gt;<i> that, I got&lt;&quot;timeout waiting for channel.flow_ok{active=false}&quot;,none}
</I>&gt;&gt;<i> . Eventually the whole system froze.
</I>&gt;<i> I guess this timeout is caused by my client not reacting to the flow
</I>&gt;<i> control from the RabbitMQ server. Is that correct? Unfortunately, the
</I>&gt;<i> client I use does not have methods for that. Should I expect to handle
</I>&gt;<i> this in normal operation, or could it be handled by a client for me?
</I>
I think you said you were using 1.8.1. Much has changed since then:

* We no longer use channel.flow to throttle producers since as you're 
seeing many clients did not implement it correctly / at all. We now use 
TCP backpressure instead.

* Prior to 2.0 all messages in all queues had to fit in memory. Messages 
are now paged to disk when memory is low.

So I would strongly advise you to upgrade to 2.6.1. It's available in 
our apt repository:

<A HREF="http://www.rabbitmq.com/debian.html">http://www.rabbitmq.com/debian.html</A>

&gt;<i> Oh, and the big question: Is it out of the question to handle approx.
</I>&gt;<i> 300 mill. messages (where payload is essentially a bigint) over a few
</I>&gt;<i> days?
</I>
That should be no big deal. My workstation can churn through that in a 
few hours.

Cheers, Simon

-- 
Simon MacMullen
RabbitMQ, VMware
</PRE>



<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="015910.html">[rabbitmq-discuss] Queue depth and no. of consumers.
</A></li>
	<LI>Next message: <A HREF="015858.html">[rabbitmq-discuss] AMQP.BasicProperties
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#15916">[ date ]</a>
              <a href="thread.html#15916">[ thread ]</a>
              <a href="subject.html#15916">[ subject ]</a>
              <a href="author.html#15916">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
