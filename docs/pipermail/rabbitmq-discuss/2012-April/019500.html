<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] What is the currently fastest way to stream messages?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20What%20is%20the%20currently%20fastest%20way%20to%20stream%0A%20messages%3F&In-Reply-To=%3C4F86B857.6000509%40rabbitmq.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="019499.html">
   <LINK REL="Next"  HREF="019496.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] What is the currently fastest way to stream messages?</H1>
    <B>Simon MacMullen</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20What%20is%20the%20currently%20fastest%20way%20to%20stream%0A%20messages%3F&In-Reply-To=%3C4F86B857.6000509%40rabbitmq.com%3E"
       TITLE="[rabbitmq-discuss] What is the currently fastest way to stream messages?">simon at rabbitmq.com
       </A><BR>
    <I>Thu Apr 12 12:11:19 BST 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="019499.html">[rabbitmq-discuss] What is the currently fastest way to stream messages?
</A></li>
        <LI>Next message: <A HREF="019496.html">[rabbitmq-discuss] Unable to use different .erlang.cookie file
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#19500">[ date ]</a>
              <a href="thread.html#19500">[ thread ]</a>
              <a href="subject.html#19500">[ subject ]</a>
              <a href="author.html#19500">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 12/04/12 07:30, Matt wrote:
&gt;<i> I am working on a project with one producer, one consumer that need to
</I>&gt;<i> pass messages over the localhost (inter-process). I am targeting C#
</I>&gt;<i> .Net4.5(4.0 also fine). I look for a way to published raw byte[] (size
</I>&gt;<i> of each 16 bytes) messages, but I can chunk up the byte[] into larger
</I>&gt;<i> sizes and send.
</I>
Chunking would definitely help; there is a certain byte overhead per 
message that is much more than 16 bytes, and there will be some routing 
work per message as well.

&gt;<i> The order of the sent messages must be preserved.
</I>
OK. Otherwise I would suggest parallelising.

&gt;<i> is there a way to go brokerless for throughput optimization,
</I>
Not with AMQP.

&gt;<i> can amqp message parsing be turned off (I
</I>&gt;<i> read its a major bottleneck and design flaw how the amqp parser works),
</I>
I'm not sure what this would mean. We don't parse AMQP message bodies, 
they're just binaries. But we parse the AMQP byte stream, we kind of 
have to.

Although it's a bottleneck I'm not sure I'd call it a flaw. As long as 
there's a protocol we will have to parse it, and IMHO AMQP is not so 
horrible for parsing (opinions may differ).

To remove parsing overhead it may be worth looking at Tony's new UDP 
exchange in raw mode, although (a) I don't know if he's been optimising 
it and (b) it's UDP.

&gt;<i> can I omit queues
</I>
If consumers keep up they will be mostly omitted anyway. Messages still 
have to pass through the queue process, but it doesn't enqueue / dequeue 
in this case.

You could set the immediate flag to ensure messages are never enqueued 
*but* since this is defined to send a basic.return whenever a message is 
dropped it has to do some synchronous stuff and is usually slower.

The next release will allow setting a message TTL of 0, which will 
ensure messages are never enqueued.

&gt;<i> will turning off ackq speed things up?
</I>
Definitely.

&gt;<i> Basically
</I>&gt;<i> anything than can get my throughput up is highly welcomed.
</I>
Other ideas: Enable HiPE (not available on Windows though) to make 
everything faster. Route via a fanout exchange for the cheapest routing 
logic.

But batching messages will help the most I suspect.

As always, the next release will contain some more performance 
enhancements...

&gt;<i> I understand
</I>&gt;<i> I will not be able to reach ZeroMQs throughput rates because its a
</I>&gt;<i> brokerless solution but I like RabbitMQ and its mature enough to run in
</I>&gt;<i> production and this pub/sub pattern is only one of the many other
</I>&gt;<i> message patterns that I use and where throughputs are not critical. But
</I>&gt;<i> this byte array stream is throughput critical and I would appreciate any
</I>&gt;<i> comments how to tune this.
</I>
Hopefully this gives you a clue. But RabbitMQ will never get as fast as 
ZeroMQ - ZeroMQ is just so minimal.

Cheers, Simon

-- 
Simon MacMullen
RabbitMQ, VMware
</PRE>




















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="019499.html">[rabbitmq-discuss] What is the currently fastest way to stream messages?
</A></li>
	<LI>Next message: <A HREF="019496.html">[rabbitmq-discuss] Unable to use different .erlang.cookie file
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#19500">[ date ]</a>
              <a href="thread.html#19500">[ thread ]</a>
              <a href="subject.html#19500">[ subject ]</a>
              <a href="author.html#19500">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
