<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] questions about distributed queue
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=%5Brabbitmq-discuss%5D%20questions%20about%20distributed%20queue&In-Reply-To=3b6ef0790908180647q1066d470wa4fe164d3212fe89%40mail.gmail.com">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="004579.html">
   <LINK REL="Next"  HREF="004608.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] questions about distributed queue</H1>
    <B>Alexis Richardson</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=%5Brabbitmq-discuss%5D%20questions%20about%20distributed%20queue&In-Reply-To=3b6ef0790908180647q1066d470wa4fe164d3212fe89%40mail.gmail.com"
       TITLE="[rabbitmq-discuss] questions about distributed queue">alexis.richardson at gmail.com
       </A><BR>
    <I>Wed Aug 19 14:06:12 BST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="004579.html">[rabbitmq-discuss] questions about distributed queue
</A></li>
        <LI>Next message: <A HREF="004608.html">[rabbitmq-discuss] questions about distributed queue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4596">[ date ]</a>
              <a href="thread.html#4596">[ thread ]</a>
              <a href="subject.html#4596">[ subject ]</a>
              <a href="author.html#4596">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Jim,

On Tue, Aug 18, 2009 at 2:47 PM, Jim Irrer&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">irrer at umich.edu</A>&gt; wrote:
&gt;<i>
</I>&gt;<i> To help load balancing, could the consumers be set up to, instead of round
</I>&gt;<i> robin,
</I>&gt;<i> simply each try to read from a common queue, and who ever gets there first
</I>&gt;<i> gets the message.
</I>&gt;<i> This would mean that each consumer only gets a message when they become
</I>&gt;<i> idle,
</I>&gt;<i> which seems like what would be wanted.
</I>
That's right.  If you attach N consumers to one queue, then they will
treat that as a shared resource, so that message consumption is
round-robined.

alexis




&gt;<i> On the producer side, if there were multiple queues, the producer would want
</I>&gt;<i> to
</I>&gt;<i> write to the queue with the least amount of messages on it.
</I>&gt;<i>
</I>&gt;<i> I'm trying to learn AMQP too and this has been an interesting discussion to
</I>&gt;<i> watch.
</I>&gt;<i>
</I>&gt;<i> Thanks,
</I>&gt;<i>
</I>&gt;<i> - Jim
</I>&gt;<i>
</I>&gt;<i> Jim Irrer &#160; &#160; <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">irrer at umich.edu</A> &#160; &#160; &#160; (734) 647-4409
</I>&gt;<i> University of Michigan Hospital Radiation Oncology
</I>&gt;<i> 519 W. William St. &#160; &#160; &#160; &#160; &#160; &#160; Ann Arbor, MI 48103
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> On Tue, Aug 18, 2009 at 9:18 AM, Paul Dix &lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">paul at pauldix.net</A>&gt; wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> All of that makes sense.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Let me give some more specifics about what I'm building and how I'm
</I>&gt;&gt;<i> hoping to use the messaging system. I'm doing a constant internet
</I>&gt;&gt;<i> crawl of sorts, twitter updates and everything else are in there. So
</I>&gt;&gt;<i> when something gets pulled down the document gets inserted into a
</I>&gt;&gt;<i> horizontally scalable key value store in the sky. I then want to send
</I>&gt;&gt;<i> a message through the system that this key/value has been
</I>&gt;&gt;<i> inserted/updated. This is being done by 20-100 boxes.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I then want that message to be grabbed by a consumer where some
</I>&gt;&gt;<i> processing will happen and probably some ranking, relevance and other
</I>&gt;&gt;<i> things get written to an index somewhere (also being done by a large
</I>&gt;&gt;<i> number of boxes).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> So for this specific case I'm using a direct exchange with a single
</I>&gt;&gt;<i> queue (no message persistence and don't bother keeping ordering).
</I>&gt;&gt;<i> Hundreds of producers are posting messages to the exchange with the
</I>&gt;&gt;<i> same routing key and hundreds of consumers are pulling off the queue.
</I>&gt;&gt;<i> It's the firehose thing. Each message has to be processed once by any
</I>&gt;&gt;<i> one of the hundreds of consumers.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I guess I was hoping for the flow management part to be handled by
</I>&gt;&gt;<i> Rabbit. It looks to me that if I want to scale past the ingress
</I>&gt;&gt;<i> capabilities of one queue or exchange I have to manage that on the
</I>&gt;&gt;<i> producer and consumer side.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I can create multiple exchanges and bind to the same queue if the
</I>&gt;&gt;<i> routing becomes the bottleneck, but then the producers need to round
</I>&gt;&gt;<i> robin between the exchanges.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> I can create multiple queues bound with different routing keys (flow1,
</I>&gt;&gt;<i> flow2) if the queue becomes the bottleneck, but then the producer
</I>&gt;&gt;<i> needs to know to round robin to the different routing keys and the
</I>&gt;&gt;<i> consumers need to check both queues.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> So in essence, when I mentioned scalability, it was a reference to
</I>&gt;&gt;<i> being able to transparently scale the messaging system to multiple
</I>&gt;&gt;<i> boxes. And more specifically, I want my hundreds of producers to post
</I>&gt;&gt;<i> messages to a single exchange with a single routing key. I want my
</I>&gt;&gt;<i> hundreds of consumers to be able to consume messages off a single
</I>&gt;&gt;<i> queue. I want the exchange and the queue to be scalable (in the
</I>&gt;&gt;<i> multi-box, multi-process sense) where the messaging system handles it.
</I>&gt;&gt;<i> I want the messaging system to be scalable like the key/value store is
</I>&gt;&gt;<i> scalable. Transparently across many boxes.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> There's really only one part of my system that has this requirement.
</I>&gt;&gt;<i> There are plenty of other aspects in which I'll use messaging and not
</I>&gt;&gt;<i> have these kinds of insane needs. As I work more with the system it's
</I>&gt;&gt;<i> likely that I'll want to use more complex routing logic. It's possible
</I>&gt;&gt;<i> I'll want to break updates from domains into separate message flows.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Thank you very much for being so helpful. Sorry for the lengthy response.
</I>&gt;&gt;<i> Paul
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On Tue, Aug 18, 2009 at 4:20 AM, Alexis
</I>&gt;&gt;<i> Richardson&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">alexis.richardson at gmail.com</A>&gt; wrote:
</I>&gt;&gt;<i> &gt; Paul,
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; On Mon, Aug 17, 2009 at 8:36 PM, Paul Dix&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">paul at pauldix.net</A>&gt; wrote:
</I>&gt;&gt;<i> &gt;&gt; Yeah, that's what I'm talking about. There will probably be upwards of
</I>&gt;&gt;<i> &gt;&gt; a few hundred producers and a few hundred consumers.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; Cool.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; So one question you need to answer is: do you want all the consumers
</I>&gt;&gt;<i> &gt; to receive the same messages? &#160;I.e.:
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; * are you aggregating all the producers into one 'firehose', and then
</I>&gt;&gt;<i> &gt; sending the whole firehose on to all connected consumers?
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; OR
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; * are you planning to in some way share messages out amongst connected
</I>&gt;&gt;<i> &gt; consumers, eg on a round robin basis
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; See more below re flow1, flow2...
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;&gt; The total ingress
</I>&gt;&gt;<i> &gt;&gt; is definitely what I'm most worried about right now.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; OK.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; Be aware that in high ingress rate cases you may be limited by the
</I>&gt;&gt;<i> &gt; client egress rate, which is strongly implementation and platform
</I>&gt;&gt;<i> &gt; dependent. &#160;Also, see Matthias' notes on testing performance, which
</I>&gt;&gt;<i> &gt; are googleable from the rabbitmq archives, if you want to run some
</I>&gt;&gt;<i> &gt; test cases at any point.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;&gt; Later, memory may
</I>&gt;&gt;<i> &gt;&gt; be a concern, but hopefully the consumers are pulling so quickly that
</I>&gt;&gt;<i> &gt;&gt; the queue never gets extremely large.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; Yep.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;&gt; Can you give me more specific details (or a pointer) to how the flow1,
</I>&gt;&gt;<i> &gt;&gt; flow2 thing work (both producer and consumer side)?
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; Sure.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; First you need to read up on what 'direct exchanges' are and how they
</I>&gt;&gt;<i> &gt; work in AMQP. &#160;I recommend Jason's intro to get you started:
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; <A HREF="http://blogs.digitar.com/jjww/2009/01/rabbits-and-warrens/">http://blogs.digitar.com/jjww/2009/01/rabbits-and-warrens/</A>
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; More background info can be found here: www.rabbitmq.com/how
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; In a nutshell, RabbitMQ will route any message it receives on to one
</I>&gt;&gt;<i> &gt; or more queues.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; Each queue lives on a node, and nodes are members of a cluster. &#160;You
</I>&gt;&gt;<i> &gt; can have one or more nodes per machine - a good guide is to have one
</I>&gt;&gt;<i> &gt; per core. &#160;You can send messages to any node in the cluster and they
</I>&gt;&gt;<i> &gt; will get routed to the right places (adding more nodes to a cluster is
</I>&gt;&gt;<i> &gt; how you scale ingress and availability).
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; The routing model is based on message routing keys: queues receive
</I>&gt;&gt;<i> &gt; messages whose routing keys match routing patterns (&quot;bindings&quot;). &#160;Note
</I>&gt;&gt;<i> &gt; that multiple queues can request messages matching the same key,
</I>&gt;&gt;<i> &gt; giving you 1-many pubsub. &#160;This is explained in Jason's article. &#160;I
</I>&gt;&gt;<i> &gt; suggest you use the 'direct exchange' routing model, in which each
</I>&gt;&gt;<i> &gt; message has one routing key, e.g.: &quot;flow1&quot;, &quot;flow2&quot;.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; Take a look at the article and let us know if it all makes sense.
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt; alexis
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i> &gt;&gt; Thanks,
</I>&gt;&gt;<i> &gt;&gt; Paul
</I>&gt;&gt;<i> &gt;&gt;
</I>&gt;&gt;<i> &gt;&gt; On Mon, Aug 17, 2009 at 2:32 PM, Alexis
</I>&gt;&gt;<i> &gt;&gt; Richardson&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">alexis.richardson at gmail.com</A>&gt; wrote:
</I>&gt;&gt;<i> &gt;&gt;&gt; On Mon, Aug 17, 2009 at 5:22 PM, Paul Dix&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">paul at pauldix.net</A>&gt; wrote:
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; So what exactly does option 1 look like?
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; It sounds like it's possible to have a queue with the same id on two
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; different nodes bound to the same exchange.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; Not quite. &#160;Same routing - two queues, two ids. &#160;Actually now that I
</I>&gt;&gt;<i> &gt;&gt;&gt; think about it that won't give you exactly what you need. &#160;More below.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; Will the exchange will
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; then round robin the messages to the two different queues? If so,
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; that's exactly what I'm looking for. I don't really care about order
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; on this queue.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; No it won't and that's why my suggestion was wrong.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; Round robin does occur when you have two consumers (clients) connected
</I>&gt;&gt;<i> &gt;&gt;&gt; to one queue. &#160;This WILL help you by draining the queue faster, if
</I>&gt;&gt;<i> &gt;&gt;&gt; memory is a limitation.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; If total ingress is the limitation you can increase that by splitting
</I>&gt;&gt;<i> &gt;&gt;&gt; the flow. &#160;Suppose you start with one queue bound once to one exchange
</I>&gt;&gt;<i> &gt;&gt;&gt; with key &quot;flow1&quot;. &#160;Then all messages with routing key flow1 will go to
</I>&gt;&gt;<i> &gt;&gt;&gt; that queue. &#160;When load is heavy, add a queue with key &quot;flow2&quot;, on a
</I>&gt;&gt;<i> &gt;&gt;&gt; second node. &#160;Then, alternate (if you prefer, randomly) between
</I>&gt;&gt;<i> &gt;&gt;&gt; routing keys flow1 and flow2. &#160;This will spread the load as you
</I>&gt;&gt;<i> &gt;&gt;&gt; require. &#160;And so on, for more queues.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; You can make this part of a load balancing layer on the server side,
</I>&gt;&gt;<i> &gt;&gt;&gt; so that clients don't have to be coded too much.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; Is this along the lines of what you need? &#160;Let me know, and I can
</I>&gt;&gt;<i> &gt;&gt;&gt; elaborate.
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt; alexis
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; Thanks,
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; Paul
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; On Mon, Aug 17, 2009 at 10:55 AM, Alexis
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt; Richardson&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">alexis.richardson at gmail.com</A>&gt; wrote:
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; Paul
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; On Mon, Aug 17, 2009 at 3:34 PM, Paul Dix&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">paul at pauldix.net</A>&gt; wrote:
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; Sorry for the confusion. I mean scalability on a single queue. Say
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; I
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; want to push 20k messages per second through a single queue. If a
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; single node can't handle that it seems I'm out of luck. That is, if
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; I'm understanding how things work.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; You can in principle just add more nodes to the cluster. &#160;More
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; details below.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; So I guess I'm not worried about total queue size, but queue
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; throughput (although size may become an issue, I'm not sure). It
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; seems
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; the solution is to split out across multiple queues, but I was
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; hoping
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; to avoid that since it will add a layer of complexity to my
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; producers
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; and consumers.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; 1. To maximise throughput, don't use persistence. &#160;To make it
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; bigger,
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; forget about ordering. &#160;So for example, you can easily have two
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; queues, one per node, subscribed to the same direct exchange with
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; the
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; same key, and you ought to double throughput (assuming all other
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; things being equal and fair).
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; 2. If you want to be both fast and 'reliable' (no loss of acked
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; messages), then add more queues and make them durable, and set
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; messages to be persistent.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; 3. If you want to preserve ordering, label each message with an ID
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; and
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; dedup at the endpoints. &#160;This does as you say, add some small noise
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; to
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; your producers and consumers, but the above two options 1 and 2, do
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; not.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; I don't think I understand how using Linux-HA with clustering would
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; lead to a splitting a single queue across multiple nodes. I'm not
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; familiar with HA, but it looked like it was a solution to provide a
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; replicated failover.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; You are right that HA techniques, indeed any kind of queue
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; replication
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; or replicated failover, will not help you here.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; What you want is 'flow over' ie. &quot;when load is high, make a new node
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; with the same routing info&quot;. &#160;This is certainly doable.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt; alexis
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; Thanks again,
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; Paul
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; On Mon, Aug 17, 2009 at 10:24 AM, Tony
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; Garnock-Jones&lt;<A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">tonyg at lshift.net</A>&gt; wrote:
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; Paul Dix wrote:
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Do you have a roadmap for when a scalable queue
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; will be available?
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; If by &quot;scalable&quot; you mean &quot;replicated&quot;, then that's available now,
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; by
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; configuration along the lines I hinted at in my previous message.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; Adding
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; clustering into the mix can help increase capacity, on top of that
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; (at a
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; certain cost in configuration complexity).
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; If instead you mean &quot;exceeding RAM+swap size&quot;, we're hoping to
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; have that
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; for the 1.7 release -- which ought to be out within a month or so.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; Just to give you a little more information on what I'm doing, I'm
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; building a live search/aggregation system. I'm hoping to push
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; updates
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; of a constant internet crawl through the messaging system so
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; workers
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; can analyze the content and build indexes as everything comes in.
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; Sounds pretty cool!
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; Tony
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; --
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; &#160;[][][] Tony Garnock-Jones &#160; &#160; | Mob: +44 (0)7905 974 211
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; &#160; [][] LShift Ltd &#160; &#160; &#160; &#160; &#160; &#160; | Tel: +44 (0)20 7729 7060
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt; &#160;[] &#160;[] <A HREF="http://www.lshift.net/">http://www.lshift.net/</A> | Email: <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">tonyg at lshift.net</A>
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; _______________________________________________
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; rabbitmq-discuss mailing list
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt; <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;&gt;
</I>&gt;&gt;<i> &gt;&gt;
</I>&gt;&gt;<i> &gt;
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;<i> rabbitmq-discuss mailing list
</I>&gt;&gt;<i> <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>
</I>&gt;&gt;<i> <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> rabbitmq-discuss mailing list
</I>&gt;<i> <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>
</I>&gt;<i> <A HREF="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>
</I>&gt;<i>
</I>&gt;<i>
</I>

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="004579.html">[rabbitmq-discuss] questions about distributed queue
</A></li>
	<LI>Next message: <A HREF="004608.html">[rabbitmq-discuss] questions about distributed queue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4596">[ date ]</a>
              <a href="thread.html#4596">[ thread ]</a>
              <a href="subject.html#4596">[ subject ]</a>
              <a href="author.html#4596">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
