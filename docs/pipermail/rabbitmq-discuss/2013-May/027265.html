<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] Someone else with a nodedown error
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Someone%20else%20with%20a%20nodedown%20error&In-Reply-To=%3CCACeek7FdaxzLoT365RhM%3Dc8S_29023NGp_BN%2B9ZgBoPuNzm3Gg%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="027033.html">
   <LINK REL="Next"  HREF="027271.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] Someone else with a nodedown error</H1>
    <B>Eric Berg</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Someone%20else%20with%20a%20nodedown%20error&In-Reply-To=%3CCACeek7FdaxzLoT365RhM%3Dc8S_29023NGp_BN%2B9ZgBoPuNzm3Gg%40mail.gmail.com%3E"
       TITLE="[rabbitmq-discuss] Someone else with a nodedown error">eric.berg at pardot.com
       </A><BR>
    <I>Thu May 16 20:09:58 BST 2013</I>
    <P><UL>
        <LI>Previous message: <A HREF="027033.html">[rabbitmq-discuss] Someone else with a nodedown error
</A></li>
        <LI>Next message: <A HREF="027271.html">[rabbitmq-discuss] Someone else with a nodedown error
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#27265">[ date ]</a>
              <a href="thread.html#27265">[ thread ]</a>
              <a href="subject.html#27265">[ subject ]</a>
              <a href="author.html#27265">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Thanks for the insight Tim. I ended up killing the the process before
receiving your email so I was unable to take advantage of your pro tips. We
subsequently upgraded our cluster to 3.1.0 on Erlang R15B03, and have run
into a slightly different problem. This appears to be unrelated, but I did
use your tips to gather as much information as possible.

Scenario:
A producer is sending messages to rabbit faster than they can be routed so
the connection goes under flow control. The flow control lasts long enough
so that our load balancer severs the connection. Before we understood that
the LB was our problem we would just retry socket write up to 10 times
before throwing an exception. In the end, our cluster now has 0 connections
yet it still has nearly 4000 channels (screen grab attached). Also, now I
am unable to stop_app on any node in the cluster without it hanging for, at
this point, over an hour.

Questions:
1. Should rabbit maintain channels without active connections? If not, has
anyone run into this before?
2. Is there any way to force kill these channels?
3. Is it a good practice for consumers to connect to rabbit via a load
balancer, or should that be for producers only? Are there any recommended
timeout settings?


Here are the results of some commands on the shell to the broker:


bash-4.1$ erl -sname debug -remsh <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>
{error_logger,{{2013,5,16},{14,44,36}},std_error,&quot;File operation error:
eacces. Target: .. Function: read_file_info. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./beam_lib.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./ram_file.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./standard_error.beam. Function: get_file. Process:
code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./supervisor_bridge.beam. Function: get_file. Process:
code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./user_sup.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./user_drv.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./group.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./edlin.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./io_lib.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./proplists.beam. Function: get_file. Process:
code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./io_lib_format.beam. Function: get_file. Process:
code_server.&quot;}
Erlang R15B03 (erts-5.9.3.1) [source] [64-bit] [smp:16:16]
[async-threads:0] [hipe] [kernel-poll:false]

{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./net.beam. Function: get_file. Process: code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./inet_gethost_native.beam. Function: get_file. Process:
code_server.&quot;}
{error_logger,{{2013,5,16},{14,44,37}},std_error,&quot;File operation error:
eacces. Target: ./kernel_config.beam. Function: get_file. Process:
code_server.&quot;}

=ERROR REPORT==== 16-May-2013::10:44:36 ===
File operation error: eacces. Target: .. Function: read_file_info. Process:
code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./beam_lib.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./ram_file.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./standard_error.beam. Function:
get_file. Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./supervisor_bridge.beam. Function:
get_file. Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./user_sup.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./user_drv.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./group.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
File operation error: eacces. Target: ./edlin.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::10:44:37 ===
{lost_messages,6}

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./error_logger_tty_h.beam. Function:
get_file. Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./calendar.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./io_lib_pretty.beam. Function:
get_file. Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./io.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./erl_scan.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./c.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./erl_eval.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./orddict.beam. Function: get_file.
Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./file_io_server.beam. Function:
get_file. Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./erl_posix_msg.beam. Function:
get_file. Process: code_server.

=ERROR REPORT==== 16-May-2013::14:44:37 ===
file:path_eval([&quot;.&quot;,&quot;/var/lib/rabbitmq&quot;],&quot;.erlang&quot;): permission denied

=ERROR REPORT==== 16-May-2013::14:44:37 ===
File operation error: eacces. Target: ./dist_util.beam. Function: get_file.
Process: code_server.
Eshell V5.9.3.1  (abort with ^G)




-------------------------------------------------

(<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>)1&gt; whereis(rabbit).
&lt;0.251.0&gt;


-------------------------------------------------

(<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>)2&gt; application:loaded_applications().
[{public_key,&quot;Public key infrastructure&quot;,&quot;0.17&quot;},
 {rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,
                            &quot;3.1.0&quot;},
 {os_mon,&quot;CPO  CXC 138 46&quot;,&quot;2.2.10&quot;},
 {amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;3.1.0&quot;},
 {mnesia,&quot;MNESIA  CXC 138 12&quot;,&quot;4.7.1&quot;},
 {rabbitmq_shovel,&quot;Data Shovel for RabbitMQ&quot;,&quot;3.1.0&quot;},
 {inets,&quot;INETS  CXC 138 49&quot;,&quot;5.9.2&quot;},
 {rabbitmq_federation,&quot;RabbitMQ Federation&quot;,&quot;3.1.0&quot;},
 {rabbitmq_web_dispatch,&quot;RabbitMQ Web Dispatcher&quot;,&quot;3.1.0&quot;},
 {rabbitmq_federation_management,&quot;RabbitMQ Federation Management&quot;,
                                 &quot;3.1.0&quot;},
 {rabbitmq_management_visualiser,&quot;RabbitMQ Visualiser&quot;,
                                 &quot;3.1.0&quot;},
 {kernel,&quot;ERTS  CXC 138 10&quot;,&quot;2.15.3&quot;},
 {crypto,&quot;CRYPTO version 2&quot;,&quot;2.2&quot;},
 {ssl,&quot;Erlang/OTP SSL application&quot;,&quot;5.1.2&quot;},
 {sasl,&quot;SASL  CXC 138 11&quot;,&quot;2.2.1&quot;},
 {rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;3.1.0&quot;},
 {mochiweb,&quot;MochiMedia Web Server&quot;,
           &quot;2.3.1-rmq3.1.0-gitd541e9a&quot;},
 {xmerl,&quot;XML parser&quot;,&quot;1.3.2&quot;},
 {rabbit,&quot;RabbitMQ&quot;,&quot;3.1.0&quot;},
 {stdlib,&quot;ERTS  CXC 138 10&quot;,&quot;1.18.3&quot;},
 {webmachine,&quot;webmachine&quot;,&quot;1.9.1-rmq3.1.0-git52e62bc&quot;}]


------------------------------------------------------------------------------------


(<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>)3&gt; application:which_applications().
** exception exit: {timeout,{gen_server,call,

[application_controller,which_applications]}}
     in function  gen_server:call/2 (gen_server.erl, line 180)


-----------------------------------------------------------------------------------

(<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>)4&gt; rabbit:stop().


-- This hangs indefinitely


------------------------------------------------------------------------------------

Perms on /var/lib/rabbitmq
drwxr-xr-x  3 rabbitmq rabbitmq 4096 May  1 07:15 rabbitmq




Thanks Tim et al.




On Thu, May 9, 2013 at 10:00 AM, Tim Watson &lt;<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">tim at rabbitmq.com</A>&gt; wrote:

&gt;<i> Hi,
</I>&gt;<i>
</I>&gt;<i> On 8 May 2013, at 18:22, Eric Berg wrote:
</I>&gt;<i>
</I>&gt;<i> I have ready through many of these nodedown error emails and of course
</I>&gt;<i> none of them seem to be exactly what I am experiencing.
</I>&gt;<i>
</I>&gt;<i> I have a 4 node cluster, and one of the nodes went offline according to
</I>&gt;<i> the cluster. This box has the following in the sasl log:
</I>&gt;<i>
</I>&gt;<i> =SUPERVISOR REPORT==== 7-May-2013::14:37:22 ===
</I>&gt;<i>      Supervisor: {&lt;0.11197.1096&gt;,
</I>&gt;<i>                                            rabbit_channel_sup_sup}
</I>&gt;<i>      Context:    shutdown_error
</I>&gt;<i>      Reason:     noproc
</I>&gt;<i>      Offender:   [{pid,&lt;0.11199.1096&gt;},
</I>&gt;<i>                   {name,channel_sup},
</I>&gt;<i>                   {mfa,{rabbit_channel_sup,start_link,[]}},
</I>&gt;<i>                   {restart_type,temporary},
</I>&gt;<i>                   {shutdown,infinity},
</I>&gt;<i>                   {child_type,supervisor}]
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> This simply indicates that and error occurred whilst a supervised process
</I>&gt;<i> was shutting down. It's not indicative of the whole node going down -
</I>&gt;<i> Erlang allows processes to crash and be restarted whilst the system is
</I>&gt;<i> running.
</I>&gt;<i>
</I>&gt;<i> *Yet in the regular rabbit log i can see that it was still accepting
</I>&gt;<i> connections up until 2:22AM the next day:*
</I>&gt;<i>
</I>&gt;<i> (last log entry)
</I>&gt;<i> =INFO REPORT==== 8-May-2013::02:22:26 ===
</I>&gt;<i> closing AMQP connection &lt;0.18267.1145&gt; (IPADDRESS:PORT -&gt; IPADDRESS:PORT)
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> So clearly that node didn't actually go offline. The 'nodedown' message in
</I>&gt;<i> the other clustered broker's logs does not necessarily mean that the node
</I>&gt;<i> in question crashed; This could, for example, be indicative of a net-split
</I>&gt;<i> or other connectivity failure.
</I>&gt;<i>
</I>&gt;<i> *Running rabbitmqctl status returns:*
</I>&gt;<i>
</I>&gt;<i> [<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">root at rabbit-box</A> rabbitmq]# rabbitmqctl status
</I>&gt;<i> Status of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>' ...
</I>&gt;<i> Error: unable to connect to node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>': nodedown
</I>&gt;<i>
</I>&gt;<i> DIAGNOSTICS
</I>&gt;<i> ===========
</I>&gt;<i>
</I>&gt;<i> nodes in question: ['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>']
</I>&gt;<i>
</I>&gt;<i> hosts, their running nodes and ports:
</I>&gt;<i> - rabbit-box: [{rabbit,13957},{rabbitmqctl2301,16508}]
</I>&gt;<i>
</I>&gt;<i> current node details:
</I>&gt;<i> - node name: '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmqctl2301 at rabbit-box</A>'
</I>&gt;<i> - home dir: /var/lib/rabbitmq
</I>&gt;<i> - cookie hash: qQwyFW90ZNbbrFvX1AtrxQ==
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Have you tried running this using `sudo' instead of as root? Is the
</I>&gt;<i> rabbitmq user's account and home folder in a consistent state? The security
</I>&gt;<i> cookie used for inter-node communications, which includes communication
</I>&gt;<i> between the temporary `rabbitmqctl' node and the broker, has to be the same
</I>&gt;<i> for all the peers.
</I>&gt;<i>
</I>&gt;<i> A couple of notes:
</I>&gt;<i> - Looking for a process run by rabbit show that it appears to still be
</I>&gt;<i> running
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Yes - as I said, there's no indication that this node actually died from
</I>&gt;<i> what you've said. However `rabbitmqctl` should be able to connect to
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A> at the very least.
</I>&gt;<i>
</I>&gt;<i> - Erlang cookie is the same on all nodes of the cluster, the cookie hash
</I>&gt;<i> is the same as well
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> If it's not the cookies then....
</I>&gt;<i>
</I>&gt;<i> - A traffic spike occurred right around the time of the last entry in the
</I>&gt;<i> rabbit log
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> It sounds like this could be a potential culprit. Can you provide any more
</I>&gt;<i> information about what happened? It could be that whilst the network was
</I>&gt;<i> saturated, the node in question got disconnected from the other nodes in
</I>&gt;<i> the cluster because it exceeded the &quot;net tick time&quot; and subsequently things
</I>&gt;<i> have started to go wrong. That shouldn't happen, viz the node should be
</I>&gt;<i> able to re-establish connectivity, but it's possible that something's gone
</I>&gt;<i> wrong here.
</I>&gt;<i>
</I>&gt;<i> What that doesn't explain is why you can't connect from rabbitmqctl. If
</I>&gt;<i> you `su rabbitmq', can you then run `erl -sname debug -remsh
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at rabbit-box</A>' to establish a shell into the running broker? If that
</I>&gt;<i> does work, then you can stop the rabbit application and then the node, as
</I>&gt;<i> follows:
</I>&gt;<i>
</I>&gt;<i> &gt; rabbit:stop().
</I>&gt;<i> ok
</I>&gt;<i> &gt; init:stop().
</I>&gt;<i>
</I>&gt;<i> But before you do, it might be worth evaluating a couple of other things
</I>&gt;<i> that might help us identify what's going on:
</I>&gt;<i>
</I>&gt;<i> (<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at iske</A>)1&gt; whereis(rabbit).
</I>&gt;<i> &lt;0.152.0&gt;
</I>&gt;<i> (<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at iske</A>)2&gt; application:loaded_applications().
</I>&gt;<i> [{os_mon,&quot;CPO  CXC 138 46&quot;,&quot;2.2.9&quot;},
</I>&gt;<i>  {rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,
</I>&gt;<i>                             &quot;0.0.0&quot;},
</I>&gt;<i>  {amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;0.0.0&quot;},
</I>&gt;<i>  etc ...
</I>&gt;<i>  ]
</I>&gt;<i> (<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at iske</A>)3&gt; application:which_applications().
</I>&gt;<i> [{rabbitmq_shovel_management,&quot;Shovel Status&quot;,&quot;0.0.0&quot;},
</I>&gt;<i>  etc ...
</I>&gt;<i> ]
</I>&gt;<i>
</I>&gt;<i> If during any of these you get stuck, CTRL-C (and press the key for
</I>&gt;<i> 'abort') should get you back out again without incident.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> - I can find no other errors in any logs that relate to rabbit or erlang
</I>&gt;<i> - Up until this point the cluster has been running fine for over 40 days.
</I>&gt;<i>
</I>&gt;<i> - telnet IP_ADDRESS 5672 times out
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> So the broker is no longer accepting new AMQP connections then.
</I>&gt;<i> Something's clearly quite wrong with this node.
</I>&gt;<i>
</I>&gt;<i> - I have not restarted the box, erlang node, or entire rabbitmq-server
</I>&gt;<i>
</I>&gt;<i> Is there anywhere else I can go looking for errors? I am about to start
</I>&gt;<i> killing processs, but Im not sure that will solve anything.
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> Did you do that in the end? If not, I would really like to get to the
</I>&gt;<i> bottom of what's wrong with this node. I don't suppose it would be possible
</I>&gt;<i> for you to give us access to this machine would it? If necessary, we may be
</I>&gt;<i> able to get some kind of confidentiality agreement signed if that'd help.
</I>&gt;<i>
</I>&gt;<i> Cheers,
</I>&gt;<i>
</I>&gt;<i> Tim Watson
</I>&gt;<i> Staff Engineer
</I>&gt;<i> RabbitMQ
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> rabbitmq-discuss mailing list
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>
</I>&gt;<i>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20130516/31b6b51a/attachment.htm">http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20130516/31b6b51a/attachment.htm</A>&gt;
-------------- next part --------------
A non-text attachment was scrubbed...
Name: rabbit-manychannels.png
Type: image/png
Size: 127694 bytes
Desc: not available
URL: &lt;<A HREF="http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20130516/31b6b51a/attachment.png">http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20130516/31b6b51a/attachment.png</A>&gt;
</PRE>




<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="027033.html">[rabbitmq-discuss] Someone else with a nodedown error
</A></li>
	<LI>Next message: <A HREF="027271.html">[rabbitmq-discuss] Someone else with a nodedown error
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#27265">[ date ]</a>
              <a href="thread.html#27265">[ thread ]</a>
              <a href="subject.html#27265">[ subject ]</a>
              <a href="author.html#27265">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
