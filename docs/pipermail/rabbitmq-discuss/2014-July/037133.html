<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] Memory not flushing?
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Memory%20not%20flushing%3F&In-Reply-To=%3C53BE69DC.4080102%40rabbitmq.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="037128.html">
   <LINK REL="Next"  HREF="037129.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] Memory not flushing?</H1>
    <B>Simon MacMullen</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Memory%20not%20flushing%3F&In-Reply-To=%3C53BE69DC.4080102%40rabbitmq.com%3E"
       TITLE="[rabbitmq-discuss] Memory not flushing?">simon at rabbitmq.com
       </A><BR>
    <I>Thu Jul 10 11:24:28 BST 2014</I>
    <P><UL>
        <LI>Previous message: <A HREF="037128.html">[rabbitmq-discuss] Memory not flushing?
</A></li>
        <LI>Next message: <A HREF="037129.html">[rabbitmq-discuss] Updated RabbitMQ Monitoring for Zabbix
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#37133">[ date ]</a>
              <a href="thread.html#37133">[ thread ]</a>
              <a href="subject.html#37133">[ subject ]</a>
              <a href="author.html#37133">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>I think Michael already answered your real question - you are running 
into the msg store index using all memory. But to answer some of your 
sub-questions...

On 09/07/2014 8:22PM, Jason McIntosh wrote:
&gt;<i> I saw this message:
</I>&gt;<i> <A HREF="http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2013-April/026649.html">http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2013-April/026649.html</A>
</I>&gt;<i> But wasn't sure it applied since the ram counts are 0?
</I>
No, it doesn't. If the ram count is 0, all messages are paged out.

&gt;<i> If that's still
</I>&gt;<i> probably the issue, is there a way to set the target ram count to
</I>&gt;<i> something other than infinity?  e.g. rabbitmqctl set_paramter myqueue
</I>&gt;<i> target_ram_count 0.50?
</I>
The target ram count is managed automatically. Ultimately it's derived 
from vm_memory_high_watermark_paging_ratio, via a system which attempts 
to ensure that all queues get a fair share of memory, where &quot;fair&quot; is 
defined as &quot;slow-moving queues page out earlier than fast-moving queues, 
since they're slow anyway&quot;. It's a feedback-based system though, which 
means that if all queues are not accepting messages (i.e. when the 
memory alarm goes off) then it can end up saying &quot;infinity&quot;. If the 
queue started moving again that number would go down some (and it's 
clearly been 0 in the past, hence the ram_msg_count).

Cheers, Simon

&gt;<i> Below are the memory reports from a few place.
</I>&gt;<i> Thanks!
</I>&gt;<i> Jason
</I>&gt;<i>
</I>&gt;<i> #####
</I>&gt;<i> Memory report on the node via the api memory=true parameter:
</I>&gt;<i>
</I>&gt;<i>   *
</I>&gt;<i>     {
</I>&gt;<i>       o
</I>&gt;<i>         total: 14309117272,
</I>&gt;<i>       o
</I>&gt;<i>         connection_procs: 1406816,
</I>&gt;<i>       o
</I>&gt;<i>         queue_procs: 10781072,
</I>&gt;<i>       o
</I>&gt;<i>         plugins: 637448,
</I>&gt;<i>       o
</I>&gt;<i>         other_proc: 9246264,
</I>&gt;<i>       o
</I>&gt;<i>         mnesia: 66312,
</I>&gt;<i>       o
</I>&gt;<i>         mgmt_db: 316096,
</I>&gt;<i>       o
</I>&gt;<i>         msg_index: 12411588360,
</I>&gt;<i>       o
</I>&gt;<i>         other_ets: 1844522120,
</I>&gt;<i>       o
</I>&gt;<i>         binary: 9166464,
</I>&gt;<i>       o
</I>&gt;<i>         code: 17795943,
</I>&gt;<i>       o
</I>&gt;<i>         atom: 1619705,
</I>&gt;<i>       o
</I>&gt;<i>         other_system: 1970672
</I>&gt;<i>     },
</I>&gt;<i>   *
</I>&gt;<i>     partitions: [ ],
</I>&gt;<i>   *
</I>&gt;<i>     os_pid: &quot;23782&quot;,
</I>&gt;<i>   *
</I>&gt;<i>     fd_used: 53,
</I>&gt;<i>   *
</I>&gt;<i>     fd_total: 1024,
</I>&gt;<i>   *
</I>&gt;<i>     sockets_used: 27,
</I>&gt;<i>   *
</I>&gt;<i>     sockets_total: 829,
</I>&gt;<i>   *
</I>&gt;<i>     mem_used: 14309008432,
</I>&gt;<i>   *
</I>&gt;<i>     mem_limit: 1682936627,
</I>&gt;<i>   *
</I>&gt;<i>     mem_alarm: true,
</I>&gt;<i>   *
</I>&gt;<i>     disk_free_limit: 50000000,
</I>&gt;<i>   *
</I>&gt;<i>     disk_free: 362680954880,
</I>&gt;<i>   *
</I>&gt;<i>     disk_free_alarm: false,
</I>&gt;<i>   *
</I>&gt;<i>     proc_used: 472,
</I>&gt;<i>   *
</I>&gt;<i>     proc_total: 1048576,
</I>&gt;<i>   *
</I>&gt;<i>     statistics_level: &quot;fine&quot;,
</I>&gt;<i>   *
</I>&gt;<i>     uptime: 88779083,
</I>&gt;<i>   *
</I>&gt;<i>     run_queue: 0,
</I>&gt;<i>   *
</I>&gt;<i>     processors: 4,
</I>&gt;<i>   *
</I>&gt;<i>     exchange_types:
</I>&gt;<i>     [
</I>&gt;<i>
</I>&gt;<i> ####
</I>&gt;<i> Backing queue status from the queue (only one queue):
</I>&gt;<i>
</I>&gt;<i>   *
</I>&gt;<i>     backing_queue_status:
</I>&gt;<i>     {
</I>&gt;<i>       o
</I>&gt;<i>         q1: 0,
</I>&gt;<i>       o
</I>&gt;<i>         q2: 0,
</I>&gt;<i>       o
</I>&gt;<i>         delta:
</I>&gt;<i>         [
</I>&gt;<i>           +
</I>&gt;<i>             &quot;delta&quot;,
</I>&gt;<i>           +
</I>&gt;<i>             25034752,
</I>&gt;<i>           +
</I>&gt;<i>             101610341,
</I>&gt;<i>           +
</I>&gt;<i>             126670623
</I>&gt;<i>         ],
</I>&gt;<i>       o
</I>&gt;<i>         q3: 3667,
</I>&gt;<i>       o
</I>&gt;<i>         q4: 0,
</I>&gt;<i>       o
</I>&gt;<i>         len: 101614008,
</I>&gt;<i>       o
</I>&gt;<i>         pending_acks: 0,
</I>&gt;<i>       o
</I>&gt;<i>         target_ram_count: &quot;infinity&quot;,
</I>&gt;<i>       o
</I>&gt;<i>         ram_msg_count: 0,
</I>&gt;<i>       o
</I>&gt;<i>         ram_ack_count: 0,
</I>&gt;<i>       o
</I>&gt;<i>         next_seq_id: 126670623,
</I>&gt;<i>       o
</I>&gt;<i>         persistent_count: 101614008,
</I>&gt;<i>       o
</I>&gt;<i>         avg_ingress_rate: 6.316340263548813e-276,
</I>&gt;<i>       o
</I>&gt;<i>         avg_egress_rate: 0,
</I>&gt;<i>       o
</I>&gt;<i>         avg_ack_ingress_rate: 0,
</I>&gt;<i>       o
</I>&gt;<i>         avg_ack_egress_rate: 0
</I>&gt;<i>     },
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> rabbitmq-discuss mailing list has moved to <A HREF="https://groups.google.com/forum/#!forum/rabbitmq-users,">https://groups.google.com/forum/#!forum/rabbitmq-users,</A>
</I>&gt;<i> please subscribe to the new list!
</I>&gt;<i>
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>
</I>&gt;<i>
</I>
-- 
Simon MacMullen
RabbitMQ, Pivotal
</PRE>














<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="037128.html">[rabbitmq-discuss] Memory not flushing?
</A></li>
	<LI>Next message: <A HREF="037129.html">[rabbitmq-discuss] Updated RabbitMQ Monitoring for Zabbix
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#37133">[ date ]</a>
              <a href="thread.html#37133">[ thread ]</a>
              <a href="subject.html#37133">[ subject ]</a>
              <a href="author.html#37133">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
