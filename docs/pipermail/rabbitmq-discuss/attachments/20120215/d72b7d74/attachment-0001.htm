<tt>
|&nbsp;So&nbsp;I&nbsp;think&nbsp;this&nbsp;is&nbsp;really&nbsp;the&nbsp;key&nbsp;point.&nbsp;OK,&nbsp;I&nbsp;accept&nbsp;your&nbsp;use&nbsp;case&nbsp;:)&lt;br&gt;&lt;br&gt;Yeah,&nbsp;I&nbsp;figured&nbsp;I&nbsp;would&nbsp;have&nbsp;to&nbsp;go&nbsp;into&nbsp;some&nbsp;detail&nbsp;to&nbsp;get&nbsp;past&nbsp;the&nbsp;(usually&nbsp;reasonable)&nbsp;&amp;quot;don&amp;#39;t&nbsp;do&nbsp;that&amp;quot;&nbsp;round&nbsp;of&nbsp;responses.&nbsp;:-)&lt;br&gt;<br>
&lt;br&gt;Regardless,&nbsp;thank&nbsp;you&nbsp;much&nbsp;for&nbsp;accepting&nbsp;the&nbsp;use&nbsp;case&nbsp;and&nbsp;plowing&nbsp;forward&nbsp;with&nbsp;the&nbsp;perf&nbsp;question.&lt;br&gt;&lt;br&gt;&lt;br&gt;|&nbsp;I&nbsp;assume&nbsp;that&nbsp;this&nbsp;is&nbsp;not&nbsp;how&nbsp;you&nbsp;plan&nbsp;to&nbsp;go&nbsp;into&nbsp;production,&nbsp;you&nbsp;are&nbsp;<br>
just&nbsp;testing&nbsp;how&nbsp;fast&nbsp;you&nbsp;can&nbsp;go&nbsp;if&nbsp;disk&nbsp;speed&nbsp;is&nbsp;not&nbsp;an&nbsp;issue?&lt;br&gt;&lt;br&gt;Correct.&nbsp;:-)&lt;br&gt;&lt;br&gt;&lt;br&gt;|&nbsp;The&nbsp;real&nbsp;issue&nbsp;though&nbsp;is&nbsp;going&nbsp;to&nbsp;be&nbsp;latency&nbsp;from&nbsp;client&nbsp;to&nbsp;server.&nbsp;What&nbsp;does&nbsp;that&nbsp;look&nbsp;like?&lt;br&gt;&lt;br&gt;I&amp;#39;m&nbsp;still&nbsp;poking&nbsp;at&nbsp;this,&nbsp;trying&nbsp;to&nbsp;get&nbsp;a&nbsp;concrete&nbsp;answer&nbsp;from&nbsp;the&nbsp;maze&nbsp;of&nbsp;available&nbsp;tools.&nbsp;All&nbsp;the&nbsp;VMs&nbsp;are&nbsp;using&nbsp;VMXNET3&nbsp;and&nbsp;exhibit&nbsp;amazing&nbsp;perf&nbsp;between&nbsp;each&nbsp;other&nbsp;using&nbsp;netperf.&lt;br&gt;<br>
&lt;br&gt;HOWEVER...&nbsp;one&nbsp;data&nbsp;point&nbsp;tends&nbsp;to&nbsp;take&nbsp;client/broker&nbsp;latency&nbsp;out&nbsp;of&nbsp;the&nbsp;question:&lt;br&gt;&lt;br&gt;If&nbsp;I&nbsp;remove&nbsp;the&nbsp;clustering,&nbsp;so&nbsp;as&nbsp;to&nbsp;just&nbsp;hit&nbsp;a&nbsp;single&nbsp;broker,&nbsp;the&nbsp;rate&nbsp;goes&nbsp;up&nbsp;to&nbsp;900&nbsp;message/sec.&nbsp;Thus,&nbsp;I&amp;#39;m&nbsp;directed&nbsp;back&nbsp;to&nbsp;looking&nbsp;for&nbsp;latency&nbsp;between&nbsp;the&nbsp;master/slaves.&lt;br&gt;<br>
&lt;br&gt;One&nbsp;other&nbsp;potentially&nbsp;interesting&nbsp;data&nbsp;point:&nbsp;With&nbsp;2&nbsp;slaves,&nbsp;the&nbsp;message&nbsp;rate&nbsp;is&nbsp;only&nbsp;very&nbsp;slightly&nbsp;degraded&nbsp;from&nbsp;1&nbsp;slave,&nbsp;i.e.&nbsp;37/second&nbsp;with&nbsp;1&nbsp;slave,&nbsp;and&nbsp;36/sec&nbsp;with&nbsp;two.&nbsp;I&nbsp;assume&nbsp;the&nbsp;slave&nbsp;synchronization&nbsp;is&nbsp;done&nbsp;in&nbsp;parallel,&nbsp;so&nbsp;this&nbsp;isn&amp;#39;t&nbsp;totally&nbsp;surprising.&lt;br&gt;<br>
&lt;br&gt;Matt&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Wed,&nbsp;Feb&nbsp;15,&nbsp;2012&nbsp;at&nbsp;9:36&nbsp;AM,&nbsp;Simon&nbsp;MacMullen&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&amp;lt;&lt;a&nbsp;href=&quot;mailto:simon@rabbitmq.com&quot;&gt;simon@rabbitmq.com&lt;/a&gt;&amp;gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
&lt;div&nbsp;class=&quot;im&quot;&gt;On&nbsp;15/02/12&nbsp;17:15,&nbsp;Matt&nbsp;Pietrek&nbsp;wrote:&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
Thanks&nbsp;Simon.&nbsp;The&nbsp;5%&nbsp;figure&nbsp;is&nbsp;useful&nbsp;for&nbsp;me.&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
Cheers.&nbsp;Bear&nbsp;in&nbsp;mind&nbsp;that&amp;#39;s&nbsp;just&nbsp;my&nbsp;guess,&nbsp;and&nbsp;it&amp;#39;s&nbsp;also&nbsp;dependent&nbsp;on&nbsp;your&nbsp;situation&nbsp;being&nbsp;CPU-bound&nbsp;-&nbsp;which&nbsp;it&nbsp;sounds&nbsp;like&nbsp;you&nbsp;aren&amp;#39;t.&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;&lt;div&nbsp;class=&quot;im&quot;&gt;<br>
Let&nbsp;me&nbsp;give&nbsp;you&nbsp;a&nbsp;more&nbsp;precise&nbsp;description&nbsp;of&nbsp;what&nbsp;I&amp;#39;m&nbsp;doing&nbsp;to&nbsp;get&nbsp;the&lt;br&gt;<br>
36&nbsp;message/sec.&lt;br&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
&nbsp; &nbsp; *&nbsp;RabbitMQ&nbsp;2.71&nbsp;on&nbsp;a&nbsp;3-node&nbsp;cluster&nbsp;with&nbsp;mirrored&nbsp;queues,&nbsp;durable&nbsp;on&lt;br&gt;<br>
&nbsp; &nbsp; &nbsp; all&nbsp;nodes.&lt;br&gt;<br>
&nbsp; &nbsp; *&nbsp;Client&nbsp;is&nbsp;Python&nbsp;2.6/Pika&nbsp;0.9.5.&lt;br&gt;<br>
&nbsp; &nbsp; *&nbsp;Each&nbsp;message&nbsp;publish&nbsp;occurs&nbsp;in&nbsp;a&nbsp;transaction&nbsp;so&nbsp;that&nbsp;we&nbsp;can&nbsp;be&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&nbsp; &nbsp; &nbsp; sure&nbsp;it&amp;#39;s&nbsp;safely&nbsp;in&nbsp;RabbitMQ.&lt;br&gt;&lt;/div&gt;<br>
&nbsp; &nbsp; *&nbsp;All&nbsp;nodes&nbsp;are&nbsp;Ubuntu&nbsp;10.04&nbsp;VMs&nbsp;with&nbsp;4GB&nbsp;RAM&nbsp;and&nbsp;2&nbsp;or&nbsp;4&nbsp;vCPUs.&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
At&nbsp;the&nbsp;heart&nbsp;of&nbsp;things,&nbsp;we&amp;#39;re&nbsp;driving&nbsp;a&nbsp;highly&nbsp;complex&nbsp;state&nbsp;machine&lt;br&gt;<br>
that&nbsp;manages&nbsp;thousands&nbsp;of&nbsp;VMs&nbsp;and&nbsp;their&nbsp;associated&nbsp;state.&nbsp;Losing&nbsp;track&lt;br&gt;<br>
of&nbsp;any&nbsp;state&nbsp;is&nbsp;prohibitively&nbsp;expensive&nbsp;to&nbsp;clean&nbsp;up&nbsp;manually.&nbsp;As&nbsp;such,&lt;br&gt;<br>
all&nbsp;state&nbsp;is&nbsp;modeled&nbsp;in&nbsp;clustered&nbsp;databases&nbsp;and/or&nbsp;persistent&nbsp;messages&lt;br&gt;<br>
in&nbsp;the&nbsp;message&nbsp;queue.&nbsp;We&nbsp;have&nbsp;to&nbsp;assume&nbsp;that&nbsp;a&nbsp;given&nbsp;client&nbsp;app&nbsp;instance&lt;br&gt;<br>
(our&nbsp;management&nbsp;code)&nbsp;may&nbsp;be&nbsp;ungracefully&nbsp;terminated&nbsp;at&nbsp;any&nbsp;moment,&nbsp;so&lt;br&gt;<br>
enough&nbsp;state&nbsp;must&nbsp;be&nbsp;modeled&nbsp;to&nbsp;let&nbsp;a&nbsp;new&nbsp;instance&nbsp;pick&nbsp;up&nbsp;and&nbsp;recover.&lt;br&gt;<br>
If&nbsp;our&nbsp;database&nbsp;record&nbsp;indicates&nbsp;that&nbsp;a&nbsp;message&nbsp;has&nbsp;been&nbsp;sent,&nbsp;it&nbsp;better&lt;br&gt;<br>
darn&nbsp;well&nbsp;be&nbsp;in&nbsp;the&nbsp;hands&nbsp;of&nbsp;the&nbsp;RabbitMQ&nbsp;broker,&nbsp;and&nbsp;not&nbsp;sitting&nbsp;in&lt;br&gt;<br>
some&nbsp;Pika&nbsp;client-side&nbsp;queue.&lt;br&gt;<br>
&lt;br&gt;<br>
For&nbsp;this&nbsp;reasons,&nbsp;publisher-confirms&nbsp;are&nbsp;not&nbsp;particularly&nbsp;helpful&nbsp;-&nbsp;They&lt;br&gt;<br>
assume&nbsp;that&nbsp;the&nbsp;client&nbsp;app&nbsp;will&nbsp;be&nbsp;around&nbsp;to&nbsp;resend&nbsp;the&nbsp;message&nbsp;if&nbsp;the&lt;br&gt;<br>
message&nbsp;doesn&amp;#39;t&nbsp;get&nbsp;confirmed.&nbsp;Similar&nbsp;story&nbsp;for&nbsp;batching&nbsp;messages.&nbsp;We&lt;br&gt;<br>
have&nbsp;to&nbsp;know&nbsp;they&amp;#39;ve&nbsp;been&nbsp;sent,&nbsp;and&lt;br&gt;<br>
&lt;/div&gt;&lt;/blockquote&gt;<br>
&lt;br&gt;<br>
OK.&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
we&nbsp;can&amp;#39;t&nbsp;stall&nbsp;our&nbsp;state&nbsp;machine&lt;br&gt;<br>
waiting&nbsp;for&nbsp;enough&nbsp;message&nbsp;to&nbsp;accumulate&nbsp;to&nbsp;publish&nbsp;multiple&nbsp;messages&nbsp;at&lt;br&gt;<br>
once.&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
So&nbsp;I&nbsp;think&nbsp;this&nbsp;is&nbsp;really&nbsp;the&nbsp;key&nbsp;point.&nbsp;OK,&nbsp;I&nbsp;accept&nbsp;your&nbsp;use&nbsp;case&nbsp;:)&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
My&nbsp;goal&nbsp;in&nbsp;my&nbsp;latest&nbsp;round&nbsp;of&nbsp;experiments&nbsp;is&nbsp;to&nbsp;see&nbsp;what&nbsp;the&nbsp;maximum&lt;br&gt;<br>
throughput&nbsp;of&nbsp;a&nbsp;highly&nbsp;available&nbsp;system&nbsp;is&nbsp;in&nbsp;optimal&nbsp;circumstances.&lt;br&gt;<br>
We&amp;#39;re&nbsp;perfectly&nbsp;willing&nbsp;to&nbsp;spend&nbsp;the&nbsp;money&nbsp;on&nbsp;high&nbsp;end&nbsp;SSDs&nbsp;and&lt;br&gt;<br>
networking&nbsp;equipment&nbsp;as&nbsp;necessary.&lt;br&gt;<br>
&lt;br&gt;<br>
To&nbsp;prototype&nbsp;what&nbsp;this&nbsp;perf&nbsp;level&nbsp;is,&nbsp;I&amp;#39;ve&nbsp;configured&nbsp;RabbitMQ&nbsp;with&nbsp;the&lt;br&gt;<br>
MNESIA&nbsp;directory&nbsp;pointing&nbsp;to&nbsp;a&nbsp;ramdisk&nbsp;(/tmp).&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
I&nbsp;assume&nbsp;that&nbsp;this&nbsp;is&nbsp;not&nbsp;how&nbsp;you&nbsp;plan&nbsp;to&nbsp;go&nbsp;into&nbsp;production,&nbsp;you&nbsp;are&nbsp;just&nbsp;testing&nbsp;how&nbsp;fast&nbsp;you&nbsp;can&nbsp;go&nbsp;if&nbsp;disk&nbsp;speed&nbsp;is&nbsp;not&nbsp;an&nbsp;issue?&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
I&amp;#39;ve&nbsp;configured&nbsp;all&nbsp;the&lt;br&gt;<br>
VMs&nbsp;with&nbsp;VMXNET3&nbsp;networking,&nbsp;am&nbsp;with&nbsp;16K&nbsp;blocks,&nbsp;are&nbsp;seeing&nbsp;bandwidth&nbsp;of&lt;br&gt;<br>
130MB/sec&nbsp;between&nbsp;VMs&nbsp;in&nbsp;the&nbsp;cluster.&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
The&nbsp;real&nbsp;issue&nbsp;though&nbsp;is&nbsp;going&nbsp;to&nbsp;be&nbsp;latency&nbsp;from&nbsp;client&nbsp;to&nbsp;server.&nbsp;What&nbsp;does&nbsp;that&nbsp;look&nbsp;like?&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex&quot;&gt;<br>
My&nbsp;test&nbsp;app&nbsp;simply&nbsp;writes&nbsp;6&nbsp;byte&nbsp;message,&nbsp;one&nbsp;at&nbsp;a&nbsp;time,&nbsp;as&nbsp;quickly&nbsp;as&lt;br&gt;<br>
it&nbsp;can.&nbsp;In&nbsp;monitoring&nbsp;the&nbsp;cluster&nbsp;nodes,&nbsp;I&amp;#39;m&nbsp;seeing&nbsp;very&nbsp;low&nbsp;CPU&nbsp;usage,&lt;br&gt;<br>
very&nbsp;few&nbsp;writes&nbsp;to&nbsp;the&nbsp;physical&nbsp;disk,&nbsp;and&nbsp;network&nbsp;operation&nbsp;rates&nbsp;of&lt;br&gt;<br>
about&nbsp;700/sec&nbsp;for&nbsp;the&nbsp;master&nbsp;node&nbsp;and&nbsp;350/sec&nbsp;for&nbsp;the&nbsp;client&nbsp;node.&lt;br&gt;<br>
&lt;br&gt;<br>
In&nbsp;short,&nbsp;there&amp;#39;s&nbsp;a&nbsp;bottleneck&nbsp;somewhere&nbsp;and&nbsp;it&amp;#39;s&nbsp;not&nbsp;obvious&nbsp;where.&lt;br&gt;<br>
I&amp;#39;ll&nbsp;try&nbsp;your&nbsp;suggestion&nbsp;about&nbsp;replacing&nbsp;tx.commit.&nbsp;Any&nbsp;other&nbsp;insight&nbsp;or&lt;br&gt;<br>
guidance&nbsp;would&nbsp;of&nbsp;course&nbsp;be&nbsp;very&nbsp;much&nbsp;appreciated.&nbsp;:-)&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
It&nbsp;sounds&nbsp;like&nbsp;you&nbsp;have&nbsp;already&nbsp;almost&nbsp;eliminated&nbsp;disk&nbsp;writes&nbsp;in&nbsp;practice,&nbsp;so&nbsp;my&nbsp;working&nbsp;assumption&nbsp;would&nbsp;be&nbsp;that&nbsp;it&amp;#39;s&nbsp;client&nbsp;-&amp;gt;&nbsp;server&nbsp;latency&nbsp;that&nbsp;is&nbsp;your&nbsp;issue.&lt;div&nbsp;class=&quot;HOEnZb&quot;&gt;&lt;div&nbsp;class=&quot;h5&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
Cheers,&nbsp;Simon&lt;br&gt;<br>
&lt;br&gt;<br>
--&nbsp;&lt;br&gt;<br>
Simon&nbsp;MacMullen&lt;br&gt;<br>
RabbitMQ,&nbsp;VMware&lt;br&gt;<br>
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;<br>

</tt>
