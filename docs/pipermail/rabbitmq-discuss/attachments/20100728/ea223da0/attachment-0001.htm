<tt>
&lt;br&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Sun,&nbsp;Jul&nbsp;25,&nbsp;2010&nbsp;at&nbsp;1:33&nbsp;AM,&nbsp;Dave&nbsp;Greggory&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&amp;lt;&lt;a&nbsp;href=&quot;mailto:davegreggory@yahoo.com&quot;&gt;davegreggory@yahoo.com&lt;/a&gt;&amp;gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:&nbsp;0pt&nbsp;0pt&nbsp;0pt&nbsp;0.8ex;&nbsp;border-left:&nbsp;1px&nbsp;solid&nbsp;rgb(204,&nbsp;204,&nbsp;204);&nbsp;padding-left:&nbsp;1ex;&quot;&gt;<br>
2.&nbsp;HA/Failover:&nbsp;I&amp;#39;ve&nbsp;seen&nbsp;the&nbsp;Pacemaker&nbsp;guide&nbsp;but&nbsp;I&amp;#39;m&nbsp;a&nbsp;little&nbsp;hesitant&nbsp;to&nbsp;set&lt;br&gt;<br>
that&nbsp;up&nbsp;as&nbsp;we&nbsp;have&nbsp;little&nbsp;experience&nbsp;in&nbsp;house&nbsp;with&nbsp;Pacemaker/Corosync/DRBD.&nbsp;How&lt;br&gt;<br>
many&nbsp;people&nbsp;use&nbsp;it&nbsp;for&nbsp;HA/Failover&nbsp;in&nbsp;production&nbsp;systems&nbsp;and&nbsp;how&nbsp;happy&nbsp;are&nbsp;you&lt;br&gt;<br>
with&nbsp;it?&nbsp;Does&nbsp;it&nbsp;support&nbsp;failing&nbsp;over&nbsp;if&nbsp;the&nbsp;hard&nbsp;drive&nbsp;on&nbsp;one&nbsp;of&nbsp;the&nbsp;nodes&nbsp;die&lt;br&gt;<br>
instead&nbsp;something&nbsp;a&nbsp;little&nbsp;more&nbsp;simple&nbsp;like&nbsp;a&nbsp;node&nbsp;running&nbsp;out&nbsp;of&nbsp;memory&nbsp;or&lt;br&gt;<br>
hanging?&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;We&nbsp;are&nbsp;contemplating&nbsp;this&nbsp;and&nbsp;have&nbsp;done&nbsp;some&nbsp;trialling/testing.&nbsp;For&nbsp;us&nbsp;the&nbsp;question&nbsp;is&nbsp;between&nbsp;providing&nbsp;HA&nbsp;at&nbsp;the&nbsp;xenserver&nbsp;level&nbsp;or&nbsp;at&nbsp;the&nbsp;host/app&nbsp;level&nbsp;using&nbsp;pacemaker&nbsp;etc.&lt;br&gt;&lt;br&gt;<br>
It&nbsp;took&nbsp;a&nbsp;little&nbsp;bit&nbsp;of&nbsp;fiddling&nbsp;to&nbsp;get&nbsp;it&nbsp;running&nbsp;with&nbsp;pacemaker&nbsp;(this&nbsp;was&nbsp;before&nbsp;the&nbsp;<br>
HA&nbsp;document&nbsp;was&nbsp;available),&nbsp;but&nbsp;once&nbsp;we&nbsp;had&nbsp;the&nbsp;system&nbsp;working,&nbsp;it&nbsp;<br>
worked/works&nbsp;well.&nbsp;Our&nbsp;solution&nbsp;used/uses&nbsp;shared&nbsp;ISCSI&nbsp;storage&nbsp;rather&nbsp;than&nbsp;DRDB&nbsp;and&nbsp;so&nbsp;relies&nbsp;on&nbsp;the&nbsp;reliability&nbsp;of&nbsp;the&nbsp;SAN.&nbsp;If&nbsp;a&nbsp;drive&nbsp;on&nbsp;one&nbsp;of&nbsp;the&nbsp;hosts&nbsp;fails&nbsp;(such&nbsp;as&nbsp;the&nbsp;root/other&nbsp;partition)&nbsp;and&nbsp;this&nbsp;causes&nbsp;difficulties&nbsp;for&nbsp;the&nbsp;status&nbsp;check&nbsp;script,&nbsp;it&nbsp;will&nbsp;failover&nbsp;to&nbsp;the&nbsp;other&nbsp;node.&nbsp;We&nbsp;assume&nbsp;that&nbsp;the&nbsp;drives&nbsp;containing&nbsp;the&nbsp;rabbitmq&nbsp;storage&nbsp;are&nbsp;&amp;quot;safe&amp;quot;&nbsp;through&nbsp;redundancy&nbsp;(RAID1,&nbsp;redundant&nbsp;storage&nbsp;controllers&nbsp;etc)&lt;br&gt;<br>
&lt;br&gt;At&nbsp;this&nbsp;stage&nbsp;we&nbsp;are&nbsp;leaning&nbsp;towards&nbsp;the&nbsp;xenserver&nbsp;level&nbsp;due&nbsp;to&nbsp;lower&nbsp;complexity&nbsp;and&nbsp;still&nbsp;satisfying&nbsp;our&nbsp;requirements.&nbsp;We&amp;#39;ve&nbsp;also&nbsp;had&nbsp;some&nbsp;hardware&nbsp;changes&nbsp;(production&nbsp;system&nbsp;will&nbsp;now&nbsp;be&nbsp;on&nbsp;a&nbsp;FC&nbsp;SAN&nbsp;rather&nbsp;than&nbsp;ISCSI)&nbsp;and&nbsp;have&nbsp;not&nbsp;done&nbsp;the&nbsp;work&nbsp;testing&nbsp;on&nbsp;the&nbsp;new&nbsp;configuration&nbsp;yet.&lt;br&gt;<br>
&lt;br&gt;In&nbsp;terms&nbsp;of&nbsp;monitoring,&nbsp;we&nbsp;generally&nbsp;run&nbsp;rabbitmq_ctl&nbsp;list_queues&nbsp;as&nbsp;part&nbsp;of&nbsp;a&nbsp;munin&nbsp;plugin.&nbsp;We&nbsp;plan&nbsp;to&nbsp;hook&nbsp;it&nbsp;up&nbsp;to&nbsp;nagios,&nbsp;but&nbsp;havent&nbsp;done&nbsp;so&nbsp;yet.&lt;br&gt;&lt;br&gt;Hope&nbsp;this&nbsp;is&nbsp;useful&nbsp;information.&lt;br&gt;&lt;br&gt;Joe&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/div&gt;<br>
&lt;/div&gt;<br>

</tt>
