<tt>
Don&amp;#39;t&nbsp;worry,&nbsp;I&amp;#39;m&nbsp;definitely&nbsp;the&nbsp;confused&nbsp;one&nbsp;:)&lt;br&gt;&lt;br&gt;I&amp;#39;m&nbsp;having&nbsp;a&nbsp;hard&nbsp;time&nbsp;finding&nbsp;info&nbsp;on&nbsp;the&nbsp;Active/Active&nbsp;HA&nbsp;in&nbsp;2.6.&nbsp; The&nbsp;FAQ&nbsp;and&nbsp;Clustering&nbsp;Guide&nbsp;led&nbsp;me&nbsp;to&nbsp;believe&nbsp;this&nbsp;feature&nbsp;didn&amp;#39;t&nbsp;exist&nbsp;yet.&nbsp; Do&nbsp;you&nbsp;know&nbsp;where&nbsp;I&nbsp;can&nbsp;find&nbsp;good&nbsp;info&nbsp;on&nbsp;this&nbsp;new&nbsp;feature?&lt;div&gt;<br>
&lt;br&gt;I&amp;#39;d&nbsp;say&nbsp;our&nbsp;main&nbsp;goal&nbsp;is&nbsp;horizontal&nbsp;scalability&nbsp;for&nbsp;performance&nbsp;sake.&nbsp; We&amp;#39;ve&nbsp;come&nbsp;to&nbsp;the&nbsp;conclusion&nbsp;that&nbsp;we&nbsp;can&nbsp;RAID&nbsp;disks,&nbsp;and&nbsp;if&nbsp;a&nbsp;queue&nbsp;node&nbsp;goes&nbsp;down,&nbsp;we&nbsp;can&nbsp;bring&nbsp;up&nbsp;a&nbsp;new&nbsp;node&nbsp;with&nbsp;the&nbsp;old&nbsp;disk&nbsp;in&nbsp;human-scale&nbsp;times.&lt;/div&gt;<br>
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;What&nbsp;do&nbsp;you&nbsp;think?&nbsp; Thank&nbsp;you&nbsp;for&nbsp;any&nbsp;feedback.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Adam&lt;br&gt;&lt;br&gt;&lt;div&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Wed,&nbsp;Oct&nbsp;19,&nbsp;2011&nbsp;at&nbsp;1:38&nbsp;PM,&nbsp;Jerry&nbsp;Kuch&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&amp;lt;&lt;a&nbsp;href=&quot;mailto:jerryk@vmware.com&quot;&gt;jerryk@vmware.com&lt;/a&gt;&amp;gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;Hi,&nbsp;Adam...&lt;br&gt;<br>
&lt;br&gt;<br>
I&amp;#39;m&nbsp;perhaps&nbsp;a&nbsp;bit&nbsp;confused.&nbsp; I&nbsp;assume&nbsp;your&nbsp;goal&nbsp;is&nbsp;tolerating&nbsp;the&nbsp;failure&nbsp;of&lt;br&gt;<br>
individual&nbsp;nodes?&lt;br&gt;<br>
&lt;br&gt;<br>
Have&nbsp;you&nbsp;looked&nbsp;at&nbsp;the&nbsp;new&nbsp;active/active&nbsp;HA&nbsp;that&nbsp;debuted&nbsp;in&nbsp;RabbitMQ&nbsp;2.6.x?&lt;br&gt;<br>
It&nbsp;allows&nbsp;for&nbsp;queues&nbsp;to&nbsp;be&nbsp;replicated&nbsp;automatically&nbsp;across&nbsp;the&nbsp;nodes&nbsp;of&nbsp;a&lt;br&gt;<br>
cluster&nbsp;with&nbsp;a&nbsp;user-selectable&nbsp;number&nbsp;of&nbsp;replicas.&lt;br&gt;<br>
&lt;br&gt;<br>
Older&nbsp;Rabbits&nbsp;also&nbsp;support&nbsp;an&nbsp;active/passive&nbsp;HA&nbsp;using&nbsp;shared&nbsp;storage.&lt;br&gt;<br>
&lt;br&gt;<br>
As&nbsp;you&nbsp;suggest,&nbsp;you&nbsp;might&nbsp;find&nbsp;building&nbsp;the&nbsp;sort&nbsp;of&nbsp;logic&nbsp;you&amp;#39;re&nbsp;talking&nbsp;about&lt;br&gt;<br>
entirely&nbsp;outside&nbsp;of&nbsp;the&nbsp;broker&nbsp;daunting&nbsp;and&nbsp;surprisingly&nbsp;difficult&nbsp;to&nbsp;get&lt;br&gt;<br>
quite&nbsp;what&nbsp;you&nbsp;want&nbsp;out&nbsp;of,&nbsp;as&nbsp;well&nbsp;as&nbsp;being&nbsp;difficult&nbsp;to&nbsp;administer.&lt;br&gt;<br>
&lt;br&gt;<br>
Best&nbsp;regards,&lt;br&gt;<br>
Jerry&lt;br&gt;<br>
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&nbsp;class=&quot;h5&quot;&gt;&lt;br&gt;<br>
-----&nbsp;Original&nbsp;Message&nbsp;-----&lt;br&gt;<br>
From:&nbsp;&amp;quot;Adam&nbsp;Rabung&amp;quot;&nbsp;&amp;lt;&lt;a&nbsp;href=&quot;mailto:adamrabung@gmail.com&quot;&gt;adamrabung@gmail.com&lt;/a&gt;&amp;gt;&lt;br&gt;<br>
To:&nbsp;&lt;a&nbsp;href=&quot;mailto:rabbitmq-discuss@lists.rabbitmq.com&quot;&gt;rabbitmq-discuss@lists.rabbitmq.com&lt;/a&gt;&lt;br&gt;<br>
Sent:&nbsp;Wednesday,&nbsp;October&nbsp;19,&nbsp;2011&nbsp;6:39:54&nbsp;AM&lt;br&gt;<br>
Subject:&nbsp;[rabbitmq-discuss]&nbsp;Possible&nbsp;clustering&nbsp;layout&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
Hello,&nbsp;I&nbsp;am&nbsp;thinking&nbsp;through&nbsp;how&nbsp;to&nbsp;lay&nbsp;out&nbsp;a&nbsp;rabbit&nbsp;cluster.&nbsp;One&nbsp;possible&nbsp;clustering&nbsp;approach&nbsp;would&nbsp;be&nbsp;have&nbsp;all&nbsp;exchanges/queues&nbsp;duplicated&nbsp;across&nbsp;each&nbsp;node&nbsp;in&nbsp;the&nbsp;cluster.&nbsp;Publishers&nbsp;load&nbsp;balance&nbsp;which&nbsp;node&nbsp;they&nbsp;publish&nbsp;to,&nbsp;and&nbsp;consumers&nbsp;subscribe&nbsp;to&nbsp;their&nbsp;applicable&nbsp;queues&nbsp;on&nbsp;all&nbsp;nodes.&nbsp;Each&nbsp;node&nbsp;is&nbsp;completely&nbsp;independent.&lt;br&gt;<br>
<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
This&nbsp;approach&nbsp;seems&nbsp;to&nbsp;have&nbsp;the&nbsp;benefit&nbsp;of&nbsp;avoiding&nbsp;unforeseen&nbsp;hops&nbsp;when&nbsp;a&nbsp;publisher&nbsp;or&nbsp;consumer&nbsp;connects&nbsp;to&nbsp;a&nbsp;node&nbsp;that&nbsp;does&nbsp;not&nbsp;hold&nbsp;the&nbsp;queue.&nbsp;It&nbsp;also&nbsp;seems&nbsp;beneficial&nbsp;from&nbsp;a&nbsp;fault&nbsp;tolerance&nbsp;standpoint&nbsp;to&nbsp;have&nbsp;messages&nbsp;for&nbsp;a&nbsp;logical&nbsp;queue&nbsp;spread&nbsp;evenly&nbsp;across&nbsp;n&nbsp;nodes.&lt;br&gt;<br>
<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
One&nbsp;downside&nbsp;I&nbsp;see&nbsp;is&nbsp;the&nbsp;maintenance&nbsp;of&nbsp;these&nbsp;nodes:&nbsp;changing&nbsp;a&nbsp;binding&nbsp;means&nbsp;changing&nbsp;it&nbsp;in&nbsp;n&nbsp;places.&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
Is&nbsp;this&nbsp;an&nbsp;acceptable&nbsp;approach,&nbsp;or&nbsp;am&nbsp;I&nbsp;barking&nbsp;up&nbsp;the&nbsp;wrong&nbsp;tree?&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
Thanks,&lt;br&gt;<br>
Adam&lt;br&gt;<br>
&lt;/div&gt;&lt;/div&gt;_______________________________________________&lt;br&gt;<br>
rabbitmq-discuss&nbsp;mailing&nbsp;list&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;mailto:rabbitmq-discuss@lists.rabbitmq.com&quot;&gt;rabbitmq-discuss@lists.rabbitmq.com&lt;/a&gt;&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss&quot;&nbsp;target=&quot;_blank&quot;&gt;https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss&lt;/a&gt;&lt;br&gt;<br>
&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;<br>

</tt>
