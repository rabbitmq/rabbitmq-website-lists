<tt>
Reply&nbsp;inline&nbsp;below:&lt;div&gt;&lt;br&nbsp;clear=&quot;all&quot;&gt;Scott&nbsp;Mohekey&lt;br&gt;Systems/Application&nbsp;Specialist&nbsp;–&nbsp;Fleet&nbsp;–&nbsp;Telogis,&nbsp;Inc.&lt;br&gt;&lt;a&nbsp;href=&quot;http://www.telogis.com&quot;&gt;www.telogis.com&lt;/a&gt;&nbsp; &lt;a&nbsp;href=&quot;http://www.telogis.co.nz&quot;&gt;www.telogis.co.nz&lt;/a&gt;&nbsp;&lt;br&gt;<br>
+1&nbsp;949&nbsp;625-4115&nbsp;ext.&nbsp;207&nbsp;(USA)&nbsp; +64&nbsp;3339&nbsp;2825&nbsp;x207&nbsp;(NZ)&lt;br&gt;&lt;br&gt;Leading&nbsp;Global&nbsp;Platform&nbsp;for&nbsp;Location&nbsp;Based&nbsp;Services&nbsp;&lt;br&gt;--&lt;br&gt;This&nbsp;e-mail,&nbsp;and&nbsp;any&nbsp;attachments,&nbsp;is&nbsp;intended&nbsp;only&nbsp;for&nbsp;use&nbsp;by&nbsp;the&nbsp;addressee(s)&nbsp;named&nbsp;herein&nbsp;and&nbsp;may&nbsp;contain&nbsp;legally&nbsp;privileged&nbsp;and/or&nbsp;confidential&nbsp;information.&nbsp; It&nbsp;is&nbsp;the&nbsp;property&nbsp;of&nbsp;Telogis.&nbsp; If&nbsp;you&nbsp;are&nbsp;not&nbsp;the&nbsp;intended&nbsp;recipient&nbsp;of&nbsp;this&nbsp;e-mail,&nbsp;you&nbsp;are&nbsp;hereby&nbsp;notified&nbsp;that&nbsp;any&nbsp;dissemination,&nbsp;distribution&nbsp;or&nbsp;copying&nbsp;of&nbsp;this&nbsp;e-mail,&nbsp;any&nbsp;attachments&nbsp;thereto,&nbsp;and&nbsp;use&nbsp;of&nbsp;the&nbsp;information&nbsp;contained,&nbsp;is&nbsp;strictly&nbsp;prohibited.&nbsp; If&nbsp;you&nbsp;have&nbsp;received&nbsp;this&nbsp;e-mail&nbsp;in&nbsp;error,&nbsp;please&nbsp;notify&nbsp;the&nbsp;sender&nbsp;and&nbsp;permanently&nbsp;delete&nbsp;the&nbsp;original&nbsp;and&nbsp;any&nbsp;copy&nbsp;there&nbsp;of.&lt;br&gt;<br>
<br>
&lt;br&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Mon,&nbsp;Mar&nbsp;22,&nbsp;2010&nbsp;at&nbsp;11:58&nbsp;AM,&nbsp;Matthew&nbsp;Sackman&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&amp;lt;&lt;a&nbsp;href=&quot;mailto:matthew@lshift.net&quot;&gt;matthew@lshift.net&lt;/a&gt;&amp;gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;<br>
&lt;div&nbsp;class=&quot;im&quot;&gt;On&nbsp;Mon,&nbsp;Mar&nbsp;22,&nbsp;2010&nbsp;at&nbsp;11:26:24AM&nbsp;+1300,&nbsp;Scott&nbsp;Mohekey&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&nbsp;I&amp;#39;m&nbsp;trying&nbsp;to&nbsp;find&nbsp;out&nbsp;when&nbsp;the&nbsp;new&nbsp;persister&nbsp;will&nbsp;be&nbsp;available.&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/div&gt;Me&nbsp;too!&lt;br&gt;<br>
&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&amp;gt;&nbsp;I&amp;#39;ve&nbsp;seen&lt;br&gt;<br>
&amp;gt;&nbsp;mention&nbsp;that&nbsp;it&nbsp;was&nbsp;to&nbsp;be&nbsp;ready&nbsp;by&nbsp;July&nbsp;of&nbsp;last&nbsp;year&nbsp;(&lt;br&gt;<br>
&amp;gt;&nbsp;&lt;a&nbsp;href=&quot;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2009-June/003667.html&quot;&nbsp;target=&quot;_blank&quot;&gt;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2009-June/003667.html&lt;/a&gt;),&lt;br&gt;<br>
&amp;gt;&nbsp;and&nbsp;further&nbsp;mention&nbsp;in&nbsp;November&nbsp;of&nbsp;it&nbsp;not&nbsp;being&nbsp;ready&nbsp;yet&nbsp;(&lt;br&gt;<br>
&amp;gt;&nbsp;&lt;a&nbsp;href=&quot;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2009-November/005386.html&quot;&nbsp;target=&quot;_blank&quot;&gt;http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/2009-November/005386.html&lt;/a&gt;&lt;br&gt;<br>
&amp;gt;&nbsp;).&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/div&gt;Yes.&nbsp;Though&nbsp;the&nbsp;&amp;quot;new&nbsp;persister&amp;quot;&nbsp;was&nbsp;in&nbsp;very&nbsp;different&nbsp;states&nbsp;at&nbsp;both&nbsp;of&lt;br&gt;<br>
occasions.&lt;br&gt;<br>
&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&amp;gt;&nbsp;The&nbsp;reason&nbsp;I&nbsp;ask&nbsp;is&nbsp;that&nbsp;we&nbsp;are&nbsp;attempting&nbsp;to&nbsp;publish&nbsp;~1000&nbsp;msgs/sec&nbsp;on&nbsp;a&lt;br&gt;<br>
&amp;gt;&nbsp;single&nbsp;rabbit&nbsp;node,&nbsp;in&nbsp;a&nbsp;persisted&nbsp;queue.&nbsp;The&nbsp;queue&nbsp;is&nbsp;then&nbsp;read&nbsp;by&nbsp;a&nbsp;java&lt;br&gt;<br>
&amp;gt;&nbsp;app&nbsp;on&nbsp;a&nbsp;geographically&nbsp;distant&nbsp;server&nbsp;over&nbsp;the&nbsp;internet,&nbsp;using&lt;br&gt;<br>
&amp;gt;&nbsp;basic.consume.&nbsp;We&nbsp;also&nbsp;require&nbsp;transactional&nbsp;consumption,&nbsp;so&nbsp;currently&nbsp;wrap&lt;br&gt;<br>
&amp;gt;&nbsp;a&nbsp;batch&nbsp;of&nbsp;X&nbsp;(500&nbsp;for&nbsp;example)&nbsp;messages&nbsp;in&nbsp;a&nbsp;transaction,&nbsp;acking&nbsp;the&nbsp;last&lt;br&gt;<br>
&amp;gt;&nbsp;one&nbsp;(passing&nbsp;true&nbsp;to&nbsp;ack&nbsp;multiple).&nbsp;We&nbsp;have&nbsp;qos&nbsp;set&nbsp;to&nbsp;batch&nbsp;size&nbsp;*&nbsp;2&nbsp;(1000&lt;br&gt;<br>
&amp;gt;&nbsp;in&nbsp;the&nbsp;above&nbsp;example).&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;We&amp;#39;re&nbsp;only&nbsp;managing&nbsp;to&nbsp;get&nbsp;something&nbsp;like&nbsp;50&nbsp;or&nbsp;so&nbsp;msgs/sec&nbsp;at&nbsp;the&nbsp;moment.&lt;br&gt;<br>
&amp;gt;&nbsp;The&nbsp;consumption&nbsp;of&nbsp;the&nbsp;messages&nbsp;is&nbsp;slow,&nbsp;but&nbsp;the&nbsp;tx.commit&nbsp;varies&nbsp;in&nbsp;speed&lt;br&gt;<br>
&amp;gt;&nbsp;from&nbsp;a&nbsp;second&nbsp;to&nbsp;many&nbsp;(sometimes&nbsp;even&nbsp;as&nbsp;long&nbsp;as&nbsp;a&nbsp;minute).&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/div&gt;Many&nbsp;things&nbsp;can&nbsp;affect&nbsp;this.&nbsp;Are&nbsp;the&nbsp;publishes&nbsp;coming&nbsp;from&nbsp;a&nbsp;single&lt;br&gt;<br>
publisher&nbsp;client&nbsp;or&nbsp;from&nbsp;many&nbsp;clients?&nbsp;Are&nbsp;all&nbsp;the&nbsp;publishes&nbsp;going&nbsp;to&lt;br&gt;<br>
the&nbsp;same&nbsp;queue&nbsp;or&nbsp;to&nbsp;several&nbsp;different&nbsp;queues?&nbsp;How&nbsp;big&nbsp;are&nbsp;the&nbsp;messages&lt;br&gt;<br>
that&nbsp;you&amp;#39;re&nbsp;publishing&nbsp;and&nbsp;which&nbsp;client&nbsp;library&nbsp;/&nbsp;language&nbsp;are&nbsp;you&lt;br&gt;<br>
using?&lt;br&gt;<br>
&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We&nbsp;have&nbsp;a&nbsp;single&nbsp;publisher,&nbsp;with&nbsp;10&nbsp;production&nbsp;queues&nbsp;which&nbsp;are&nbsp;duplicated&nbsp;for&nbsp;testing&nbsp;(so&nbsp;20&nbsp;queues&nbsp;all&nbsp;up).&nbsp;All&nbsp;of&nbsp;these&nbsp;queues&nbsp;are&nbsp;persistent.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;<br>
&lt;div&gt;We&nbsp;use&nbsp;a&nbsp;topic&nbsp;exchange,&nbsp;with&nbsp;messages&nbsp;being&nbsp;routed&nbsp;to&nbsp;one&nbsp;or&nbsp;more&nbsp;of&nbsp;the&nbsp;queues.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;The&nbsp;publisher&nbsp;uses&nbsp;the&nbsp;.net&nbsp;client&nbsp;and&nbsp;does&nbsp;no&nbsp;transactions,&nbsp;while&nbsp;the&nbsp;consumer&nbsp;uses&nbsp;the&nbsp;java&nbsp;client&nbsp;and&nbsp;wraps&nbsp;batches&nbsp;of&nbsp;messages&nbsp;in&nbsp;transactions.&lt;/div&gt;<br>
&lt;div&gt; &lt;/div&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;&lt;div&nbsp;class=&quot;im&quot;&gt;<br>
&amp;gt;&nbsp;The&nbsp;version&nbsp;of&nbsp;rabbitmq&nbsp;we&nbsp;currently&nbsp;have&nbsp;installed&nbsp;is&nbsp;1.7.0.&nbsp;We&nbsp;are&lt;br&gt;<br>
&amp;gt;&nbsp;planning&nbsp;to&nbsp;test&nbsp;with&nbsp;1.7.2&nbsp;later&nbsp;today&nbsp;to&nbsp;see&nbsp;if&nbsp;this&nbsp;helps&nbsp;any.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;What&nbsp;are&nbsp;we&nbsp;doing&nbsp;wrong?&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;/div&gt;The&nbsp;new&nbsp;persister&nbsp;is&nbsp;much&nbsp;better&nbsp;(at&nbsp;least&nbsp;an&nbsp;order&nbsp;of&nbsp;magnitude,&nbsp;and&lt;br&gt;<br>
frequently&nbsp;several,&nbsp;depending&nbsp;on&nbsp;workload)&nbsp;at&nbsp;transactions.&nbsp;I&nbsp;would&lt;br&gt;<br>
suggest&nbsp;you&nbsp;try&nbsp;compiling&nbsp;from&nbsp;source&nbsp;and&nbsp;using&nbsp;that.&nbsp;There&nbsp;are&nbsp;several&lt;br&gt;<br>
people&nbsp;on&nbsp;this&nbsp;list&nbsp;who&nbsp;have&nbsp;been&nbsp;using&nbsp;the&nbsp;new&nbsp;persister&nbsp;with&nbsp;good&lt;br&gt;<br>
success.&nbsp;There&nbsp;are&nbsp;occasionally&nbsp;bugs&nbsp;found,&nbsp;but&nbsp;we&nbsp;tend&nbsp;to&nbsp;fix&nbsp;them&lt;br&gt;<br>
within&nbsp;hours.&lt;br&gt;<br>
&lt;br&gt;<br>
There&nbsp;haven&amp;#39;t&nbsp;really&nbsp;been&nbsp;any&nbsp;new&nbsp;features&nbsp;added&nbsp;to&nbsp;the&nbsp;new&nbsp;persister&lt;br&gt;<br>
for&nbsp;a&nbsp;few&nbsp;months&nbsp;-&nbsp;it&nbsp;has&nbsp;been&nbsp;solidifying&nbsp;nicely.&nbsp;However,&nbsp;the&nbsp;diff&lt;br&gt;<br>
from&nbsp;the&nbsp;current&nbsp;default&nbsp;branch&nbsp;to&nbsp;the&nbsp;new&nbsp;persister&nbsp;branch&nbsp;(bug21673)&lt;br&gt;<br>
shows&nbsp;the&nbsp;addition&nbsp;of&nbsp;7000&nbsp;lines&nbsp;of&nbsp;code.&nbsp;This&nbsp;is&nbsp;the&nbsp;reason&nbsp;why&nbsp;it&nbsp;is&lt;br&gt;<br>
taking&nbsp;a&nbsp;long&nbsp;time&nbsp;to&nbsp;get&nbsp;through&nbsp;QA&nbsp;-&nbsp;not&nbsp;because&nbsp;it&amp;#39;s&nbsp;buggy&nbsp;or&nbsp;faults&lt;br&gt;<br>
are&nbsp;being&nbsp;found,&nbsp;but&nbsp;simply&nbsp;because&nbsp;it&nbsp;is&nbsp;a&nbsp;lot&nbsp;of&nbsp;very&nbsp;complex&nbsp;code.&lt;br&gt;<br>
&lt;br&gt;<br>
If&nbsp;you&nbsp;do&nbsp;choose&nbsp;to&nbsp;use&nbsp;the&nbsp;new&nbsp;persister,&nbsp;try&nbsp;to&nbsp;ensure&nbsp;the&nbsp;following:&lt;br&gt;<br>
1)&nbsp;Try&nbsp;to&nbsp;make&nbsp;sure&nbsp;nothing&nbsp;else&nbsp;is&nbsp;writing&nbsp;to&nbsp;the&nbsp;disk&nbsp;that&nbsp;Rabbit&nbsp;is&lt;br&gt;<br>
using&nbsp;-&nbsp;Rabbit&nbsp;is&nbsp;pretty&nbsp;good&nbsp;at&nbsp;managing&nbsp;the&nbsp;position&nbsp;of&nbsp;the&nbsp;disk&nbsp;head,&lt;br&gt;<br>
but&nbsp;that&nbsp;tends&nbsp;to&nbsp;go&nbsp;wrong&nbsp;if&nbsp;other&nbsp;applications&nbsp;are&nbsp;writing&nbsp;at&nbsp;the&nbsp;same&lt;br&gt;<br>
time.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We&nbsp;have&nbsp;our&nbsp;instance&nbsp;of&nbsp;Rabbit&nbsp;running&nbsp;on&nbsp;a&nbsp;XenCenter&nbsp;vm,&nbsp;using&nbsp;shared&nbsp;fibre&nbsp;storage.&nbsp;Is&nbsp;this&nbsp;going&nbsp;to&nbsp;be&nbsp;a&nbsp;problem?&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;<br>
<br>
2)&nbsp;Ensure&nbsp;plenty&nbsp;of&nbsp;free&nbsp;RAM&nbsp;so&nbsp;the&nbsp;OS&nbsp;can&nbsp;use&nbsp;it&nbsp;as&nbsp;disk&nbsp;cache.&nbsp;This&lt;br&gt;<br>
means&nbsp;a&nbsp;lot&nbsp;of&nbsp;reads&nbsp;can&nbsp;be&nbsp;satisfied&nbsp;without&nbsp;going&nbsp;all&nbsp;the&nbsp;way&nbsp;to&nbsp;disk.&lt;br&gt;&lt;/blockquote&gt;&lt;div&gt;We&nbsp;have&nbsp;given&nbsp;the&nbsp;vm&nbsp;8&nbsp;gigs&nbsp;at&nbsp;the&nbsp;moment.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;<br>
<br>
3)&nbsp;You&nbsp;may&nbsp;wish&nbsp;to&nbsp;investigate&nbsp;different&nbsp;file&nbsp;systems&nbsp;-&nbsp;e.g.&nbsp;Matthias&amp;#39;s&lt;br&gt;<br>
desktop,&nbsp;Ubuntu,&nbsp;using&nbsp;ext4,&nbsp;gets&nbsp;a&nbsp;pitiful&nbsp;9&nbsp;transactions&nbsp;a&nbsp;second,&lt;br&gt;<br>
where&nbsp;as&nbsp;my&nbsp;rather&nbsp;more&nbsp;carefully&nbsp;tuned&nbsp;debian&nbsp;sid&nbsp;system&nbsp;gets&nbsp;500&lt;br&gt;<br>
txns/sec&nbsp;on&nbsp;an&nbsp;ext3&nbsp;disk,&nbsp;and&nbsp;1100&nbsp;on&nbsp;an&nbsp;ext4&nbsp;SSD.&nbsp;See&nbsp;the&nbsp;thread&nbsp;at&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;http://old.nabble.com/limit-number-of-messages-buffered-in-memory-in-new-persister-td27753311.html&quot;&nbsp;target=&quot;_blank&quot;&gt;http://old.nabble.com/limit-number-of-messages-buffered-in-memory-in-new-persister-td27753311.html&lt;/a&gt;&lt;/blockquote&gt;<br>
&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;We&amp;#39;re&nbsp;using&nbsp;ext3.&lt;/div&gt;&lt;div&gt; &lt;/div&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;&lt;br&gt;<br>
4)&nbsp;SSDs&nbsp;can&nbsp;go&nbsp;much&nbsp;faster&nbsp;for&nbsp;txns&nbsp;because&nbsp;their&nbsp;fsync&nbsp;cost&nbsp;is&nbsp;very&lt;br&gt;<br>
very&nbsp;low.&lt;br&gt;<br>
5)&nbsp;Publishing&nbsp;in&nbsp;parallel&nbsp;(several&nbsp;producers,&nbsp;all&nbsp;issuing&nbsp;txns&lt;br&gt;<br>
individually)&nbsp;will&nbsp;get&nbsp;you&nbsp;even&nbsp;better&nbsp;performance.&lt;font&nbsp;color=&quot;#888888&quot;&gt;&lt;br&gt;&lt;/font&gt;&lt;/blockquote&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Will&nbsp;this&nbsp;make&nbsp;a&nbsp;difference&nbsp;even&nbsp;though&nbsp;we&amp;#39;re&nbsp;not&nbsp;using&nbsp;transactions&nbsp;on&nbsp;the&nbsp;publishing&nbsp;side?&lt;/div&gt;&lt;div&gt;<br>
&lt;br&gt;&lt;/div&gt;&lt;div&gt;Also,&nbsp;it&nbsp;seems&nbsp;to&nbsp;me&nbsp;that&nbsp;the&nbsp;slow&nbsp;throughput&nbsp;is&nbsp;on&nbsp;the&nbsp;consumer&nbsp;side.&nbsp;Queues&nbsp;have&nbsp;no&nbsp;problem&nbsp;filling&nbsp;up&nbsp;with&nbsp;messages,&nbsp;faster&nbsp;than&nbsp;the&nbsp;consumers&nbsp;can&nbsp;keep&nbsp;up&nbsp;with&nbsp;them.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;margin:0&nbsp;0&nbsp;0&nbsp;.8ex;border-left:1px&nbsp;#ccc&nbsp;solid;padding-left:1ex;&quot;&gt;<br>
&lt;font&nbsp;color=&quot;#888888&quot;&gt;Matthew&lt;br&gt;<br>
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;&lt;/div&gt;<br>

</tt>
