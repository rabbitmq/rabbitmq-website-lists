<tt>
&lt;div&nbsp;dir=&quot;ltr&quot;&gt;&lt;div&gt;We&nbsp;have&nbsp;two&nbsp;data&nbsp;centers&nbsp;connected&nbsp;closely&nbsp;by&nbsp;LAN.&nbsp;&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;We&nbsp;are&nbsp;interested&nbsp;in&nbsp;a&nbsp;*reliable&nbsp;cluster*&nbsp;setup.&nbsp;It&nbsp;must&nbsp;be&nbsp;a&nbsp;cluster&nbsp;because&nbsp;we&nbsp;want&nbsp;clients&nbsp;to&nbsp;be&nbsp;able&nbsp;to&nbsp;connect&nbsp;to&nbsp;each&nbsp;node&nbsp;transparently.&nbsp;Federation&nbsp;is&nbsp;not&nbsp;an&nbsp;option.&lt;/div&gt;&lt;div&gt;&lt;div&gt;1.&nbsp;It&nbsp;happens&nbsp;that&nbsp;the&nbsp;firewall/switch&nbsp;is&nbsp;restarted,&nbsp;and&nbsp;maybe&nbsp;a&nbsp;few&nbsp;ping&nbsp;messages&nbsp;are&nbsp;lost.&lt;/div&gt;&lt;div&gt;2.&nbsp;The&nbsp;setup&nbsp;should&nbsp;survive&nbsp;data&nbsp;center&nbsp;crash&lt;/div&gt;&lt;/div&gt;&lt;div&gt;3.&nbsp;All&nbsp;queues&nbsp;are&nbsp;durable&nbsp;and&nbsp;mirrored,&nbsp;all&nbsp;messages&nbsp;are&nbsp;persisted,&nbsp;all&nbsp;publishes&nbsp;are&nbsp;confirmed&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;There&nbsp;are&nbsp;3&nbsp;cluster-recovery&nbsp;settings&lt;/div&gt;&lt;div&gt;a)&nbsp;&lt;span&nbsp;class=&quot;code&nbsp;&quot;&gt;ignore:&lt;/span&gt;&nbsp;A&nbsp;cross&nbsp;data&nbsp;center&nbsp;network&nbsp;break-down&nbsp;would&nbsp;cause&nbsp;message&nbsp;loss&nbsp;on&nbsp;the&nbsp;node&nbsp;that&nbsp;is&nbsp;restarted&nbsp;In&nbsp;order&nbsp;to&nbsp;rejoin.&lt;/div&gt;&lt;div&gt;b)&nbsp;&lt;span&nbsp;class=&quot;code&nbsp;&quot;&gt;pause_minority:&lt;/span&gt;&nbsp;If&nbsp;we&nbsp;choose&nbsp;the&nbsp;same&nbsp;number&nbsp;of&nbsp;nodes&nbsp;in&nbsp;each&nbsp;data&nbsp;center,&nbsp;the&nbsp;whole&nbsp;cluster&nbsp;will&nbsp;pause.&nbsp;If&nbsp;we&nbsp;don't,&nbsp;only&nbsp;the&nbsp;data&nbsp;center&nbsp;with&nbsp;the&nbsp;most&nbsp;nodes&nbsp;can&nbsp;survive.&nbsp;&lt;/div&gt;&lt;div&gt;c)&nbsp;auto_heal:&nbsp;If&nbsp;the&nbsp;cluster&nbsp;decides&nbsp;network&nbsp;partitioning,&nbsp;there&nbsp;is&nbsp;a&nbsp;potential&nbsp;of&nbsp;message&nbsp;loss,&nbsp;when&nbsp;joining.&lt;/div&gt;&lt;div&gt;[I&nbsp;would&nbsp;really&nbsp;like&nbsp;a&nbsp;resync-setting&nbsp;similar&nbsp;to&nbsp;the&nbsp;one&nbsp;described&nbsp;below]&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;Question&nbsp;1:&nbsp;Is&nbsp;it&nbsp;even&nbsp;possible&nbsp;to&nbsp;have&nbsp;a&nbsp;fully&nbsp;reliable&nbsp;setup&nbsp;in&nbsp;such&nbsp;a&nbsp;setting?&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;In&nbsp;reality&nbsp;we&nbsp;probably&nbsp;won't&nbsp;have&nbsp;actual&nbsp;network&nbsp;partitions,&nbsp;and&nbsp;it&nbsp;will&nbsp;most&nbsp;probably&nbsp;only&nbsp;be&nbsp;a&nbsp;very&nbsp;short&nbsp;network&nbsp;downtime.&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;Question&nbsp;2:&nbsp;Is&nbsp;it&nbsp;possible&nbsp;to&nbsp;adjust&nbsp;how&nbsp;long&nbsp;it&nbsp;takes&nbsp;rabbitmq&nbsp;to&nbsp;decide&nbsp;&quot;node&nbsp;down&quot;?&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;It&nbsp;is&nbsp;much&nbsp;better&nbsp;to&nbsp;have&nbsp;a&nbsp;halted&nbsp;rabbitmq&nbsp;for&nbsp;some&nbsp;seconds&nbsp;than&nbsp;to&nbsp;have&nbsp;message&nbsp;loss.&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;Question&nbsp;3:&nbsp;Assume&nbsp;that&nbsp;we&nbsp;are&nbsp;using&nbsp;the&nbsp;ignore&nbsp;setting,&nbsp;and&nbsp;that&nbsp;we&nbsp;have&nbsp;only&nbsp;two&nbsp;nodes&nbsp;in&nbsp;the&nbsp;cluster.&nbsp;Would&nbsp;the&nbsp;following&nbsp;be&nbsp;a&nbsp;full&nbsp;recovery&nbsp;with&nbsp;zero&nbsp;message&nbsp;loss?&nbsp;&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;0.&nbsp;Decide&nbsp;which&nbsp;node&nbsp;survives,&nbsp;Ns,&nbsp;and&nbsp;which&nbsp;should&nbsp;be&nbsp;restarted,&nbsp;Nr.&lt;/div&gt;&lt;div&gt;1.&nbsp;Refuse&nbsp;all&nbsp;connections&nbsp;to&nbsp;Nr&nbsp;except&nbsp;from&nbsp;a&nbsp;special&nbsp;recovery&nbsp;application.&nbsp;(One&nbsp;could&nbsp;change&nbsp;the&nbsp;ip,&nbsp;so&nbsp;all&nbsp;running&nbsp;services&nbsp;can't&nbsp;connect&nbsp;or&nbsp;similar)&lt;/div&gt;&lt;div&gt;2.&nbsp;Consume&nbsp;and&nbsp;republish&nbsp;all&nbsp;message&nbsp;from&nbsp;Nr&nbsp;to&nbsp;Ns.&lt;/div&gt;&lt;div&gt;3.&nbsp;Restart&nbsp;Nr&lt;/div&gt;&lt;div&gt;Then&nbsp;the&nbsp;cluster&nbsp;should&nbsp;be&nbsp;up-and-running&nbsp;again.&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;Since&nbsp;all&nbsp;queues&nbsp;are&nbsp;mirrored,&nbsp;all&nbsp;messages&nbsp;published&nbsp;in&nbsp;the&nbsp;partition&nbsp;time&nbsp;is&nbsp;preserved.&nbsp;If&nbsp;a&nbsp;certain&nbsp;service&nbsp;lives&nbsp;only&nbsp;in&nbsp;the&nbsp;one&nbsp;data&nbsp;center,&nbsp;messages&nbsp;will&nbsp;pile&nbsp;up&nbsp;in&nbsp;the&nbsp;other&nbsp;(if&nbsp;there&nbsp;are&nbsp;any&nbsp;publishes).&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;If&nbsp;you&nbsp;have&nbsp;any&nbsp;other&nbsp;suggestions,&nbsp;I&nbsp;would&nbsp;be&nbsp;very&nbsp;interested&nbsp;to&nbsp;hear&nbsp;them.&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;I&nbsp;would&nbsp;be&nbsp;really&nbsp;sad&nbsp;to&nbsp;find&nbsp;it&nbsp;necessary&nbsp;to&nbsp;choose&nbsp;Tibco&nbsp;ESB&nbsp;over&nbsp;RabbitMQ,&nbsp;for&nbsp;this&nbsp;reason.&lt;/div&gt;&lt;div&gt;&nbsp;&lt;/div&gt;&lt;div&gt;Thank&nbsp;you,&lt;/div&gt;&lt;div&gt;--&nbsp;Steffen&lt;/div&gt;&lt;/div&gt;
</tt>
