<tt>
&lt;br&gt;Hi&nbsp;Matthias,&lt;br&gt;&lt;br&gt;That&amp;#39;s&nbsp;good&nbsp;to&nbsp;know&nbsp;that&nbsp;those&nbsp;numbers&nbsp;look&nbsp;high&nbsp;to&nbsp;you. &nbsp;Knowing&nbsp;where&nbsp;our&nbsp;bounds&nbsp;are&nbsp;will&nbsp;help&nbsp;me&nbsp;readjust&nbsp;out&nbsp;configuration.&lt;br&gt;&lt;br&gt;We&nbsp;have&nbsp;~75&nbsp;bindings,&nbsp;same&nbsp;as&nbsp;the&nbsp;number&nbsp;of&nbsp;queues. &nbsp;&nbsp;We&nbsp;don&amp;#39;t&nbsp;do&nbsp;many&nbsp;multiple&nbsp;bindings&nbsp;per&nbsp;queue&nbsp;(if&nbsp;any). &nbsp;This&nbsp;has&nbsp;increased&nbsp;faster&nbsp;than&nbsp;our&nbsp;message&nbsp;volumes&nbsp;(more&nbsp;consuming&nbsp;applications&nbsp;to&nbsp;make&nbsp;use&nbsp;of&nbsp;the&nbsp;data),&nbsp;so&nbsp;I&nbsp;believe&nbsp;this&nbsp;is&nbsp;the&nbsp;primary&nbsp;reason&nbsp;things&nbsp;are&nbsp;harder&nbsp;now&nbsp;than&nbsp;they&nbsp;used&nbsp;to&nbsp;be.&lt;br&gt;<br>
<br>
&lt;br&gt;Unfortunately,&nbsp;moving&nbsp;to&nbsp;a&nbsp;direct&nbsp;exchange&nbsp;is&nbsp;in&nbsp;the&nbsp;works&nbsp;but&nbsp;not&nbsp;a&nbsp;quick&nbsp;for&nbsp;us&nbsp;at&nbsp;this&nbsp;point.&lt;br&gt;&lt;br&gt;What&nbsp;I&nbsp;would&nbsp;like&nbsp;to&nbsp;figure&nbsp;out&nbsp;is&nbsp;how&nbsp;to&nbsp;reorient&nbsp;my&nbsp;cluster&nbsp;to&nbsp;make&nbsp;things&nbsp;more&nbsp;stable. &nbsp;Knowing&nbsp;that&nbsp;the&nbsp;routing&nbsp;time&nbsp;is&nbsp;increasing&nbsp;due&nbsp;to&nbsp;the&nbsp;number&nbsp;of&nbsp;bindings,&nbsp;I&nbsp;am&nbsp;not&nbsp;convinced&nbsp;that&nbsp;my&nbsp;plan&nbsp;of&nbsp;adding&nbsp;a&nbsp;rabbitmq&nbsp;node&nbsp;to&nbsp;each&nbsp;producer&nbsp;is&nbsp;going&nbsp;to&nbsp;make&nbsp;things&nbsp;all&nbsp;that&nbsp;much&nbsp;better&nbsp;-&nbsp;the&nbsp;routing&nbsp;table&nbsp;will&nbsp;still&nbsp;be&nbsp;the&nbsp;same,&nbsp;and&nbsp;it&nbsp;will&nbsp;need&nbsp;to&nbsp;do&nbsp;that&nbsp;cross-routing&nbsp;you&amp;#39;re&nbsp;talking&nbsp;about&nbsp;avoiding. &nbsp;Even&nbsp;when&nbsp;we&nbsp;have&nbsp;a&nbsp;single&nbsp;producer&nbsp;catching&nbsp;up&nbsp;in&nbsp;our&nbsp;current&nbsp;system,&nbsp;the&nbsp;node&nbsp;can&nbsp;only&nbsp;route&nbsp;at&nbsp;a&nbsp;certain&nbsp;rate,&nbsp;and&nbsp;this&nbsp;is&nbsp;definitely&nbsp;not&nbsp;CPU&nbsp;bound. &nbsp;I&nbsp;am&nbsp;curious&nbsp;why&nbsp;Erlang&nbsp;cannot&nbsp;spend&nbsp;more&nbsp;time&nbsp;in&nbsp;that&nbsp;thread,&nbsp;but&nbsp;I&nbsp;don&amp;#39;t&nbsp;know&nbsp;much&nbsp;about&nbsp;it&nbsp;-&nbsp;does&nbsp;that&nbsp;seem&nbsp;right&nbsp;to&nbsp;you?&lt;br&gt;<br>
<br>
&lt;br&gt;I&nbsp;am&nbsp;not&nbsp;sure&nbsp;what&nbsp;I&nbsp;can&nbsp;do&nbsp;to&nbsp;minimize&nbsp;cross-routing,&nbsp;other&nbsp;than&nbsp;to&nbsp;try&nbsp;to&nbsp;keep&nbsp;our&nbsp;producers&nbsp;consolidated&nbsp;and&nbsp;keep&nbsp;the&nbsp;heaviest&nbsp;consumers&nbsp;(meaning&nbsp;the&nbsp;ones&nbsp;with&nbsp;a&nbsp;binding&nbsp;to&nbsp;the&nbsp;most&nbsp;active&nbsp;topics&nbsp;-&nbsp;remember&nbsp;that&nbsp;all&nbsp;queues&nbsp;bind&nbsp;to&nbsp;only&nbsp;one&nbsp;topic&nbsp;expression)&nbsp;separated&nbsp;on&nbsp;their&nbsp;own&nbsp;nodes,&nbsp;to&nbsp;remove&nbsp;their&nbsp;queue&nbsp;management&nbsp;processing&nbsp;on&nbsp;the&nbsp;core&nbsp;routing&nbsp;function. &nbsp;Ironically,&nbsp;I&nbsp;was&nbsp;originally&nbsp;trying&nbsp;to&nbsp;keep&nbsp;the&nbsp;heaviest&nbsp;consumers&nbsp;on&nbsp;the&nbsp;routing&nbsp;nodes,&nbsp;to&nbsp;minimize&nbsp;forwarding&nbsp;of&nbsp;messages&nbsp;-&nbsp;but&nbsp;if&nbsp;the&nbsp;cost&nbsp;magnifies&nbsp;with&nbsp;the&nbsp;number&nbsp;of&nbsp;consumer&nbsp;queues,&nbsp;then&nbsp;it&amp;#39;s&nbsp;likely&nbsp;that&nbsp;keeping&nbsp;the&nbsp;larger&nbsp;fanout&nbsp;(but&nbsp;smaller&nbsp;throughput)&nbsp;of&nbsp;consumers&nbsp;on&nbsp;the&nbsp;routing&nbsp;nodes&nbsp;might&nbsp;be&nbsp;best.&lt;br&gt;<br>
<br>
&lt;br&gt;The&nbsp;thing&nbsp;that&nbsp;concerns&nbsp;me&nbsp;is&nbsp;that&nbsp;my&nbsp;scalability&nbsp;here&nbsp;seems&nbsp;to&nbsp;be&nbsp;limited&nbsp;-&nbsp;the&nbsp;only&nbsp;other&nbsp;thing&nbsp;I&nbsp;can&nbsp;think&nbsp;of&nbsp;doing&nbsp;is&nbsp;increasing&nbsp;my&nbsp;number&nbsp;of&nbsp;producers&nbsp;to&nbsp;distribute&nbsp;the&nbsp;load&nbsp;even&nbsp;further&nbsp;and&nbsp;possibly&nbsp;do&nbsp;the&nbsp;local&nbsp;node&nbsp;thing&nbsp;-&nbsp;then&nbsp;if&nbsp;our&nbsp;routing&nbsp;table&nbsp;keeps&nbsp;growing,&nbsp;I&nbsp;can&nbsp;manage&nbsp;scaling&nbsp;at&nbsp;the&nbsp;producer&nbsp;level&nbsp;-&nbsp;not&nbsp;efficient&nbsp;maybe,&nbsp;but&nbsp;at&nbsp;least&nbsp;it&nbsp;can&nbsp;grow&nbsp;past&nbsp;the&nbsp;threshold&nbsp;I&nbsp;appear&nbsp;to&nbsp;be&nbsp;running&nbsp;into.&lt;br&gt;<br>
<br>
&lt;br&gt;Thanks&nbsp;for&nbsp;the&nbsp;background. &nbsp;I&nbsp;would&nbsp;love&nbsp;to&nbsp;see&nbsp;more&nbsp;documentation&nbsp;on&nbsp;how&nbsp;the&nbsp;process&nbsp;model&nbsp;works. &nbsp;Let&nbsp;me&nbsp;know&nbsp;if&nbsp;the&nbsp;above&nbsp;triggers&nbsp;any&nbsp;other&nbsp;solutions.&lt;br&gt;&lt;br&gt;Thanks,&lt;br&gt;Brian&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Tue,&nbsp;Feb&nbsp;2,&nbsp;2010&nbsp;at&nbsp;6:00&nbsp;PM,&nbsp;Matthias&nbsp;Radestock&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&amp;lt;&lt;a&nbsp;href=&quot;mailto:matthias@lshift.net&quot;&gt;matthias@lshift.net&lt;/a&gt;&amp;gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;<br>
<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;border-left:&nbsp;1px&nbsp;solid&nbsp;rgb(204,&nbsp;204,&nbsp;204);&nbsp;margin:&nbsp;0pt&nbsp;0pt&nbsp;0pt&nbsp;0.8ex;&nbsp;padding-left:&nbsp;1ex;&quot;&gt;Brian,&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
Brian&nbsp;Sullivan&nbsp;wrote:&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;border-left:&nbsp;1px&nbsp;solid&nbsp;rgb(204,&nbsp;204,&nbsp;204);&nbsp;margin:&nbsp;0pt&nbsp;0pt&nbsp;0pt&nbsp;0.8ex;&nbsp;padding-left:&nbsp;1ex;&quot;&gt;<br>
1)&nbsp;How&nbsp;many&nbsp;msgs/second&nbsp;are&nbsp;being&nbsp;published&nbsp;for&nbsp;this&nbsp;issue&nbsp;to&nbsp;occur?&lt;br&gt;<br>
 From&nbsp;a&nbsp;single&nbsp;producer,&nbsp;about&nbsp;900&nbsp;messages/sec&nbsp;during&nbsp;these&nbsp;burst&nbsp;catchup&nbsp;periods.&nbsp; Normal&nbsp;volumes&nbsp;then&nbsp;drop&nbsp;down&nbsp;to&nbsp;300-500&nbsp;mps&nbsp;throughout&nbsp;the&nbsp;day,&nbsp;which&nbsp;we&nbsp;can&nbsp;keep&nbsp;up&nbsp;with&nbsp;for&nbsp;the&nbsp;most&nbsp;part.&nbsp; Note&nbsp;that&nbsp;there&nbsp;are&nbsp;8-9&nbsp;such&nbsp;producers,&nbsp;distributed&nbsp;across&nbsp;2&nbsp;nodes.&lt;br&gt;<br>
<br>
<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
So&nbsp;that&amp;#39;s&nbsp;a&nbsp;900Hz&nbsp;*&nbsp;9&nbsp;=&nbsp;8.1kHz&nbsp;peak&nbsp;inbound&nbsp;rate?&lt;div&nbsp;class=&quot;im&quot;&gt;&lt;br&gt;<br>
&lt;br&gt;<br>
&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;border-left:&nbsp;1px&nbsp;solid&nbsp;rgb(204,&nbsp;204,&nbsp;204);&nbsp;margin:&nbsp;0pt&nbsp;0pt&nbsp;0pt&nbsp;0.8ex;&nbsp;padding-left:&nbsp;1ex;&quot;&gt;<br>
4)&nbsp;How&nbsp;many&nbsp;queues&nbsp;do&nbsp;messages&nbsp;end&nbsp;up&nbsp;in,&nbsp;on&nbsp;average?&lt;br&gt;<br>
About&nbsp;the&nbsp;same&nbsp;number&nbsp;of&nbsp;bindings&nbsp;-&nbsp;75.&nbsp; We&nbsp;don&amp;#39;t&nbsp;do&nbsp;many&nbsp;multiple&nbsp;bindings&nbsp;per&nbsp;queue&nbsp;(if&nbsp;any).&lt;br&gt;<br>
&lt;/blockquote&gt;<br>
&lt;br&gt;&lt;/div&gt;<br>
8.1kHz&nbsp;inbound&nbsp;with&nbsp;a&nbsp;75x&nbsp;fan-out&nbsp;ratio&nbsp;would&nbsp;require&nbsp;an&nbsp;outbound&nbsp;rate&nbsp;of&nbsp;&amp;gt;600kHz,&nbsp;which&nbsp;is&nbsp;way&nbsp;more&nbsp;than&nbsp;a&nbsp;two-node&nbsp;rabbit&nbsp;cluster&nbsp;can&nbsp;handle.&nbsp;So&nbsp;some&nbsp;backlog&nbsp;will&nbsp;certainly&nbsp;build&nbsp;up.&lt;br&gt;<br>
&lt;br&gt;<br>
It&nbsp;will&nbsp;take&nbsp;a&nbsp;while&nbsp;for&nbsp;messages&nbsp;to&nbsp;make&nbsp;it&nbsp;into&nbsp;queues.&nbsp;This&nbsp;isn&amp;#39;t&nbsp;helped&nbsp;by&nbsp;lack&nbsp;of&nbsp;optimisation&nbsp;in&nbsp;two&nbsp;areas&nbsp;of&nbsp;the&nbsp;server&nbsp;code:&lt;br&gt;<br>
&lt;br&gt;<br>
-&nbsp;topic&nbsp;exchanges.&nbsp;As&nbsp;you&nbsp;know,&nbsp;they&nbsp;are&nbsp;currently&nbsp;totally&nbsp;unoptimised&nbsp;and&nbsp;the&nbsp;cost&nbsp;of&nbsp;determining&nbsp;the&nbsp;queues&nbsp;a&nbsp;message&nbsp;should&nbsp;be&nbsp;routed&nbsp;to&nbsp;is&nbsp;linear&nbsp;in&nbsp;the&nbsp;total&nbsp;number&nbsp;of&nbsp;bindings&nbsp;on&nbsp;the&nbsp;exchage.&nbsp;How&nbsp;many&nbsp;bindings&nbsp;are&nbsp;there&nbsp;in&nbsp;total&nbsp;in&nbsp;your&nbsp;case?&nbsp;If&nbsp;you&nbsp;can,&nbsp;please&nbsp;use&nbsp;a&nbsp;direct&nbsp;exchange.&lt;br&gt;<br>
<br>
<br>
&lt;br&gt;<br>
-&nbsp;cross-node&nbsp;routing&nbsp;in&nbsp;a&nbsp;cluster.&nbsp;A&nbsp;while&nbsp;ago&nbsp;we&nbsp;had&nbsp;to&nbsp;remove&nbsp;optimised&nbsp;cross-node&nbsp;routing&nbsp;since&nbsp;it&nbsp;turned&nbsp;out&nbsp;to&nbsp;break&nbsp;certain&nbsp;effect&nbsp;visibility&nbsp;guarantees&nbsp;required&nbsp;by&nbsp;AMQP.&nbsp;As&nbsp;a&nbsp;result,&nbsp;routing&nbsp;a&nbsp;message&nbsp;to&nbsp;N&nbsp;queues&nbsp;residing&nbsp;on&nbsp;a&nbsp;different&nbsp;node&nbsp;will&nbsp;result&nbsp;in&nbsp;N&nbsp;network&nbsp;transmissions&nbsp;of&nbsp;the&nbsp;message&nbsp;to&nbsp;that&nbsp;node,&nbsp;and&nbsp;N&nbsp;copies&nbsp;of&nbsp;the&nbsp;message&nbsp;at&nbsp;the&nbsp;node.&nbsp;If&nbsp;you&nbsp;can,&nbsp;don&amp;#39;t&nbsp;use&nbsp;clustering&nbsp;or&nbsp;at&nbsp;least&nbsp;avoid&nbsp;configurations&nbsp;where&nbsp;producers&nbsp;and&nbsp;consumers&nbsp;connect&nbsp;to&nbsp;different&nbsp;nodes.&lt;br&gt;<br>
<br>
<br>
&lt;br&gt;<br>
&lt;br&gt;<br>
Regards,&lt;br&gt;&lt;font&nbsp;color=&quot;#888888&quot;&gt;<br>
&lt;br&gt;<br>
Matthias.&lt;br&gt;<br>
&lt;/font&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;<br>

</tt>
