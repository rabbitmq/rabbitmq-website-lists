<tt>
It&nbsp;seems&nbsp;like&nbsp;one&nbsp;of&nbsp;the&nbsp;problems&nbsp;with&nbsp;round&nbsp;robin&nbsp;is&nbsp;that&nbsp;consumers&nbsp;may&nbsp;spend&lt;br&gt;more&nbsp;time&nbsp;on&nbsp;some&nbsp;messages&nbsp;than&nbsp;others,&nbsp;so&nbsp;you&nbsp;are&nbsp;depending&nbsp;on&nbsp;a&nbsp;random&lt;br&gt;distribution&nbsp;to&nbsp;even&nbsp;out&nbsp;the&nbsp;load.&lt;br&gt;&lt;br&gt;To&nbsp;help&nbsp;load&nbsp;balancing,&nbsp;could&nbsp;the&nbsp;consumers&nbsp;be&nbsp;set&nbsp;up&nbsp;to,&nbsp;instead&nbsp;of&nbsp;round&nbsp;robin,&lt;br&gt;<br>
simply&nbsp;each&nbsp;try&nbsp;to&nbsp;read&nbsp;from&nbsp;a&nbsp;common&nbsp;queue,&nbsp;and&nbsp;who&nbsp;ever&nbsp;gets&nbsp;there&nbsp;first&nbsp;gets&nbsp;the&nbsp;message.&lt;br&gt;This&nbsp;would&nbsp;mean&nbsp;that&nbsp;each&nbsp;consumer&nbsp;only&nbsp;gets&nbsp;a&nbsp;message&nbsp;when&nbsp;they&nbsp;become&nbsp;idle,&lt;br&gt;which&nbsp;seems&nbsp;like&nbsp;what&nbsp;would&nbsp;be&nbsp;wanted.&lt;br&gt;&lt;br&gt;<br>
On&nbsp;the&nbsp;producer&nbsp;side,&nbsp;if&nbsp;there&nbsp;were&nbsp;multiple&nbsp;queues,&nbsp;the&nbsp;producer&nbsp;would&nbsp;want&nbsp;to&lt;br&gt;write&nbsp;to&nbsp;the&nbsp;queue&nbsp;with&nbsp;the&nbsp;least&nbsp;amount&nbsp;of&nbsp;messages&nbsp;on&nbsp;it.&lt;br&gt;&lt;br&gt;I&amp;#39;m&nbsp;trying&nbsp;to&nbsp;learn&nbsp;AMQP&nbsp;too&nbsp;and&nbsp;this&nbsp;has&nbsp;been&nbsp;an&nbsp;interesting&nbsp;discussion&nbsp;to&nbsp;watch.&lt;br&gt;<br>
&lt;br&gt;Thanks,&lt;br&gt;&lt;br&gt;-&nbsp;Jim&lt;br&gt;&lt;br&nbsp;clear=&quot;all&quot;&gt;Jim&nbsp;Irrer&nbsp; &nbsp; &nbsp;&lt;a&nbsp;href=&quot;mailto:irrer@umich.edu&quot;&gt;irrer@umich.edu&lt;/a&gt;&nbsp; &nbsp; &nbsp; &nbsp;(734)&nbsp;647-4409&lt;br&gt;University&nbsp;of&nbsp;Michigan&nbsp;Hospital&nbsp;Radiation&nbsp;Oncology&lt;br&gt;519&nbsp;W.&nbsp;William&nbsp;St.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;Ann&nbsp;Arbor,&nbsp;MI&nbsp;48103&lt;br&gt;<br>
<br>
&lt;br&gt;&lt;br&gt;&lt;div&nbsp;class=&quot;gmail_quote&quot;&gt;On&nbsp;Tue,&nbsp;Aug&nbsp;18,&nbsp;2009&nbsp;at&nbsp;9:18&nbsp;AM,&nbsp;Paul&nbsp;Dix&nbsp;&lt;span&nbsp;dir=&quot;ltr&quot;&gt;&amp;lt;&lt;a&nbsp;href=&quot;mailto:paul@pauldix.net&quot;&gt;paul@pauldix.net&lt;/a&gt;&amp;gt;&lt;/span&gt;&nbsp;wrote:&lt;br&gt;&lt;blockquote&nbsp;class=&quot;gmail_quote&quot;&nbsp;style=&quot;border-left:&nbsp;1px&nbsp;solid&nbsp;rgb(204,&nbsp;204,&nbsp;204);&nbsp;margin:&nbsp;0pt&nbsp;0pt&nbsp;0pt&nbsp;0.8ex;&nbsp;padding-left:&nbsp;1ex;&quot;&gt;<br>
All&nbsp;of&nbsp;that&nbsp;makes&nbsp;sense.&lt;br&gt;<br>
&lt;br&gt;<br>
Let&nbsp;me&nbsp;give&nbsp;some&nbsp;more&nbsp;specifics&nbsp;about&nbsp;what&nbsp;I&amp;#39;m&nbsp;building&nbsp;and&nbsp;how&nbsp;I&amp;#39;m&lt;br&gt;<br>
hoping&nbsp;to&nbsp;use&nbsp;the&nbsp;messaging&nbsp;system.&nbsp;I&amp;#39;m&nbsp;doing&nbsp;a&nbsp;constant&nbsp;internet&lt;br&gt;<br>
crawl&nbsp;of&nbsp;sorts,&nbsp;twitter&nbsp;updates&nbsp;and&nbsp;everything&nbsp;else&nbsp;are&nbsp;in&nbsp;there.&nbsp;So&lt;br&gt;<br>
when&nbsp;something&nbsp;gets&nbsp;pulled&nbsp;down&nbsp;the&nbsp;document&nbsp;gets&nbsp;inserted&nbsp;into&nbsp;a&lt;br&gt;<br>
horizontally&nbsp;scalable&nbsp;key&nbsp;value&nbsp;store&nbsp;in&nbsp;the&nbsp;sky.&nbsp;I&nbsp;then&nbsp;want&nbsp;to&nbsp;send&lt;br&gt;<br>
a&nbsp;message&nbsp;through&nbsp;the&nbsp;system&nbsp;that&nbsp;this&nbsp;key/value&nbsp;has&nbsp;been&lt;br&gt;<br>
inserted/updated.&nbsp;This&nbsp;is&nbsp;being&nbsp;done&nbsp;by&nbsp;20-100&nbsp;boxes.&lt;br&gt;<br>
&lt;br&gt;<br>
I&nbsp;then&nbsp;want&nbsp;that&nbsp;message&nbsp;to&nbsp;be&nbsp;grabbed&nbsp;by&nbsp;a&nbsp;consumer&nbsp;where&nbsp;some&lt;br&gt;<br>
processing&nbsp;will&nbsp;happen&nbsp;and&nbsp;probably&nbsp;some&nbsp;ranking,&nbsp;relevance&nbsp;and&nbsp;other&lt;br&gt;<br>
things&nbsp;get&nbsp;written&nbsp;to&nbsp;an&nbsp;index&nbsp;somewhere&nbsp;(also&nbsp;being&nbsp;done&nbsp;by&nbsp;a&nbsp;large&lt;br&gt;<br>
number&nbsp;of&nbsp;boxes).&lt;br&gt;<br>
&lt;br&gt;<br>
So&nbsp;for&nbsp;this&nbsp;specific&nbsp;case&nbsp;I&amp;#39;m&nbsp;using&nbsp;a&nbsp;direct&nbsp;exchange&nbsp;with&nbsp;a&nbsp;single&lt;br&gt;<br>
queue&nbsp;(no&nbsp;message&nbsp;persistence&nbsp;and&nbsp;don&amp;#39;t&nbsp;bother&nbsp;keeping&nbsp;ordering).&lt;br&gt;<br>
Hundreds&nbsp;of&nbsp;producers&nbsp;are&nbsp;posting&nbsp;messages&nbsp;to&nbsp;the&nbsp;exchange&nbsp;with&nbsp;the&lt;br&gt;<br>
same&nbsp;routing&nbsp;key&nbsp;and&nbsp;hundreds&nbsp;of&nbsp;consumers&nbsp;are&nbsp;pulling&nbsp;off&nbsp;the&nbsp;queue.&lt;br&gt;<br>
It&amp;#39;s&nbsp;the&nbsp;firehose&nbsp;thing.&nbsp;Each&nbsp;message&nbsp;has&nbsp;to&nbsp;be&nbsp;processed&nbsp;once&nbsp;by&nbsp;any&lt;br&gt;<br>
one&nbsp;of&nbsp;the&nbsp;hundreds&nbsp;of&nbsp;consumers.&lt;br&gt;<br>
&lt;br&gt;<br>
I&nbsp;guess&nbsp;I&nbsp;was&nbsp;hoping&nbsp;for&nbsp;the&nbsp;flow&nbsp;management&nbsp;part&nbsp;to&nbsp;be&nbsp;handled&nbsp;by&lt;br&gt;<br>
Rabbit.&nbsp;It&nbsp;looks&nbsp;to&nbsp;me&nbsp;that&nbsp;if&nbsp;I&nbsp;want&nbsp;to&nbsp;scale&nbsp;past&nbsp;the&nbsp;ingress&lt;br&gt;<br>
capabilities&nbsp;of&nbsp;one&nbsp;queue&nbsp;or&nbsp;exchange&nbsp;I&nbsp;have&nbsp;to&nbsp;manage&nbsp;that&nbsp;on&nbsp;the&lt;br&gt;<br>
producer&nbsp;and&nbsp;consumer&nbsp;side.&lt;br&gt;<br>
&lt;br&gt;<br>
I&nbsp;can&nbsp;create&nbsp;multiple&nbsp;exchanges&nbsp;and&nbsp;bind&nbsp;to&nbsp;the&nbsp;same&nbsp;queue&nbsp;if&nbsp;the&lt;br&gt;<br>
routing&nbsp;becomes&nbsp;the&nbsp;bottleneck,&nbsp;but&nbsp;then&nbsp;the&nbsp;producers&nbsp;need&nbsp;to&nbsp;round&lt;br&gt;<br>
robin&nbsp;between&nbsp;the&nbsp;exchanges.&lt;br&gt;<br>
&lt;br&gt;<br>
I&nbsp;can&nbsp;create&nbsp;multiple&nbsp;queues&nbsp;bound&nbsp;with&nbsp;different&nbsp;routing&nbsp;keys&nbsp;(flow1,&lt;br&gt;<br>
flow2)&nbsp;if&nbsp;the&nbsp;queue&nbsp;becomes&nbsp;the&nbsp;bottleneck,&nbsp;but&nbsp;then&nbsp;the&nbsp;producer&lt;br&gt;<br>
needs&nbsp;to&nbsp;know&nbsp;to&nbsp;round&nbsp;robin&nbsp;to&nbsp;the&nbsp;different&nbsp;routing&nbsp;keys&nbsp;and&nbsp;the&lt;br&gt;<br>
consumers&nbsp;need&nbsp;to&nbsp;check&nbsp;both&nbsp;queues.&lt;br&gt;<br>
&lt;br&gt;<br>
So&nbsp;in&nbsp;essence,&nbsp;when&nbsp;I&nbsp;mentioned&nbsp;scalability,&nbsp;it&nbsp;was&nbsp;a&nbsp;reference&nbsp;to&lt;br&gt;<br>
being&nbsp;able&nbsp;to&nbsp;transparently&nbsp;scale&nbsp;the&nbsp;messaging&nbsp;system&nbsp;to&nbsp;multiple&lt;br&gt;<br>
boxes.&nbsp;And&nbsp;more&nbsp;specifically,&nbsp;I&nbsp;want&nbsp;my&nbsp;hundreds&nbsp;of&nbsp;producers&nbsp;to&nbsp;post&lt;br&gt;<br>
messages&nbsp;to&nbsp;a&nbsp;single&nbsp;exchange&nbsp;with&nbsp;a&nbsp;single&nbsp;routing&nbsp;key.&nbsp;I&nbsp;want&nbsp;my&lt;br&gt;<br>
hundreds&nbsp;of&nbsp;consumers&nbsp;to&nbsp;be&nbsp;able&nbsp;to&nbsp;consume&nbsp;messages&nbsp;off&nbsp;a&nbsp;single&lt;br&gt;<br>
queue.&nbsp;I&nbsp;want&nbsp;the&nbsp;exchange&nbsp;and&nbsp;the&nbsp;queue&nbsp;to&nbsp;be&nbsp;scalable&nbsp;(in&nbsp;the&lt;br&gt;<br>
multi-box,&nbsp;multi-process&nbsp;sense)&nbsp;where&nbsp;the&nbsp;messaging&nbsp;system&nbsp;handles&nbsp;it.&lt;br&gt;<br>
I&nbsp;want&nbsp;the&nbsp;messaging&nbsp;system&nbsp;to&nbsp;be&nbsp;scalable&nbsp;like&nbsp;the&nbsp;key/value&nbsp;store&nbsp;is&lt;br&gt;<br>
scalable.&nbsp;Transparently&nbsp;across&nbsp;many&nbsp;boxes.&lt;br&gt;<br>
&lt;br&gt;<br>
There&amp;#39;s&nbsp;really&nbsp;only&nbsp;one&nbsp;part&nbsp;of&nbsp;my&nbsp;system&nbsp;that&nbsp;has&nbsp;this&nbsp;requirement.&lt;br&gt;<br>
There&nbsp;are&nbsp;plenty&nbsp;of&nbsp;other&nbsp;aspects&nbsp;in&nbsp;which&nbsp;I&amp;#39;ll&nbsp;use&nbsp;messaging&nbsp;and&nbsp;not&lt;br&gt;<br>
have&nbsp;these&nbsp;kinds&nbsp;of&nbsp;insane&nbsp;needs.&nbsp;As&nbsp;I&nbsp;work&nbsp;more&nbsp;with&nbsp;the&nbsp;system&nbsp;it&amp;#39;s&lt;br&gt;<br>
likely&nbsp;that&nbsp;I&amp;#39;ll&nbsp;want&nbsp;to&nbsp;use&nbsp;more&nbsp;complex&nbsp;routing&nbsp;logic.&nbsp;It&amp;#39;s&nbsp;possible&lt;br&gt;<br>
I&amp;#39;ll&nbsp;want&nbsp;to&nbsp;break&nbsp;updates&nbsp;from&nbsp;domains&nbsp;into&nbsp;separate&nbsp;message&nbsp;flows.&lt;br&gt;<br>
&lt;br&gt;<br>
Thank&nbsp;you&nbsp;very&nbsp;much&nbsp;for&nbsp;being&nbsp;so&nbsp;helpful.&nbsp;Sorry&nbsp;for&nbsp;the&nbsp;lengthy&nbsp;response.&lt;br&gt;<br>
Paul&lt;br&gt;<br>
&lt;br&gt;<br>
On&nbsp;Tue,&nbsp;Aug&nbsp;18,&nbsp;2009&nbsp;at&nbsp;4:20&nbsp;AM,&nbsp;Alexis&lt;br&gt;<br>
&lt;div&gt;&lt;div&gt;&lt;/div&gt;&lt;div&nbsp;class=&quot;h5&quot;&gt;Richardson&amp;lt;&lt;a&nbsp;href=&quot;mailto:alexis.richardson@gmail.com&quot;&gt;alexis.richardson@gmail.com&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&nbsp;Paul,&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;On&nbsp;Mon,&nbsp;Aug&nbsp;17,&nbsp;2009&nbsp;at&nbsp;8:36&nbsp;PM,&nbsp;Paul&nbsp;Dix&amp;lt;&lt;a&nbsp;href=&quot;mailto:paul@pauldix.net&quot;&gt;paul@pauldix.net&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;Yeah,&nbsp;that&amp;#39;s&nbsp;what&nbsp;I&amp;#39;m&nbsp;talking&nbsp;about.&nbsp;There&nbsp;will&nbsp;probably&nbsp;be&nbsp;upwards&nbsp;of&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;a&nbsp;few&nbsp;hundred&nbsp;producers&nbsp;and&nbsp;a&nbsp;few&nbsp;hundred&nbsp;consumers.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;Cool.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;So&nbsp;one&nbsp;question&nbsp;you&nbsp;need&nbsp;to&nbsp;answer&nbsp;is:&nbsp;do&nbsp;you&nbsp;want&nbsp;all&nbsp;the&nbsp;consumers&lt;br&gt;<br>
&amp;gt;&nbsp;to&nbsp;receive&nbsp;the&nbsp;same&nbsp;messages?&nbsp; I.e.:&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;*&nbsp;are&nbsp;you&nbsp;aggregating&nbsp;all&nbsp;the&nbsp;producers&nbsp;into&nbsp;one&nbsp;&amp;#39;firehose&amp;#39;,&nbsp;and&nbsp;then&lt;br&gt;<br>
&amp;gt;&nbsp;sending&nbsp;the&nbsp;whole&nbsp;firehose&nbsp;on&nbsp;to&nbsp;all&nbsp;connected&nbsp;consumers?&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;OR&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;*&nbsp;are&nbsp;you&nbsp;planning&nbsp;to&nbsp;in&nbsp;some&nbsp;way&nbsp;share&nbsp;messages&nbsp;out&nbsp;amongst&nbsp;connected&lt;br&gt;<br>
&amp;gt;&nbsp;consumers,&nbsp;eg&nbsp;on&nbsp;a&nbsp;round&nbsp;robin&nbsp;basis&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;See&nbsp;more&nbsp;below&nbsp;re&nbsp;flow1,&nbsp;flow2...&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;The&nbsp;total&nbsp;ingress&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;is&nbsp;definitely&nbsp;what&nbsp;I&amp;#39;m&nbsp;most&nbsp;worried&nbsp;about&nbsp;right&nbsp;now.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;OK.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;Be&nbsp;aware&nbsp;that&nbsp;in&nbsp;high&nbsp;ingress&nbsp;rate&nbsp;cases&nbsp;you&nbsp;may&nbsp;be&nbsp;limited&nbsp;by&nbsp;the&lt;br&gt;<br>
&amp;gt;&nbsp;client&nbsp;egress&nbsp;rate,&nbsp;which&nbsp;is&nbsp;strongly&nbsp;implementation&nbsp;and&nbsp;platform&lt;br&gt;<br>
&amp;gt;&nbsp;dependent.&nbsp; Also,&nbsp;see&nbsp;Matthias&amp;#39;&nbsp;notes&nbsp;on&nbsp;testing&nbsp;performance,&nbsp;which&lt;br&gt;<br>
&amp;gt;&nbsp;are&nbsp;googleable&nbsp;from&nbsp;the&nbsp;rabbitmq&nbsp;archives,&nbsp;if&nbsp;you&nbsp;want&nbsp;to&nbsp;run&nbsp;some&lt;br&gt;<br>
&amp;gt;&nbsp;test&nbsp;cases&nbsp;at&nbsp;any&nbsp;point.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;Later,&nbsp;memory&nbsp;may&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;be&nbsp;a&nbsp;concern,&nbsp;but&nbsp;hopefully&nbsp;the&nbsp;consumers&nbsp;are&nbsp;pulling&nbsp;so&nbsp;quickly&nbsp;that&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;the&nbsp;queue&nbsp;never&nbsp;gets&nbsp;extremely&nbsp;large.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;Yep.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;Can&nbsp;you&nbsp;give&nbsp;me&nbsp;more&nbsp;specific&nbsp;details&nbsp;(or&nbsp;a&nbsp;pointer)&nbsp;to&nbsp;how&nbsp;the&nbsp;flow1,&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;flow2&nbsp;thing&nbsp;work&nbsp;(both&nbsp;producer&nbsp;and&nbsp;consumer&nbsp;side)?&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;Sure.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;First&nbsp;you&nbsp;need&nbsp;to&nbsp;read&nbsp;up&nbsp;on&nbsp;what&nbsp;&amp;#39;direct&nbsp;exchanges&amp;#39;&nbsp;are&nbsp;and&nbsp;how&nbsp;they&lt;br&gt;<br>
&amp;gt;&nbsp;work&nbsp;in&nbsp;AMQP.&nbsp; I&nbsp;recommend&nbsp;Jason&amp;#39;s&nbsp;intro&nbsp;to&nbsp;get&nbsp;you&nbsp;started:&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;&lt;a&nbsp;href=&quot;http://blogs.digitar.com/jjww/2009/01/rabbits-and-warrens/&quot;&nbsp;target=&quot;_blank&quot;&gt;http://blogs.digitar.com/jjww/2009/01/rabbits-and-warrens/&lt;/a&gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;More&nbsp;background&nbsp;info&nbsp;can&nbsp;be&nbsp;found&nbsp;here:&nbsp;&lt;a&nbsp;href=&quot;http://www.rabbitmq.com/how&quot;&nbsp;target=&quot;_blank&quot;&gt;www.rabbitmq.com/how&lt;/a&gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;In&nbsp;a&nbsp;nutshell,&nbsp;RabbitMQ&nbsp;will&nbsp;route&nbsp;any&nbsp;message&nbsp;it&nbsp;receives&nbsp;on&nbsp;to&nbsp;one&lt;br&gt;<br>
&amp;gt;&nbsp;or&nbsp;more&nbsp;queues.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;Each&nbsp;queue&nbsp;lives&nbsp;on&nbsp;a&nbsp;node,&nbsp;and&nbsp;nodes&nbsp;are&nbsp;members&nbsp;of&nbsp;a&nbsp;cluster.&nbsp; You&lt;br&gt;<br>
&amp;gt;&nbsp;can&nbsp;have&nbsp;one&nbsp;or&nbsp;more&nbsp;nodes&nbsp;per&nbsp;machine&nbsp;-&nbsp;a&nbsp;good&nbsp;guide&nbsp;is&nbsp;to&nbsp;have&nbsp;one&lt;br&gt;<br>
&amp;gt;&nbsp;per&nbsp;core.&nbsp; You&nbsp;can&nbsp;send&nbsp;messages&nbsp;to&nbsp;any&nbsp;node&nbsp;in&nbsp;the&nbsp;cluster&nbsp;and&nbsp;they&lt;br&gt;<br>
&amp;gt;&nbsp;will&nbsp;get&nbsp;routed&nbsp;to&nbsp;the&nbsp;right&nbsp;places&nbsp;(adding&nbsp;more&nbsp;nodes&nbsp;to&nbsp;a&nbsp;cluster&nbsp;is&lt;br&gt;<br>
&amp;gt;&nbsp;how&nbsp;you&nbsp;scale&nbsp;ingress&nbsp;and&nbsp;availability).&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;The&nbsp;routing&nbsp;model&nbsp;is&nbsp;based&nbsp;on&nbsp;message&nbsp;routing&nbsp;keys:&nbsp;queues&nbsp;receive&lt;br&gt;<br>
&amp;gt;&nbsp;messages&nbsp;whose&nbsp;routing&nbsp;keys&nbsp;match&nbsp;routing&nbsp;patterns&nbsp;(&amp;quot;bindings&amp;quot;).&nbsp; Note&lt;br&gt;<br>
&amp;gt;&nbsp;that&nbsp;multiple&nbsp;queues&nbsp;can&nbsp;request&nbsp;messages&nbsp;matching&nbsp;the&nbsp;same&nbsp;key,&lt;br&gt;<br>
&amp;gt;&nbsp;giving&nbsp;you&nbsp;1-many&nbsp;pubsub.&nbsp; This&nbsp;is&nbsp;explained&nbsp;in&nbsp;Jason&amp;#39;s&nbsp;article.&nbsp; I&lt;br&gt;<br>
&amp;gt;&nbsp;suggest&nbsp;you&nbsp;use&nbsp;the&nbsp;&amp;#39;direct&nbsp;exchange&amp;#39;&nbsp;routing&nbsp;model,&nbsp;in&nbsp;which&nbsp;each&lt;br&gt;<br>
&amp;gt;&nbsp;message&nbsp;has&nbsp;one&nbsp;routing&nbsp;key,&nbsp;e.g.:&nbsp;&amp;quot;flow1&amp;quot;,&nbsp;&amp;quot;flow2&amp;quot;.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;Take&nbsp;a&nbsp;look&nbsp;at&nbsp;the&nbsp;article&nbsp;and&nbsp;let&nbsp;us&nbsp;know&nbsp;if&nbsp;it&nbsp;all&nbsp;makes&nbsp;sense.&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&nbsp;alexis&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;Thanks,&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;Paul&lt;br&gt;<br>
&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;On&nbsp;Mon,&nbsp;Aug&nbsp;17,&nbsp;2009&nbsp;at&nbsp;2:32&nbsp;PM,&nbsp;Alexis&lt;br&gt;<br>
&amp;gt;&amp;gt;&nbsp;Richardson&amp;lt;&lt;a&nbsp;href=&quot;mailto:alexis.richardson@gmail.com&quot;&gt;alexis.richardson@gmail.com&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;On&nbsp;Mon,&nbsp;Aug&nbsp;17,&nbsp;2009&nbsp;at&nbsp;5:22&nbsp;PM,&nbsp;Paul&nbsp;Dix&amp;lt;&lt;a&nbsp;href=&quot;mailto:paul@pauldix.net&quot;&gt;paul@pauldix.net&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;So&nbsp;what&nbsp;exactly&nbsp;does&nbsp;option&nbsp;1&nbsp;look&nbsp;like?&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;It&nbsp;sounds&nbsp;like&nbsp;it&amp;#39;s&nbsp;possible&nbsp;to&nbsp;have&nbsp;a&nbsp;queue&nbsp;with&nbsp;the&nbsp;same&nbsp;id&nbsp;on&nbsp;two&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;different&nbsp;nodes&nbsp;bound&nbsp;to&nbsp;the&nbsp;same&nbsp;exchange.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;Not&nbsp;quite.&nbsp; Same&nbsp;routing&nbsp;-&nbsp;two&nbsp;queues,&nbsp;two&nbsp;ids.&nbsp; Actually&nbsp;now&nbsp;that&nbsp;I&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;think&nbsp;about&nbsp;it&nbsp;that&nbsp;won&amp;#39;t&nbsp;give&nbsp;you&nbsp;exactly&nbsp;what&nbsp;you&nbsp;need.&nbsp; More&nbsp;below.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Will&nbsp;the&nbsp;exchange&nbsp;will&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;then&nbsp;round&nbsp;robin&nbsp;the&nbsp;messages&nbsp;to&nbsp;the&nbsp;two&nbsp;different&nbsp;queues?&nbsp;If&nbsp;so,&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;that&amp;#39;s&nbsp;exactly&nbsp;what&nbsp;I&amp;#39;m&nbsp;looking&nbsp;for.&nbsp;I&nbsp;don&amp;#39;t&nbsp;really&nbsp;care&nbsp;about&nbsp;order&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;on&nbsp;this&nbsp;queue.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;No&nbsp;it&nbsp;won&amp;#39;t&nbsp;and&nbsp;that&amp;#39;s&nbsp;why&nbsp;my&nbsp;suggestion&nbsp;was&nbsp;wrong.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;Round&nbsp;robin&nbsp;does&nbsp;occur&nbsp;when&nbsp;you&nbsp;have&nbsp;two&nbsp;consumers&nbsp;(clients)&nbsp;connected&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;to&nbsp;one&nbsp;queue.&nbsp; This&nbsp;WILL&nbsp;help&nbsp;you&nbsp;by&nbsp;draining&nbsp;the&nbsp;queue&nbsp;faster,&nbsp;if&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;memory&nbsp;is&nbsp;a&nbsp;limitation.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;If&nbsp;total&nbsp;ingress&nbsp;is&nbsp;the&nbsp;limitation&nbsp;you&nbsp;can&nbsp;increase&nbsp;that&nbsp;by&nbsp;splitting&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;the&nbsp;flow.&nbsp; Suppose&nbsp;you&nbsp;start&nbsp;with&nbsp;one&nbsp;queue&nbsp;bound&nbsp;once&nbsp;to&nbsp;one&nbsp;exchange&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;with&nbsp;key&nbsp;&amp;quot;flow1&amp;quot;.&nbsp; Then&nbsp;all&nbsp;messages&nbsp;with&nbsp;routing&nbsp;key&nbsp;flow1&nbsp;will&nbsp;go&nbsp;to&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;that&nbsp;queue.&nbsp; When&nbsp;load&nbsp;is&nbsp;heavy,&nbsp;add&nbsp;a&nbsp;queue&nbsp;with&nbsp;key&nbsp;&amp;quot;flow2&amp;quot;,&nbsp;on&nbsp;a&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;second&nbsp;node.&nbsp; Then,&nbsp;alternate&nbsp;(if&nbsp;you&nbsp;prefer,&nbsp;randomly)&nbsp;between&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;routing&nbsp;keys&nbsp;flow1&nbsp;and&nbsp;flow2.&nbsp; This&nbsp;will&nbsp;spread&nbsp;the&nbsp;load&nbsp;as&nbsp;you&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;require.&nbsp; And&nbsp;so&nbsp;on,&nbsp;for&nbsp;more&nbsp;queues.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;You&nbsp;can&nbsp;make&nbsp;this&nbsp;part&nbsp;of&nbsp;a&nbsp;load&nbsp;balancing&nbsp;layer&nbsp;on&nbsp;the&nbsp;server&nbsp;side,&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;so&nbsp;that&nbsp;clients&nbsp;don&amp;#39;t&nbsp;have&nbsp;to&nbsp;be&nbsp;coded&nbsp;too&nbsp;much.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;Is&nbsp;this&nbsp;along&nbsp;the&nbsp;lines&nbsp;of&nbsp;what&nbsp;you&nbsp;need?&nbsp; Let&nbsp;me&nbsp;know,&nbsp;and&nbsp;I&nbsp;can&nbsp;elaborate.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&nbsp;alexis&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Thanks,&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Paul&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;On&nbsp;Mon,&nbsp;Aug&nbsp;17,&nbsp;2009&nbsp;at&nbsp;10:55&nbsp;AM,&nbsp;Alexis&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Richardson&amp;lt;&lt;a&nbsp;href=&quot;mailto:alexis.richardson@gmail.com&quot;&gt;alexis.richardson@gmail.com&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Paul&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;On&nbsp;Mon,&nbsp;Aug&nbsp;17,&nbsp;2009&nbsp;at&nbsp;3:34&nbsp;PM,&nbsp;Paul&nbsp;Dix&amp;lt;&lt;a&nbsp;href=&quot;mailto:paul@pauldix.net&quot;&gt;paul@pauldix.net&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Sorry&nbsp;for&nbsp;the&nbsp;confusion.&nbsp;I&nbsp;mean&nbsp;scalability&nbsp;on&nbsp;a&nbsp;single&nbsp;queue.&nbsp;Say&nbsp;I&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;want&nbsp;to&nbsp;push&nbsp;20k&nbsp;messages&nbsp;per&nbsp;second&nbsp;through&nbsp;a&nbsp;single&nbsp;queue.&nbsp;If&nbsp;a&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;single&nbsp;node&nbsp;can&amp;#39;t&nbsp;handle&nbsp;that&nbsp;it&nbsp;seems&nbsp;I&amp;#39;m&nbsp;out&nbsp;of&nbsp;luck.&nbsp;That&nbsp;is,&nbsp;if&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;I&amp;#39;m&nbsp;understanding&nbsp;how&nbsp;things&nbsp;work.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;You&nbsp;can&nbsp;in&nbsp;principle&nbsp;just&nbsp;add&nbsp;more&nbsp;nodes&nbsp;to&nbsp;the&nbsp;cluster.&nbsp; More&nbsp;details&nbsp;below.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;So&nbsp;I&nbsp;guess&nbsp;I&amp;#39;m&nbsp;not&nbsp;worried&nbsp;about&nbsp;total&nbsp;queue&nbsp;size,&nbsp;but&nbsp;queue&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;throughput&nbsp;(although&nbsp;size&nbsp;may&nbsp;become&nbsp;an&nbsp;issue,&nbsp;I&amp;#39;m&nbsp;not&nbsp;sure).&nbsp;It&nbsp;seems&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;the&nbsp;solution&nbsp;is&nbsp;to&nbsp;split&nbsp;out&nbsp;across&nbsp;multiple&nbsp;queues,&nbsp;but&nbsp;I&nbsp;was&nbsp;hoping&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;to&nbsp;avoid&nbsp;that&nbsp;since&nbsp;it&nbsp;will&nbsp;add&nbsp;a&nbsp;layer&nbsp;of&nbsp;complexity&nbsp;to&nbsp;my&nbsp;producers&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;and&nbsp;consumers.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;1.&nbsp;To&nbsp;maximise&nbsp;throughput,&nbsp;don&amp;#39;t&nbsp;use&nbsp;persistence.&nbsp; To&nbsp;make&nbsp;it&nbsp;bigger,&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;forget&nbsp;about&nbsp;ordering.&nbsp; So&nbsp;for&nbsp;example,&nbsp;you&nbsp;can&nbsp;easily&nbsp;have&nbsp;two&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;queues,&nbsp;one&nbsp;per&nbsp;node,&nbsp;subscribed&nbsp;to&nbsp;the&nbsp;same&nbsp;direct&nbsp;exchange&nbsp;with&nbsp;the&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;same&nbsp;key,&nbsp;and&nbsp;you&nbsp;ought&nbsp;to&nbsp;double&nbsp;throughput&nbsp;(assuming&nbsp;all&nbsp;other&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;things&nbsp;being&nbsp;equal&nbsp;and&nbsp;fair).&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;2.&nbsp;If&nbsp;you&nbsp;want&nbsp;to&nbsp;be&nbsp;both&nbsp;fast&nbsp;and&nbsp;&amp;#39;reliable&amp;#39;&nbsp;(no&nbsp;loss&nbsp;of&nbsp;acked&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;messages),&nbsp;then&nbsp;add&nbsp;more&nbsp;queues&nbsp;and&nbsp;make&nbsp;them&nbsp;durable,&nbsp;and&nbsp;set&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;messages&nbsp;to&nbsp;be&nbsp;persistent.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;3.&nbsp;If&nbsp;you&nbsp;want&nbsp;to&nbsp;preserve&nbsp;ordering,&nbsp;label&nbsp;each&nbsp;message&nbsp;with&nbsp;an&nbsp;ID&nbsp;and&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;dedup&nbsp;at&nbsp;the&nbsp;endpoints.&nbsp; This&nbsp;does&nbsp;as&nbsp;you&nbsp;say,&nbsp;add&nbsp;some&nbsp;small&nbsp;noise&nbsp;to&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;your&nbsp;producers&nbsp;and&nbsp;consumers,&nbsp;but&nbsp;the&nbsp;above&nbsp;two&nbsp;options&nbsp;1&nbsp;and&nbsp;2,&nbsp;do&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;not.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;I&nbsp;don&amp;#39;t&nbsp;think&nbsp;I&nbsp;understand&nbsp;how&nbsp;using&nbsp;Linux-HA&nbsp;with&nbsp;clustering&nbsp;would&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;lead&nbsp;to&nbsp;a&nbsp;splitting&nbsp;a&nbsp;single&nbsp;queue&nbsp;across&nbsp;multiple&nbsp;nodes.&nbsp;I&amp;#39;m&nbsp;not&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;familiar&nbsp;with&nbsp;HA,&nbsp;but&nbsp;it&nbsp;looked&nbsp;like&nbsp;it&nbsp;was&nbsp;a&nbsp;solution&nbsp;to&nbsp;provide&nbsp;a&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;replicated&nbsp;failover.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;You&nbsp;are&nbsp;right&nbsp;that&nbsp;HA&nbsp;techniques,&nbsp;indeed&nbsp;any&nbsp;kind&nbsp;of&nbsp;queue&nbsp;replication&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;or&nbsp;replicated&nbsp;failover,&nbsp;will&nbsp;not&nbsp;help&nbsp;you&nbsp;here.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;What&nbsp;you&nbsp;want&nbsp;is&nbsp;&amp;#39;flow&nbsp;over&amp;#39;&nbsp;ie.&nbsp;&amp;quot;when&nbsp;load&nbsp;is&nbsp;high,&nbsp;make&nbsp;a&nbsp;new&nbsp;node&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;with&nbsp;the&nbsp;same&nbsp;routing&nbsp;info&amp;quot;.&nbsp; This&nbsp;is&nbsp;certainly&nbsp;doable.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;alexis&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Thanks&nbsp;again,&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Paul&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;On&nbsp;Mon,&nbsp;Aug&nbsp;17,&nbsp;2009&nbsp;at&nbsp;10:24&nbsp;AM,&nbsp;Tony&nbsp;Garnock-Jones&amp;lt;&lt;a&nbsp;href=&quot;mailto:tonyg@lshift.net&quot;&gt;tonyg@lshift.net&lt;/a&gt;&amp;gt;&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Paul&nbsp;Dix&nbsp;wrote:&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Do&nbsp;you&nbsp;have&nbsp;a&nbsp;roadmap&nbsp;for&nbsp;when&nbsp;a&nbsp;scalable&nbsp;queue&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;will&nbsp;be&nbsp;available?&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;If&nbsp;by&nbsp;&amp;quot;scalable&amp;quot;&nbsp;you&nbsp;mean&nbsp;&amp;quot;replicated&amp;quot;,&nbsp;then&nbsp;that&amp;#39;s&nbsp;available&nbsp;now,&nbsp;by&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;configuration&nbsp;along&nbsp;the&nbsp;lines&nbsp;I&nbsp;hinted&nbsp;at&nbsp;in&nbsp;my&nbsp;previous&nbsp;message.&nbsp;Adding&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;clustering&nbsp;into&nbsp;the&nbsp;mix&nbsp;can&nbsp;help&nbsp;increase&nbsp;capacity,&nbsp;on&nbsp;top&nbsp;of&nbsp;that&nbsp;(at&nbsp;a&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;certain&nbsp;cost&nbsp;in&nbsp;configuration&nbsp;complexity).&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;If&nbsp;instead&nbsp;you&nbsp;mean&nbsp;&amp;quot;exceeding&nbsp;RAM+swap&nbsp;size&amp;quot;,&nbsp;we&amp;#39;re&nbsp;hoping&nbsp;to&nbsp;have&nbsp;that&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;for&nbsp;the&nbsp;1.7&nbsp;release&nbsp;--&nbsp;which&nbsp;ought&nbsp;to&nbsp;be&nbsp;out&nbsp;within&nbsp;a&nbsp;month&nbsp;or&nbsp;so.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Just&nbsp;to&nbsp;give&nbsp;you&nbsp;a&nbsp;little&nbsp;more&nbsp;information&nbsp;on&nbsp;what&nbsp;I&amp;#39;m&nbsp;doing,&nbsp;I&amp;#39;m&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;building&nbsp;a&nbsp;live&nbsp;search/aggregation&nbsp;system.&nbsp;I&amp;#39;m&nbsp;hoping&nbsp;to&nbsp;push&nbsp;updates&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;of&nbsp;a&nbsp;constant&nbsp;internet&nbsp;crawl&nbsp;through&nbsp;the&nbsp;messaging&nbsp;system&nbsp;so&nbsp;workers&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;can&nbsp;analyze&nbsp;the&nbsp;content&nbsp;and&nbsp;build&nbsp;indexes&nbsp;as&nbsp;everything&nbsp;comes&nbsp;in.&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Sounds&nbsp;pretty&nbsp;cool!&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;Tony&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;--&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp; [][][]&nbsp;Tony&nbsp;Garnock-Jones&nbsp; &nbsp; &nbsp;|&nbsp;Mob:&nbsp;+44&nbsp;(0)7905&nbsp;974&nbsp;211&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp; &nbsp;[][]&nbsp;LShift&nbsp;Ltd&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;|&nbsp;Tel:&nbsp;+44&nbsp;(0)20&nbsp;7729&nbsp;7060&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp; []&nbsp; []&nbsp;&lt;a&nbsp;href=&quot;http://www.lshift.net/&quot;&nbsp;target=&quot;_blank&quot;&gt;http://www.lshift.net/&lt;/a&gt;&nbsp;|&nbsp;Email:&nbsp;&lt;a&nbsp;href=&quot;mailto:tonyg@lshift.net&quot;&gt;tonyg@lshift.net&lt;/a&gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;_______________________________________________&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;rabbitmq-discuss&nbsp;mailing&nbsp;list&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;&lt;a&nbsp;href=&quot;mailto:rabbitmq-discuss@lists.rabbitmq.com&quot;&gt;rabbitmq-discuss@lists.rabbitmq.com&lt;/a&gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&nbsp;&lt;a&nbsp;href=&quot;http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss&quot;&nbsp;target=&quot;_blank&quot;&gt;http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss&lt;/a&gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&amp;gt;&lt;br&gt;<br>
&amp;gt;&lt;br&gt;<br>
&lt;br&gt;<br>
_______________________________________________&lt;br&gt;<br>
rabbitmq-discuss&nbsp;mailing&nbsp;list&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;mailto:rabbitmq-discuss@lists.rabbitmq.com&quot;&gt;rabbitmq-discuss@lists.rabbitmq.com&lt;/a&gt;&lt;br&gt;<br>
&lt;a&nbsp;href=&quot;http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss&quot;&nbsp;target=&quot;_blank&quot;&gt;http://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss&lt;/a&gt;&lt;br&gt;<br>
&lt;/div&gt;&lt;/div&gt;&lt;/blockquote&gt;&lt;/div&gt;&lt;br&gt;<br>

</tt>
