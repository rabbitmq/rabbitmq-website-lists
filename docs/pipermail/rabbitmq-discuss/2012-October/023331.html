<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] Batching messages
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Batching%20messages&In-Reply-To=%3C0AB02CE2-48A6-4F1D-A19B-7B88B2C7EEA7%40kvrgic.se%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="023334.html">
   <LINK REL="Next"  HREF="023333.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] Batching messages</H1>
    <B>Srdan Kvrgic</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Batching%20messages&In-Reply-To=%3C0AB02CE2-48A6-4F1D-A19B-7B88B2C7EEA7%40kvrgic.se%3E"
       TITLE="[rabbitmq-discuss] Batching messages">srdan at kvrgic.se
       </A><BR>
    <I>Thu Oct 25 06:33:47 BST 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="023334.html">[rabbitmq-discuss] Can a downed node affect responsive of HTTP queries to other nodes?
</A></li>
        <LI>Next message: <A HREF="023333.html">[rabbitmq-discuss] Batching messages
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#23331">[ date ]</a>
              <a href="thread.html#23331">[ thread ]</a>
              <a href="subject.html#23331">[ subject ]</a>
              <a href="author.html#23331">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hi,

Short story:
Are there any plans to support batching of messages within the rabbitmq eco-system?


Long story:
We at Burtcorp are using rabbit-mq to send relatively small messages (1kb) at rates of a couple of thousand per second. We noticed at one point that there seemed to be a lot of overhead with handling individual messages so we started lumping a bunch of messages in a batch and sending that. The throughput sky-rocketed.

I did some benchmarks back in the day (<A HREF="http://goo.gl/wmEmD">http://goo.gl/wmEmD</A>). The graphs on page 14 and 16 illustrate the extremes of this point. Maxing out sending 10 byte messages at 5000/s or 10kb at 1200/s.

So the throughput boost is great, as could be expected. There's a reason Amazon bundles your books together when shipping them - the overhead of sending each individually would put them out of business.

Still, there are issues with our manual batching. The problem is when we screw up processing a message. The paradigm is to reject the message you can't process but the problem is we got a batch of 10 messages and we only failed processing one. We can't reject the whole batch. That would mean re-processing the 9 messages that got processed the first time around..

Optimally you would want a system that sends and receives batches of messages but allows you to reject single messages. Have your cake and eat it, as it were...

Also automatic de-/compression in the driver. That also was a great performance boost when the batches started getting big. Lzf ftw!

You think?

Kind regards,
Srdan


</PRE>

























<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="023334.html">[rabbitmq-discuss] Can a downed node affect responsive of HTTP queries to other nodes?
</A></li>
	<LI>Next message: <A HREF="023333.html">[rabbitmq-discuss] Batching messages
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#23331">[ date ]</a>
              <a href="thread.html#23331">[ thread ]</a>
              <a href="subject.html#23331">[ subject ]</a>
              <a href="author.html#23331">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
