<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Outage%20with%203-node%20RabbitMQ%203.1.3%20Cluster&In-Reply-To=%3CCAOHkZxPLAJqBZcYuV9cOFigiKk%3D9C5e1zEuZd5bP5j_jm0WSXA%40mail.gmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="031714.html">
   <LINK REL="Next"  HREF="031739.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster</H1>
    <B>Matt Wise</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20Outage%20with%203-node%20RabbitMQ%203.1.3%20Cluster&In-Reply-To=%3CCAOHkZxPLAJqBZcYuV9cOFigiKk%3D9C5e1zEuZd5bP5j_jm0WSXA%40mail.gmail.com%3E"
       TITLE="[rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster">matt at nextdoor.com
       </A><BR>
    <I>Wed Nov  6 16:02:45 GMT 2013</I>
    <P><UL>
        <LI>Previous message: <A HREF="031714.html">[rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster
</A></li>
        <LI>Next message: <A HREF="031739.html">[rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#31738">[ date ]</a>
              <a href="thread.html#31738">[ thread ]</a>
              <a href="subject.html#31738">[ subject ]</a>
              <a href="author.html#31738">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>See comments inline.


On Wed, Nov 6, 2013 at 2:37 AM, Tim Watson &lt;<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">tim at rabbitmq.com</A>&gt; wrote:

&gt;<i> Hi Matt,
</I>&gt;<i>
</I>&gt;<i> Sorry to hear you've been running into problems.
</I>&gt;<i>
</I>&gt;<i> On 5 Nov 2013, at 22:05, Matt Wise wrote:
</I>&gt;<i>
</I>&gt;<i> &gt; (sorry if this gets posted twice.. first email never seemed to make it
</I>&gt;<i> to the list)
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Hey... I had a pretty rough time today with a 3-node RabbitMQ 3.1.3
</I>&gt;<i> cluster thats under pretty heavy use (6-7 million messages per day -- 100MB
</I>&gt;<i> peak bandwidth per node). I want to pose a few questions here. First off,
</I>&gt;<i> here's the basic configuration though.
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Configuration:
</I>&gt;<i> &gt;   serverA, serverB and serverC are all configured with RabbitMQ 3.1.3.
</I>&gt;<i> They each are configured via Puppet ... and Puppet uses a dynamic node
</I>&gt;<i> discovery plugin (zookeeper) to find the nodes. The node lists are
</I>&gt;<i> hard-coded into the rabbitmq.config file. A dynamic server list generator
</I>&gt;<i> supplies Puppet with this list of servers (and is not really necessary to
</I>&gt;<i> describe here in this email).
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; Scenario:
</I>&gt;<i> &gt;   A momentary configuration blip caused serverA and serverB to begin
</I>&gt;<i> reconfiguring their rabbitmq.config files... when they did this, they also
</I>&gt;<i> both issued a 'service rabbitmq restart' command. This command took
</I>&gt;<i> 40+minutes and ultimately failed. During this failure, RabbitMQ was
</I>&gt;<i> technically running and accepting connections to the TCP ports ... but it
</I>&gt;<i> would not actually answer any queries. Commands like list_queues would hang
</I>&gt;<i> indefinitely.
</I>&gt;<i> &gt;
</I>&gt;<i>
</I>&gt;<i> What ha recovery policy (if any) do you have set up? A and B might get a
</I>&gt;<i> different &quot;view of the world&quot; set up in their respective rabbitmq.config
</I>&gt;<i> files (either to each other and/or to C) and then get restarted, but this
</I>&gt;<i> should affect their view of the cluster, because as per
</I>&gt;<i> <A HREF="http://www.rabbitmq.com/clustering.html:">http://www.rabbitmq.com/clustering.html:</A>
</I>&gt;<i>
</I>&gt;<i> &quot;Note that the cluster configuration is applied only to fresh nodes. A
</I>&gt;<i> fresh nodes is a node which has just been reset or is being start for the
</I>&gt;<i> first time. Thus, the automatic clustering won't take place after restarts
</I>&gt;<i> of nodes. This means that any change to the clustering via rabbitmqctl will
</I>&gt;<i> take precedence over the automatic clustering configuration.&quot;
</I>&gt;<i>
</I>&gt;<i>
</I>So far we've taken the approach that clustering configuration should be
hard-coded into the rabbitmq.config files. This works well in explicitly
defining all of the hosts in a cluster on every machine, but it also means
that adding a 4th node to a 3-node cluster will cause the 3 running live
nodes to do a full service restart, which is bad. Our rabbitmq.config
though is identical on all of the machines (other than the server-list,
which may have been in-flux when Puppet was restarting these services)

[
&gt;<i>         {rabbit, [
</I>&gt;<i>                 {log_levels, [{connection, warning}]},
</I>&gt;<i>                 {cluster_partition_handling,pause_minority},
</I>&gt;<i>                 {tcp_listeners, [ 5672 ] },
</I>&gt;<i>                 {ssl_listeners, [ 5673 ] },
</I>&gt;<i>                 {ssl_options, [{cacertfile,&quot;/etc/rabbitmq/ssl/cacert.pem&quot;},
</I>&gt;<i>                         {certfile,&quot;/etc/rabbitmq/ssl/cert.pem&quot;},
</I>&gt;<i>                         {keyfile,&quot;/etc/rabbitmq/ssl/key.pem&quot;},
</I>&gt;<i>                         {verify,verify_peer},
</I>&gt;<i>                         {fail_if_no_peer_cert,true}
</I>&gt;<i>                 ]},
</I>&gt;<i>                 {cluster_nodes,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at i-23cf477b</A>', '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at i-07d8bc5f</A>',
</I>&gt;<i> '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at i-a3291cf8</A>']}
</I>&gt;<i>         ]}
</I>&gt;<i> ].
</I>


&gt;<i> &gt; Questions:
</I>&gt;<i> &gt;   1. We only had ~2500 messages in the queues (they are HA'd and
</I>&gt;<i> durable). The policy is { 'ha-mode': 'all' }. When serverA and serverB
</I>&gt;<i> restarted, why did they never come up? Unfortunately in the restart
</I>&gt;<i> process, they blew away their log files as well which makes this really
</I>&gt;<i> tough to troubleshoot.
</I>&gt;<i>
</I>&gt;<i> It's nigh on impossible to guess what might've gone wrong without any log
</I>&gt;<i> files to verify against. We could sit and stare at all the relevant code
</I>&gt;<i> for weeks and not spot a bug that's been triggered here, since if it were
</I>&gt;<i> obvious we would've fixed it already.
</I>&gt;<i>
</I>&gt;<i> If you can give us a very precise set of steps (and timings) that led to
</I>&gt;<i> this situation, I can try and replicate what you've seen, but I don't fancy
</I>&gt;<i> my chances to be honest.
</I>&gt;<i>
</I>
Its a tough one for us to reproduce.. but I think the closest steps would
be:

  1. Create a 3-node cluster... configured with similar config to the one I
pasted above.
  2. Create enough publishers and subscribers that you have a few hundred
messages/sec going through the three machines.
  3. On MachineA and MachineC, remove MachineB from the config file.
  4. Restart MachineA's rabbitmq daemon using init script
  5. Wait 3 minutes... theoretically #4 is still in process.. now issue the
same restart to MachineC.

  Fail.

Thats our best guess right now.. but agreed, the logs are a problem. Can we
configure RabbitMQ to log through syslog for the future?


&gt;<i> &gt;
</I>&gt;<i> &gt;   2. I know that restarting serverA and serverB at nearly the same time
</I>&gt;<i> is obviously a bad idea -- we'll be implementing some changes so this
</I>&gt;<i> doesn't happen again -- but could this have lead to data corruption?
</I>&gt;<i>
</I>&gt;<i> It's possible, though obviously that shouldn't really happen. How close
</I>&gt;<i> were the restarts to one another? How many HA queues were mirrored across
</I>&gt;<i> these nodes, and were they all very busy (as your previous comment about
</I>&gt;<i> load seems to suggest)? We could try replicating that scenario in our
</I>&gt;<i> tests, though it's not easy to get the timing right and obviously the
</I>&gt;<i> existence of network infrastructure on which the nodes are running won't be
</I>&gt;<i> the same (and that can make a surprisingly big difference IME).
</I>&gt;<i>
</I>
The restarts were within a few minutes of each other. There are 5 queues,
and all 5 queues are set to mirror to 'all' nodes in the cluster. They were
busy, but no more than maybe 100 messages/sec coming in/out.


&gt;<i>
</I>&gt;<i> &gt; Once the entire RabbitMQ farm was shut down, we actually were forced to
</I>&gt;<i> move the rabbitmq data directory out of the way and start up the farm
</I>&gt;<i> completely with blank databases. It seemed that RabbitMQ 3.1.3 really did
</I>&gt;<i> not want to recover from this failure. Any thoughts?
</I>&gt;<i> &gt;
</I>&gt;<i> &gt;   3. Lastly .. in the event of future failures, what tools are there for
</I>&gt;<i> recovering our Mnesia databases? Is there any way we can dump out the data
</I>&gt;<i> into some raw form, and then import it back into a new fresh cluster?
</I>&gt;<i> &gt;
</I>&gt;<i>
</I>&gt;<i> I'm afraid there are not, at least not &quot;off the shelf&quot; ones anyway. If you
</I>&gt;<i> are desperate to recover important production data however, I'm sure we
</I>&gt;<i> could explore the possibility of trying to help with that somehow. Let me
</I>&gt;<i> know and I'll make some enquiries at this end.
</I>&gt;<i>
</I>
At this point we can move on from the data loss... but it does make for an
interesting issue. Having tools to analyze the Mnesia DB and get &quot;most of&quot;
the messages out in some format where they could be re-injected into a
fresh cluster would be an incredibly useful tool. I wonder how hard it is
to do?


&gt;<i> Cheers,
</I>&gt;<i> Tim
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> rabbitmq-discuss mailing list
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-discuss at lists.rabbitmq.com</A>
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss</A>
</I>&gt;<i>
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20131106/c319f978/attachment.htm">http://lists.rabbitmq.com/pipermail/rabbitmq-discuss/attachments/20131106/c319f978/attachment.htm</A>&gt;
</PRE>










<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="031714.html">[rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster
</A></li>
	<LI>Next message: <A HREF="031739.html">[rabbitmq-discuss] Outage with 3-node RabbitMQ 3.1.3 Cluster
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#31738">[ date ]</a>
              <a href="thread.html#31738">[ thread ]</a>
              <a href="subject.html#31738">[ subject ]</a>
              <a href="author.html#31738">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
