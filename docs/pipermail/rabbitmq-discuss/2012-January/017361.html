<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%20broker%20crashing%20under%20heavy%20load%0A%09with%20mirrored%20queues&In-Reply-To=%3C16d4069e-726a-4121-b412-341cff384c4b%40ck5g2000vbb.googlegroups.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017317.html">
   <LINK REL="Next"  HREF="017400.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues</H1>
    <B>Venkat</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%20broker%20crashing%20under%20heavy%20load%0A%09with%20mirrored%20queues&In-Reply-To=%3C16d4069e-726a-4121-b412-341cff384c4b%40ck5g2000vbb.googlegroups.com%3E"
       TITLE="[rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues">vveludan at gmail.com
       </A><BR>
    <I>Fri Jan 13 05:03:33 GMT 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="017317.html">[rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues
</A></li>
        <LI>Next message: <A HREF="017400.html">[rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17361">[ date ]</a>
              <a href="thread.html#17361">[ thread ]</a>
              <a href="subject.html#17361">[ subject ]</a>
              <a href="author.html#17361">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>&gt;<i> (You did start_app after the cluster command, didn't you??? &#160;:-))
</I>
Hi Steve I did restart the the app.
Following are the steps I have performed on both nodes:

Starting the second node t-4:
./rabbitmq-server -detached

Steps to join t-4 node to t-2:
 /usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/rabbitmqctl stop_app

 /usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/rabbitmqctl reset

 /usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/rabbitmqctl cluster
<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>
 Clustering node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>' with ['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A>',
                                         '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>'] ...
...done.

/usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/rabbitmqctl start_app
Starting node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>' ...
...done.

Running cluster_status on t-4 node:
[<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">ecloud at t-4</A> sbin]$ /usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/
rabbitmqctl cluster_status
Cluster status of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>' ...
[{nodes,[{disc,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A>']}]},
 {running_nodes,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>']}]
...done.

Running cluster_status on t-2 node (to which t-4 is joined):
[<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">ecloud at t-2</A> vv]$ /usr/lib/rabbitmq/lib/rabbitmq_server-2.7.1/sbin/
rabbitmqctl cluster_status
Cluster status of node '<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A>' ...
[{nodes,[{disc,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A>']}]},
 {running_nodes,['<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-4</A>','<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A>']}]
...done.

---------------------------------------------------------------------------------------------------------------
I have been testing with HA feature with different scenario.
In my previous test the messages were pumped in with a SOAP service.
This was pumping messages at slow rate.
I have used a test that pumps in messages by calling plain Java
Service. I have also increased messages pumping in from 20K to 40K.
I am finding that messages are lost while pumping into the queue.
As you mentioned earlier this could be due to connecting to dead
broker.
I modified the producer code by giving 2 seconds lapse of time and
setting a fresh ConnectionFactory as follows:
	@Override
	public void convertAndSend(final Object message) throws AmqpException
{
		MessageProperties props = null;
		try {
			props = new MessageProperties();
			props.setDeliveryMode(MessageDeliveryMode.PERSISTENT);   //setting
delivery mode as PERSISTENT
			send(getMessageConverter().toMessage(message, props));
		} catch (AmqpException amqpe) {
			System.out.println(&quot;Exception occurred while sending:
&quot;+amqpe.getMessage());
			try {
				Thread.sleep(2000);
			} catch (InterruptedException e) {
				e.printStackTrace();
			}
			Properties props1 = FrameworkServiceLocator.getInstance().
	
getCommonsConfigurationService(ServiceConstants.DMB_COMMONS_CONFIG_SERVICE).
			getProperties(CommonsConfigurationConstants.RABBIT_MQ_CONFIG_NAME);
			String rabbitMQUser =
props1.getProperty(CommonsConfigurationConstants.RABBITMQ_USER);
			String rabbitMQPassword =
props1.getProperty(CommonsConfigurationConstants.RABBITMQ_PASSWORD);
			String rabbitMQHost =
props1.getProperty(CommonsConfigurationConstants.RABBITMQ_HOST);
			String rabbitMQChannelCacheSize =
props1.getProperty(CommonsConfigurationConstants.RABBITMQ_CHANNEL_CACHE_SIZE);
			CachingConnectionFactory connectionFactory = new
CachingConnectionFactory(rabbitMQHost);
	
connectionFactory.setChannelCacheSize(Integer.parseInt(rabbitMQChannelCacheSize));
			connectionFactory.setUsername(rabbitMQUser);
			connectionFactory.setPassword(rabbitMQPassword);
			setConnectionFactory(connectionFactory);
			try {
				send(getMessageConverter().toMessage(message, props));
			} catch(AmqpException e1) {
				e1.printStackTrace();
			}
		}
	}

After this change is made, I saw an exception occurred once while
sending 40K messages which is as follows:
java.net.SocketException: Broken pipe.
 I have run the test 10-15 times each time 5K-6K messages were lost
but this exception was occurring only once.

Thanks
Venkat


On Jan 11, 12:55&#160;pm, Steve Powell &lt;<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">st... at rabbitmq.com</A>&gt; wrote:
&gt;<i> Hi Venkat,
</I>&gt;<i>
</I>&gt;<i> &gt; This time there were no messages lost. All 20K messages were
</I>&gt;<i> &gt; processed.
</I>&gt;<i>
</I>&gt;<i> That's great.
</I>&gt;<i>
</I>&gt;<i> I'm trying to figure out what might be wrong with
</I>&gt;<i> rabbitmqctl report; I'll get back to you.
</I>&gt;<i>
</I>&gt;<i> Meanwhile, running
</I>&gt;<i> &#160; &#160; &#160; &#160;rabbitmqctl -n <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbit at t-2</A> status
</I>&gt;<i> ON NODE t-4 might be interesting.
</I>&gt;<i>
</I>&gt;<i> Also, can you tell us the output from
</I>&gt;<i> &#160; &#160; &#160; &#160;rabbitmqctl cluster_status
</I>&gt;<i> on both nodes, please.
</I>&gt;<i>
</I>&gt;<i> It is not clear if you have issued the stop_app and start_app and
</I>&gt;<i> reset/force_reset commands properly (you probably have), so could you follow
</I>&gt;<i> the steps as described in the clustering guide, and issue
</I>&gt;<i> rabbitmqctl cluster_status on both nodes after each cluster change?
</I>&gt;<i> We should be able to see where things went wrong, then.
</I>&gt;<i>
</I>&gt;<i> (You did start_app after the cluster command, didn't you??? &#160;:-))
</I>&gt;<i>
</I>&gt;<i> Cheers,
</I>&gt;<i>
</I>&gt;<i> Steve Powell &#160;(a hoppy bunny)
</I>&gt;<i> ----------some more definitions from the SPD----------
</I>&gt;<i> avoirdupois (phr.) 'Would you like peas with that?'
</I>&gt;<i> distribute (v.) To denigrate an award ceremony.
</I>&gt;<i> definite (phr.) 'It's hard of hearing, I think.'
</I>&gt;<i> modest (n.) The most mod.
</I>&gt;<i>
</I>&gt;<i> On 11 Jan 2012, at 01:22, Venkat wrote:&gt; ...
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> rabbitmq-discuss mailing list
</I>&gt;<i> <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">rabbitmq-disc... at lists.rabbitmq.comhttps</A>://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss
</I></PRE>



















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="017317.html">[rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues
</A></li>
	<LI>Next message: <A HREF="017400.html">[rabbitmq-discuss] RabbitMQ broker crashing under heavy load	with mirrored queues
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17361">[ date ]</a>
              <a href="thread.html#17361">[ thread ]</a>
              <a href="subject.html#17361">[ subject ]</a>
              <a href="author.html#17361">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
