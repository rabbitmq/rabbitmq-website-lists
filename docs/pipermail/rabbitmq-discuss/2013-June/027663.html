<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%203.1.0%20lost%20messages%20and%20autoheal%0A%20failures%20when%20recovering%20from%20cluster%20partition&In-Reply-To=%3C51ACB13F.9040505%40rabbitmq.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="027660.html">
   <LINK REL="Next"  HREF="027664.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition</H1>
    <B>Simon MacMullen</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%203.1.0%20lost%20messages%20and%20autoheal%0A%20failures%20when%20recovering%20from%20cluster%20partition&In-Reply-To=%3C51ACB13F.9040505%40rabbitmq.com%3E"
       TITLE="[rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition">simon at rabbitmq.com
       </A><BR>
    <I>Mon Jun  3 16:07:43 BST 2013</I>
    <P><UL>
        <LI>Previous message: <A HREF="027660.html">[rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition
</A></li>
        <LI>Next message: <A HREF="027664.html">[rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#27663">[ date ]</a>
              <a href="thread.html#27663">[ thread ]</a>
              <a href="subject.html#27663">[ subject ]</a>
              <a href="author.html#27663">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Hmm. While the partition is in effect neither side should be aware that 
the other side is up at all - we assume if we lose contact with a node 
that it has crashed. So I'm quite surprised by the slow trickle you are 
seeing, since I'm sure people don't see that if part of a cluster just 
crashes.

So I am more suspicious that the iptables commands you are using are in 
fact not simulating a real partitioning of the cluster.

Can you post the iptables commands you are using and I will try to 
replicate?

Cheers, Simon

On 03/06/13 14:01, Maslinski, Ray wrote:
&gt;<i> For this particular test, I was trying to gain some insight as to the
</I>&gt;<i> behavior of the cluster while the partition was in effect, so the
</I>&gt;<i> partition wasn't resolved until the test was completed or aborted.
</I>&gt;<i> My general expectation was that both sides of the partition would
</I>&gt;<i> begin to process messages more or less normally once the cluster
</I>&gt;<i> connection timed out and the slave promoted itself to master,
</I>&gt;<i> possibly with some glitches such as dropped messages during the
</I>&gt;<i> transition.  The slow trickle of messages delivered on one of the
</I>&gt;<i> existing connections was unexpected, and seemed to be a bit of an
</I>&gt;<i> anomaly when combined with the growing count of unacked messages
</I>&gt;<i> shown on the console.
</I>&gt;<i>
</I>&gt;<i> Ray Maslinski Senior Software Developer, Engineering Valassis /
</I>&gt;<i> Digital Media Cell: 585.330.2426 <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">maslinskir at valassis.com</A>
</I>&gt;<i> www.valassis.com
</I>&gt;<i>
</I>&gt;<i> Creating the future of intelligent media delivery to drive your
</I>&gt;<i> greatest success
</I>&gt;<i>
</I>&gt;<i> _____________________________________________________________________________
</I>&gt;<i>
</I>&gt;<i>  This message may include proprietary or protected information. If
</I>&gt;<i> you are not the intended recipient, please notify me, delete this
</I>&gt;<i> message and do not further communicate the information contained
</I>&gt;<i> herein without my express consent.
</I>&gt;<i>
</I>&gt;<i> -----Original Message----- From: Simon MacMullen
</I>&gt;<i> [mailto:<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">simon at rabbitmq.com</A>] Sent: Monday, June 03, 2013 6:37 AM To:
</I>&gt;<i> Maslinski, Ray Cc: Discussions about RabbitMQ Subject: Re:
</I>&gt;<i> [rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures
</I>&gt;<i> when recovering from cluster partition
</I>&gt;<i>
</I>&gt;<i> Just to be clear - at what point in this test are you unblocking the
</I>&gt;<i> connection so the partition can heal?
</I>&gt;<i>
</I>&gt;<i> Cheers, Simon
</I>&gt;<i>
</I>&gt;<i> On 31/05/13 20:04, Maslinski, Ray wrote:
</I>&gt;&gt;<i> The net_ticktime is using the default value, and event sequence
</I>&gt;&gt;<i> seems consistent with the associated timeout.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Roughly,
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Start test
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Block cluster connection at some point -&gt; trace data shows that
</I>&gt;&gt;<i> only publish events are occurring after this happens
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> After a bit more than a minute, RabbitMQ server log shows lost
</I>&gt;&gt;<i> cluster connection on both nodes, along with the death of the
</I>&gt;&gt;<i> mirrors and promotion of slave to master.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Test continues and completes publish phase, since these appeared to
</I>&gt;&gt;<i> be progressing normally, with no errors visible to client
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Test then starts to verify that all messages were received by
</I>&gt;&gt;<i> polling the contents of a buffer used to store incoming messages.
</I>&gt;&gt;<i> In a normal scenario without faults, this generally means that the
</I>&gt;&gt;<i> first poll finds all the messages expected to be present and test
</I>&gt;&gt;<i> completes successfully.  Otherwise, the poll rechecks for any
</I>&gt;&gt;<i> missing messages once per second, and gives up if 30 seconds elapse
</I>&gt;&gt;<i> without any new messages showing up (timer is reset if any messages
</I>&gt;&gt;<i> arrived during polling window).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> The slow trickle of messages occurs during the last phase, as one
</I>&gt;&gt;<i> appears to arrive every 14 seconds and the polling loop continues
</I>&gt;&gt;<i> to retry.  Trace data doesn't appear to log any deliver events
</I>&gt;&gt;<i> during this stage, but console shows a slow increment in the number
</I>&gt;&gt;<i> of unacknowledged messages that lines up with the delivery rate
</I>&gt;&gt;<i> observed by the client.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Ray Maslinski Senior Software Developer, Engineering Valassis /
</I>&gt;&gt;<i> Digital Media Cell: 585.330.2426 <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">maslinskir at valassis.com</A>
</I>&gt;&gt;<i> www.valassis.com
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Creating the future of intelligent media delivery to drive your
</I>&gt;&gt;<i> greatest success
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> ______________________________________________________________________
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>_______
&gt;&gt;<i>
</I>&gt;&gt;<i> This message may include proprietary or protected information. If
</I>&gt;&gt;<i> you are not the intended recipient, please notify me, delete this
</I>&gt;&gt;<i> message and do not further communicate the information contained
</I>&gt;&gt;<i> herein without my express consent.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> -----Original Message----- From: Simon MacMullen
</I>&gt;&gt;<i> [mailto:<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">simon at rabbitmq.com</A>] Sent: Friday, May 31, 2013 12:33 PM
</I>&gt;&gt;<i> To: Maslinski, Ray Cc: Discussions about RabbitMQ Subject: Re:
</I>&gt;&gt;<i> [rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal
</I>&gt;&gt;<i> failures when recovering from cluster partition
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Hi. The behaviour you describe doesn't really match what I would
</I>&gt;&gt;<i> expect to see. In the beginning of a partition I would expect:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> 1) Partition starts
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> 2) Things behave slowly for approximately net_ticktime (see
</I>&gt;&gt;<i> <A HREF="http://www.rabbitmq.com/partitions.html#net_ticktime">http://www.rabbitmq.com/partitions.html#net_ticktime</A>) as nodes
</I>&gt;&gt;<i> attempt to contact each other and time out
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> 3) On each node, Erlang decides the other nodes are down. Things
</I>&gt;&gt;<i> speed up again, HA queues fail over. Split-brain has begun.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> It sounds like you were stuck in 2) for an extended period of
</I>&gt;&gt;<i> time. Have you changed net_ticktime?
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Alternatively, when testing partitions I have see really odd
</I>&gt;&gt;<i> behaviour by blocking network traffic in one direction only with
</I>&gt;&gt;<i> iptables. You might want to check if you've done that by mistake.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Cheers, Simon
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> On 30/05/13 22:14, Maslinski, Ray wrote:
</I>&gt;&gt;&gt;<i> Follow-up question ...
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I tried some experiments to gain some understanding of how the
</I>&gt;&gt;&gt;<i> cluster behaved with clients attached during a network partition
</I>&gt;&gt;&gt;<i> event. Essentially, I repeated the previous tests described below
</I>&gt;&gt;&gt;<i> for autohealing and automatic queue synchronization, but left the
</I>&gt;&gt;&gt;<i> cluster communications port blocked while the client test
</I>&gt;&gt;&gt;<i> completed. One oddity I noticed was that while the consumer
</I>&gt;&gt;&gt;<i> connected to the slave appeared to receive an indication that
</I>&gt;&gt;&gt;<i> something was amiss (client log showed a consumer cancel
</I>&gt;&gt;&gt;<i> exception being handled by the Spring AMQP framework, and other
</I>&gt;&gt;&gt;<i> monitoring logs appeared to show the client restarting a
</I>&gt;&gt;&gt;<i> connection, which seems to be consistent with documentation), the
</I>&gt;&gt;&gt;<i> consumer connected to the master seemed to remain oblivious to
</I>&gt;&gt;&gt;<i> any possible issues. That consumer continued to receive messages,
</I>&gt;&gt;&gt;<i> but at an extremely slow rate (test published at 16/sec fixed
</I>&gt;&gt;&gt;<i> rate, but the remaining consumer began to receive messages at the
</I>&gt;&gt;&gt;<i> rate of about 1 every 14 seconds).
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Since the test client waits around for expected message
</I>&gt;&gt;&gt;<i> deliveries with a resettable 30 second timeout, it continued to
</I>&gt;&gt;&gt;<i> run for an extended period of time (longer than I waited around
</I>&gt;&gt;&gt;<i> for).  In addition, the admin console showed a relatively small
</I>&gt;&gt;&gt;<i> number of unacked messages on that server, with the unacked count
</I>&gt;&gt;&gt;<i> increasing with each actual delivery (client should always be
</I>&gt;&gt;&gt;<i> acknowledging in the test setup, and reported no errors).
</I>&gt;&gt;&gt;<i> Eventually unblocking the cluster port released a bunch of
</I>&gt;&gt;&gt;<i> messages in a short interval (albeit with some lost, as described
</I>&gt;&gt;&gt;<i> previously).
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I also saw  producer connections go into flow control during the
</I>&gt;&gt;&gt;<i> outage and remain there during the slow consumer delivery (though
</I>&gt;&gt;&gt;<i> the test had long since completed delivering all its messages).
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Does this sound like expected behavior during a partition?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Ray Maslinski Senior Software Developer, Engineering Valassis /
</I>&gt;&gt;&gt;<i> Digital Media Cell: 585.330.2426 <A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">maslinskir at valassis.com</A>
</I>&gt;&gt;&gt;<i> www.valassis.com
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Creating the future of intelligent media delivery to drive your
</I>&gt;&gt;&gt;<i> greatest success
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> _____________________________________________________________________
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>_
&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;<i> _______
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> This message may include proprietary or protected information. If
</I>&gt;&gt;&gt;<i> you are not the intended recipient, please notify me, delete this
</I>&gt;&gt;&gt;<i> message and do not further communicate the information contained
</I>&gt;&gt;&gt;<i> herein without my express consent.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> -----Original Message----- From: Simon MacMullen
</I>&gt;&gt;&gt;<i> [mailto:<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">simon at rabbitmq.com</A>] Sent: Monday, May 20, 2013 6:30 AM
</I>&gt;&gt;&gt;<i> To: Discussions about RabbitMQ Cc: Maslinski, Ray Subject: Re:
</I>&gt;&gt;&gt;<i> [rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal
</I>&gt;&gt;&gt;<i> failures when recovering from cluster partition
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> On 17/05/13 20:38, Maslinski, Ray wrote:
</I>&gt;&gt;&gt;&gt;<i> Hello,
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Hi!
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> To simulate a network partition failure, I've been using
</I>&gt;&gt;&gt;&gt;<i> iptables to temporarily block inbound and outbound access on
</I>&gt;&gt;&gt;&gt;<i> one of the nodes to the single port configured for cluster
</I>&gt;&gt;&gt;&gt;<i> communications through inet_dist_listen_min and
</I>&gt;&gt;&gt;&gt;<i> inet_dist_listen_max settings (min = max). Client access is not
</I>&gt;&gt;&gt;&gt;<i> blocked during a simulated partition fault.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Sounds reasonable.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> I've observed two anomalies during testing that I wasn't
</I>&gt;&gt;&gt;&gt;<i> expecting based on the documentation I've read:
</I>&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> -At a sufficiently high message rate, some number of messages
</I>&gt;&gt;&gt;&gt;<i> will be lost during the fault sequence, with the number lost
</I>&gt;&gt;&gt;&gt;<i> tending to increase with message rate.  No indication of a send
</I>&gt;&gt;&gt;&gt;<i> error has been observed by the client program. Based on results
</I>&gt;&gt;&gt;&gt;<i> obtained from test logs and an independent monitor listening on
</I>&gt;&gt;&gt;&gt;<i> trace messages from each node, it appears that as soon as the
</I>&gt;&gt;&gt;&gt;<i> port is blocked, both nodes continue to accept published
</I>&gt;&gt;&gt;&gt;<i> messages, but (temporarily) stop delivering messages until the
</I>&gt;&gt;&gt;&gt;<i> cluster heartbeat failure is detected, at which point the
</I>&gt;&gt;&gt;&gt;<i> cluster is partitioned and the slave promotes itself to become
</I>&gt;&gt;&gt;&gt;<i> master. In the sequences I've looked at, the messages that are
</I>&gt;&gt;&gt;&gt;<i> lost all appear to be published to the original master (and
</I>&gt;&gt;&gt;&gt;<i> final master after a winner is selected during autoheal).
</I>&gt;&gt;&gt;&gt;<i> Neither the start nor the end of the lost message window appear
</I>&gt;&gt;&gt;&gt;<i> to line up with any events in the logs, other than the start
</I>&gt;&gt;&gt;&gt;<i> occurring sometime after the port connection is blocked but
</I>&gt;&gt;&gt;&gt;<i> before the cluster heartbeat failure is detected, and the end
</I>&gt;&gt;&gt;&gt;<i> occurring sometime after the detection of the cluster heartbeat
</I>&gt;&gt;&gt;&gt;<i> failure and before the detection of the partitioned cluster
</I>&gt;&gt;&gt;&gt;<i> after the connection is unblocked.  Is message loss to be
</I>&gt;&gt;&gt;&gt;<i> expected in this scenario?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I would expect to see message loss in a cluster heal scenario.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> It's important to remember that a cluster partition is still a
</I>&gt;&gt;&gt;<i> substantial problem, and the healing process involves throwing
</I>&gt;&gt;&gt;<i> state away. Autoheal mode just means you get through this process
</I>&gt;&gt;&gt;<i> faster, and hopefully spend much less time accepting messages
</I>&gt;&gt;&gt;<i> that will end up being lost.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> I would expect intuitively that only messages from the losing
</I>&gt;&gt;&gt;<i> partitions would be lost. But I am not entirely surprised if
</I>&gt;&gt;&gt;<i> messages from the winner are lost too; there is a period after
</I>&gt;&gt;&gt;<i> the partitions have come back together but before autoheal kicks
</I>&gt;&gt;&gt;<i> in during which we will have multiple masters for a queue, and
</I>&gt;&gt;&gt;<i> behaviour can be unpredictable.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> -Occasionally the autoheal loser node fails to rejoin the
</I>&gt;&gt;&gt;&gt;<i> cluster after restart.  I don't have a lot of data points on
</I>&gt;&gt;&gt;&gt;<i> this one since it's only happened a handful of times during
</I>&gt;&gt;&gt;&gt;<i> overnight test iterations.  During one failure, the autoheal
</I>&gt;&gt;&gt;&gt;<i> winner showed the log message below during recovery:
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Ah, that looks like a bug in autoheal. I think the stack trace
</I>&gt;&gt;&gt;<i> you posted should contain enough information to fix it. Thanks.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Cheers, Simon
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> -- Simon MacMullen RabbitMQ, Pivotal
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> -- Simon MacMullen RabbitMQ, Pivotal
</I>&gt;&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> -- Simon MacMullen RabbitMQ, Pivotal
</I>&gt;<i>
</I>

-- 
Simon MacMullen
RabbitMQ, Pivotal
</PRE>









<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="027660.html">[rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition
</A></li>
	<LI>Next message: <A HREF="027664.html">[rabbitmq-discuss] RabbitMQ 3.1.0 lost messages and autoheal failures when recovering from cluster partition
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#27663">[ date ]</a>
              <a href="thread.html#27663">[ thread ]</a>
              <a href="subject.html#27663">[ subject ]</a>
              <a href="author.html#27663">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
