<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> [rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%203.0%20Policy%20ha-all%20delete%20issue&In-Reply-To=%3C50ABE77B.2090201%40rabbitmq.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="024014.html">
   <LINK REL="Next"  HREF="024045.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue</H1>
    <B>Matthias Radestock</B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20%5Brabbitmq-discuss%5D%20RabbitMQ%203.0%20Policy%20ha-all%20delete%20issue&In-Reply-To=%3C50ABE77B.2090201%40rabbitmq.com%3E"
       TITLE="[rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue">matthias at rabbitmq.com
       </A><BR>
    <I>Tue Nov 20 20:26:35 GMT 2012</I>
    <P><UL>
        <LI>Previous message: <A HREF="024014.html">[rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue
</A></li>
        <LI>Next message: <A HREF="024045.html">[rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#24020">[ date ]</a>
              <a href="thread.html#24020">[ thread ]</a>
              <a href="subject.html#24020">[ subject ]</a>
              <a href="author.html#24020">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Mark,

On 20/11/12 19:29, Mark Ward wrote:
&gt;<i> The function request typically always goes into a queue that is static.  For
</I>&gt;<i> example a ping service would have a queue based upon the computer's name.
</I>&gt;<i> Any ping request to the computer would be put into the queue.  Results of
</I>&gt;<i> the ping would generate a new queue.  Each result will be placed into a
</I>&gt;<i> unique result queue that is created for each result published.  The result
</I>&gt;<i> queue is based upon a name that the server and client both know.  I went
</I>&gt;<i> with this design to eliminate the need to build routing logic to route
</I>&gt;<i> results from a queue to waiting callers.  I also didn't want a caller's
</I>&gt;<i> result be dependent upon another caller's result within a single queue.
</I>
Could you create one reply queue per thread, assuming there can't be 
more than one pending rpc per thread? Or maintain a pool of reply queues.

&gt;<i> I will think about the result queue not being mirrored as this would greatly
</I>&gt;<i> improve performance but does make rabbitMQ server maintenance more
</I>&gt;<i> difficult.  If the node with the queue is shutdown and the client connects
</I>&gt;<i> to a new node the result queue would be recreated.
</I>
I see. If you can move off the one-queue-per-reply model then making the 
reply queues HA won't be so much of an issue. w/o that though the 
penalty is massive.

&gt;<i> I ran into issues with my cluster testing when messages become large enough
</I>&gt;<i> to negatively impact the cluster.  My test cluster only has 1 gig of ram per
</I>&gt;<i> computer (3 servers).  The message size plus slowly draining queues will
</I>&gt;<i> easily destroy this test cluster.  I would run into issues with the erlang
</I>&gt;<i> node heartbeat.  I would also run into issues where erlang would run out of
</I>&gt;<i> ram even with the default high watermark + flow control.  Erlang would crash
</I>&gt;<i> bringing down the rabbitmq node.
</I>
Interesting. How large are the messages?

&gt;<i> If a large message is detected it will be split into smaller packets.  A
</I>&gt;<i> split indicator message will be placed into the original target queue.  The
</I>&gt;<i> actual message will be split into smaller packets and published into a newly
</I>&gt;<i> created queue just for the split.  Each split message will have an equal
</I>&gt;<i> split queue.
</I>&gt;<i> The original target queue may have two or more subscribers.  A subscriber
</I>&gt;<i> will receive a split indicator message.  It will then begin to subscribe and
</I>&gt;<i> drain the message's split queue.  When completed all messages are acked.
</I>&gt;<i> This allows the split message queue to be processed by a single client while
</I>&gt;<i> the original queue can have any number of subscribers.  When the split queue
</I>&gt;<i> is finished it is disposed of.
</I>
That's pretty neat.

Perhaps you could somehow recycle the split message queues rather than 
deleting it.

&gt;<i> I know i am getting a performance hit with the dynamic queues but their use
</I>&gt;<i> made the two scenarios much easier to implement.
</I>
If the performance you are getting is good enough for your application 
then there is no compelling reason to change anything.


Regards,

Matthias.
</PRE>




































<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="024014.html">[rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue
</A></li>
	<LI>Next message: <A HREF="024045.html">[rabbitmq-discuss] RabbitMQ 3.0 Policy ha-all delete issue
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#24020">[ date ]</a>
              <a href="thread.html#24020">[ thread ]</a>
              <a href="subject.html#24020">[ subject ]</a>
              <a href="author.html#24020">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
