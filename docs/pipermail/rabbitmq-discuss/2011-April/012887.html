<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
 <HEAD>
   <TITLE> No subject
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20No%20subject&In-Reply-To=%3Cmailman.4.1305549305.2895.rabbitmq-discuss%40lists.rabbitmq.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="016632.html">
   <LINK REL="Next"  HREF="016650.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>No subject</H1>
    <B></B> 
    <A HREF="mailto:rabbitmq-discuss%40lists.rabbitmq.com?Subject=Re%3A%20No%20subject&In-Reply-To=%3Cmailman.4.1305549305.2895.rabbitmq-discuss%40lists.rabbitmq.com%3E"
       TITLE="No subject">
       </A><BR>
    <I>Tue Apr 12 10:32:41 BST 2011</I>
    <P><UL>
        <LI>Previous message: <A HREF="016632.html">No subject
</A></li>
        <LI>Next message: <A HREF="016650.html">No subject
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12887">[ date ]</a>
              <a href="thread.html#12887">[ thread ]</a>
              <a href="subject.html#12887">[ subject ]</a>
              <a href="author.html#12887">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>the same degrading performance that I did in a multi-host test. I also
observe the same thing on my workstation. I cut my testing short
before finding out where specifically the client and rabbit were
contributing to produce that curve.

If you do investigate libevent, you may find like I did that the
pyevent project suffers from poor releases. After years of fighting
with it we forked and created a separate pypi package with the latest
pyevent changes. Solving this problem with a ctypes library, and
possibly switching over to libev, are on my list of future projects.

I can't recall if pika was around when we first forked pyamqplib; we
chose libevent because we have fast HTTP -&gt; AMQP gateways and needed
it on both sides of that bridge. Once we had something working, it
seemed like a good idea to publish, but it needed the rewrite that is
haigha to make it worth the effort. I also have learned a lot about
the protocol and wanted to put into practice some ideas on how to
write a good client.

If you like what you see perhaps we can figure out how to merge or
otherwise mutually improve haigha and pika. We recently used eventlet
to great success, which gave me inspiration to think about haigha with
an abstract connection layer. I found that since we only rely on
libevent in the Connection class, we're not far away from that design,
which I gather is also what pika is going for.

cheers,
Aaron

On Mon, May 16, 2011 at 3:01 AM, Gavin M. Roy &lt;<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">gmr at myyearbook.com</A>&gt; wrote:
&gt;<i> Hey Aaron, cool work. =A0Using libevent is a nice approach. =A0Given Pika=
</I>'s
&gt;<i> modular approach, I'll have to see what that looks like as an option in P=
</I>ika
&gt;<i> v2.
</I>&gt;<i> Given Jason's questions, I decided to port your bench to Pika and threw i=
</I>n
&gt;<i> py-amqplib (single channel only) to boot.
</I>&gt;<i> As I had expected,=A0Haigha benched faster than Pika, but surprisingly on=
</I>ly by
&gt;<i> 2.84% with 500 channels. =A0I does, however, start to show its performanc=
</I>e
&gt;<i> benefits on a single connection with multiple channels when the single
</I>&gt;<i> socket is not over-saturated. =A0It was 13.29% faster than Pika with 50
</I>&gt;<i> channels and 21.57% faster with 10 channels.
</I>&gt;<i> I was somewhat surprised to find that Pika benched 13.08% faster with onl=
</I>y 1
&gt;<i> channel. So surprised that I had to triple check the numbers ;-)
</I>&gt;<i> I used the 500 number as the initial baseline because it the default valu=
</I>e
&gt;<i> in your test app.=A0I am curious what the use case for so many channels i=
</I>s in
&gt;<i> the test. =A0Is it to simulate concurrency in a client app?
</I>&gt;<i> Anyway here is the info on my tests:
</I>&gt;<i> Box:
</I>&gt;<i>
</I>&gt;<i> Dual quad core AMD 2.2Gz (Model 2356)
</I>&gt;<i> 8GB Ram
</I>&gt;<i> Max CPU utilization during all tests: 19%
</I>&gt;<i> Max IOWait during all tests: 0.2%
</I>&gt;<i> Gentoo Linux with a custom compiled 2.6.28 kernel
</I>&gt;<i>
</I>&gt;<i> RabbitMQ:
</I>&gt;<i>
</I>&gt;<i> 2.4.1
</I>&gt;<i> Erlang R14B02
</I>&gt;<i> Default settings
</I>&gt;<i>
</I>&gt;<i> Client libraries:
</I>&gt;<i>
</I>&gt;<i> Haigha 0.2.1
</I>&gt;<i> Pika 0.9.6p0
</I>&gt;<i> py-amqplib 0.6.1
</I>&gt;<i>
</I>&gt;<i> Test Parameters:
</I>&gt;<i>
</I>&gt;<i> Duration: 300 seconds
</I>&gt;<i> Channel Count: 1, 10, 50, 500
</I>&gt;<i> No-Ack: True
</I>&gt;<i> Transactions: Off
</I>&gt;<i> Single threaded
</I>&gt;<i> Single Process
</I>&gt;<i>
</I>&gt;<i> The 1 channel option was to accommodate py-admqplib and BlockingConnectio=
</I>n.
&gt;<i> =A0BlockingConnection can handle multiple channels but the overhead for
</I>&gt;<i> setting up 500 connections on BlockingAdapter in Pika was prohibitive. =
</I>=A0The
&gt;<i> test ended prior to all queues being bound and a single full setup is
</I>&gt;<i> roughly 1.2 seconds in my environment. For the Pika/TornadoConnection tes=
</I>t,
&gt;<i> I used Tornado 1.2.
</I>&gt;<i> A few important things were uncovered in Pika with this test:
</I>&gt;<i>
</I>&gt;<i> There is an interesting recursion bug under heavy loads in all 0.9.x
</I>&gt;<i> versions. This bug would only present itself if there was always a frame =
</I>to
&gt;<i> read or frame to publish in the buffer. If the IOLoop ever had a cycle
</I>&gt;<i> without inbound or outbound data, the bug will not present. =A0But if the=
</I>re is
&gt;<i> always data to process, for up to 1,000 frames, there will be a
</I>&gt;<i> RuntimeError. 1,000 is the default Python recursion limit. This bug has b=
</I>een
&gt;<i> fixed.
</I>&gt;<i> BlockingConnection is very slow! It is roughly 1/8th the speed of
</I>&gt;<i> py-amqplib. While Asyncore can do roughly 1,800 messages a second on a
</I>&gt;<i> single channel, Blocking can only do roughly 4!
</I>&gt;<i>
</I>&gt;<i> I didn't make much of an effort to clean up the code or remove the parts =
</I>I
&gt;<i> don't use, but the stress_test app hack for pika is
</I>&gt;<i> at=<A HREF="A0https://gist.github.com/974021">A0https://gist.github.com/974021</A>
</I>&gt;<i> Haigha looks nice. You're doing some of the things I have been thinking
</I>&gt;<i> about with future versions of Pika such as in your haigha/classes modules
</I>&gt;<i> (More natural AMQP mapping of classes for use in the client).=A0I look fo=
</I>rward
&gt;<i> to seeing where you take it.
</I>&gt;<i> Regards,
</I>&gt;<i> Gavin
</I>&gt;<i>
</I>&gt;<i> On Saturday, May 14, 2011 at 9:40 PM, Jason J. W. Williams wrote:
</I>&gt;<i>
</I>&gt;<i> How does this differ from Pika's asyncore or Tornado bindings in terms of
</I>&gt;<i> performance?
</I>&gt;<i>
</I>


--=20
Aaron Westendorf
Senior Software Engineer
Agora Games
359 Broadway
Troy, NY 12180
Phone: 518.268.1000
<A HREF="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">aaron at agoragames.com</A>
www.agoragames.com
</PRE>





























<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="016632.html">No subject
</A></li>
	<LI>Next message: <A HREF="016650.html">No subject
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12887">[ date ]</a>
              <a href="thread.html#12887">[ thread ]</a>
              <a href="subject.html#12887">[ subject ]</a>
              <a href="author.html#12887">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.rabbitmq.com/cgi-bin/mailman/listinfo/rabbitmq-discuss">More information about the rabbitmq-discuss
mailing list</a><br>
</body></html>
